{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 4151,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024093482712926155,
      "grad_norm": 0.778272807598114,
      "learning_rate": 1.9975903614457833e-05,
      "loss": 1.7877,
      "step": 10
    },
    {
      "epoch": 0.004818696542585231,
      "grad_norm": 0.7076205611228943,
      "learning_rate": 1.9951807228915665e-05,
      "loss": 1.7033,
      "step": 20
    },
    {
      "epoch": 0.007228044813877846,
      "grad_norm": 0.6755002737045288,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 1.7309,
      "step": 30
    },
    {
      "epoch": 0.009637393085170462,
      "grad_norm": 0.7528151273727417,
      "learning_rate": 1.9903614457831325e-05,
      "loss": 1.7177,
      "step": 40
    },
    {
      "epoch": 0.012046741356463078,
      "grad_norm": 0.7398552894592285,
      "learning_rate": 1.987951807228916e-05,
      "loss": 1.6826,
      "step": 50
    },
    {
      "epoch": 0.014456089627755691,
      "grad_norm": 0.6689538359642029,
      "learning_rate": 1.985542168674699e-05,
      "loss": 1.6262,
      "step": 60
    },
    {
      "epoch": 0.01686543789904831,
      "grad_norm": 0.8494299054145813,
      "learning_rate": 1.983132530120482e-05,
      "loss": 1.5772,
      "step": 70
    },
    {
      "epoch": 0.019274786170340924,
      "grad_norm": 0.8741278648376465,
      "learning_rate": 1.9807228915662652e-05,
      "loss": 1.5601,
      "step": 80
    },
    {
      "epoch": 0.02168413444163354,
      "grad_norm": 0.9824590086936951,
      "learning_rate": 1.9783132530120484e-05,
      "loss": 1.4793,
      "step": 90
    },
    {
      "epoch": 0.024093482712926155,
      "grad_norm": 0.8975394368171692,
      "learning_rate": 1.9759036144578312e-05,
      "loss": 1.4605,
      "step": 100
    },
    {
      "epoch": 0.02650283098421877,
      "grad_norm": 1.0387011766433716,
      "learning_rate": 1.9734939759036148e-05,
      "loss": 1.4309,
      "step": 110
    },
    {
      "epoch": 0.028912179255511383,
      "grad_norm": 1.1360622644424438,
      "learning_rate": 1.9710843373493976e-05,
      "loss": 1.3897,
      "step": 120
    },
    {
      "epoch": 0.031321527526804,
      "grad_norm": 0.8835365176200867,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 1.2697,
      "step": 130
    },
    {
      "epoch": 0.03373087579809662,
      "grad_norm": 1.3133453130722046,
      "learning_rate": 1.966265060240964e-05,
      "loss": 1.2546,
      "step": 140
    },
    {
      "epoch": 0.03614022406938923,
      "grad_norm": 1.0252336263656616,
      "learning_rate": 1.963855421686747e-05,
      "loss": 1.2842,
      "step": 150
    },
    {
      "epoch": 0.03854957234068185,
      "grad_norm": 0.9969293475151062,
      "learning_rate": 1.9614457831325303e-05,
      "loss": 1.2192,
      "step": 160
    },
    {
      "epoch": 0.04095892061197446,
      "grad_norm": 0.8924717307090759,
      "learning_rate": 1.9590361445783135e-05,
      "loss": 1.2718,
      "step": 170
    },
    {
      "epoch": 0.04336826888326708,
      "grad_norm": 1.1445220708847046,
      "learning_rate": 1.9566265060240967e-05,
      "loss": 1.2669,
      "step": 180
    },
    {
      "epoch": 0.04577761715455969,
      "grad_norm": 0.8756242990493774,
      "learning_rate": 1.9542168674698795e-05,
      "loss": 1.2184,
      "step": 190
    },
    {
      "epoch": 0.04818696542585231,
      "grad_norm": 0.9437810778617859,
      "learning_rate": 1.951807228915663e-05,
      "loss": 1.2006,
      "step": 200
    },
    {
      "epoch": 0.05059631369714492,
      "grad_norm": 0.8347366452217102,
      "learning_rate": 1.949397590361446e-05,
      "loss": 1.1787,
      "step": 210
    },
    {
      "epoch": 0.05300566196843754,
      "grad_norm": 1.04587721824646,
      "learning_rate": 1.946987951807229e-05,
      "loss": 1.1493,
      "step": 220
    },
    {
      "epoch": 0.05541501023973015,
      "grad_norm": 1.071115493774414,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 1.1795,
      "step": 230
    },
    {
      "epoch": 0.057824358511022765,
      "grad_norm": 1.1713043451309204,
      "learning_rate": 1.9421686746987954e-05,
      "loss": 1.0934,
      "step": 240
    },
    {
      "epoch": 0.060233706782315384,
      "grad_norm": 0.9322252869606018,
      "learning_rate": 1.9397590361445785e-05,
      "loss": 1.1258,
      "step": 250
    },
    {
      "epoch": 0.062643055053608,
      "grad_norm": 0.8990157246589661,
      "learning_rate": 1.9373493975903617e-05,
      "loss": 1.1739,
      "step": 260
    },
    {
      "epoch": 0.06505240332490062,
      "grad_norm": 0.8893855810165405,
      "learning_rate": 1.9349397590361446e-05,
      "loss": 1.1577,
      "step": 270
    },
    {
      "epoch": 0.06746175159619323,
      "grad_norm": 1.1032131910324097,
      "learning_rate": 1.9325301204819277e-05,
      "loss": 1.0794,
      "step": 280
    },
    {
      "epoch": 0.06987109986748584,
      "grad_norm": 1.3081083297729492,
      "learning_rate": 1.930120481927711e-05,
      "loss": 1.0782,
      "step": 290
    },
    {
      "epoch": 0.07228044813877846,
      "grad_norm": 0.9143674969673157,
      "learning_rate": 1.927710843373494e-05,
      "loss": 1.1114,
      "step": 300
    },
    {
      "epoch": 0.07468979641007108,
      "grad_norm": 1.19508957862854,
      "learning_rate": 1.9253012048192773e-05,
      "loss": 1.1457,
      "step": 310
    },
    {
      "epoch": 0.0770991446813637,
      "grad_norm": 1.0510634183883667,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 1.1496,
      "step": 320
    },
    {
      "epoch": 0.0795084929526563,
      "grad_norm": 1.41334867477417,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 1.1344,
      "step": 330
    },
    {
      "epoch": 0.08191784122394892,
      "grad_norm": 1.275490164756775,
      "learning_rate": 1.9180722891566265e-05,
      "loss": 1.0732,
      "step": 340
    },
    {
      "epoch": 0.08432718949524154,
      "grad_norm": 1.463879942893982,
      "learning_rate": 1.91566265060241e-05,
      "loss": 1.1524,
      "step": 350
    },
    {
      "epoch": 0.08673653776653416,
      "grad_norm": 0.8707205653190613,
      "learning_rate": 1.9132530120481928e-05,
      "loss": 1.15,
      "step": 360
    },
    {
      "epoch": 0.08914588603782676,
      "grad_norm": 0.9129836559295654,
      "learning_rate": 1.910843373493976e-05,
      "loss": 1.1522,
      "step": 370
    },
    {
      "epoch": 0.09155523430911938,
      "grad_norm": 0.9253113865852356,
      "learning_rate": 1.908433734939759e-05,
      "loss": 1.1306,
      "step": 380
    },
    {
      "epoch": 0.093964582580412,
      "grad_norm": 1.0518560409545898,
      "learning_rate": 1.9060240963855423e-05,
      "loss": 1.0591,
      "step": 390
    },
    {
      "epoch": 0.09637393085170462,
      "grad_norm": 1.1177632808685303,
      "learning_rate": 1.9036144578313255e-05,
      "loss": 1.0948,
      "step": 400
    },
    {
      "epoch": 0.09878327912299723,
      "grad_norm": 1.1873198747634888,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 1.1042,
      "step": 410
    },
    {
      "epoch": 0.10119262739428984,
      "grad_norm": 0.9943903088569641,
      "learning_rate": 1.898795180722892e-05,
      "loss": 1.1161,
      "step": 420
    },
    {
      "epoch": 0.10360197566558246,
      "grad_norm": 0.9248993396759033,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 1.1091,
      "step": 430
    },
    {
      "epoch": 0.10601132393687508,
      "grad_norm": 1.708941102027893,
      "learning_rate": 1.893975903614458e-05,
      "loss": 1.0747,
      "step": 440
    },
    {
      "epoch": 0.10842067220816769,
      "grad_norm": 1.084115743637085,
      "learning_rate": 1.891566265060241e-05,
      "loss": 1.168,
      "step": 450
    },
    {
      "epoch": 0.1108300204794603,
      "grad_norm": 1.0397188663482666,
      "learning_rate": 1.8891566265060242e-05,
      "loss": 1.1396,
      "step": 460
    },
    {
      "epoch": 0.11323936875075293,
      "grad_norm": 1.003334403038025,
      "learning_rate": 1.8867469879518074e-05,
      "loss": 1.1563,
      "step": 470
    },
    {
      "epoch": 0.11564871702204553,
      "grad_norm": 1.1543530225753784,
      "learning_rate": 1.8843373493975906e-05,
      "loss": 1.0877,
      "step": 480
    },
    {
      "epoch": 0.11805806529333815,
      "grad_norm": 1.2510093450546265,
      "learning_rate": 1.8819277108433734e-05,
      "loss": 1.1235,
      "step": 490
    },
    {
      "epoch": 0.12046741356463077,
      "grad_norm": 0.8050975203514099,
      "learning_rate": 1.879518072289157e-05,
      "loss": 1.1216,
      "step": 500
    },
    {
      "epoch": 0.12287676183592339,
      "grad_norm": 1.5139371156692505,
      "learning_rate": 1.8771084337349398e-05,
      "loss": 1.1365,
      "step": 510
    },
    {
      "epoch": 0.125286110107216,
      "grad_norm": 1.0474332571029663,
      "learning_rate": 1.874698795180723e-05,
      "loss": 1.09,
      "step": 520
    },
    {
      "epoch": 0.12769545837850863,
      "grad_norm": 1.2310971021652222,
      "learning_rate": 1.872289156626506e-05,
      "loss": 1.1175,
      "step": 530
    },
    {
      "epoch": 0.13010480664980123,
      "grad_norm": 1.172333836555481,
      "learning_rate": 1.8698795180722893e-05,
      "loss": 1.1018,
      "step": 540
    },
    {
      "epoch": 0.13251415492109384,
      "grad_norm": 1.0365737676620483,
      "learning_rate": 1.8674698795180725e-05,
      "loss": 1.0509,
      "step": 550
    },
    {
      "epoch": 0.13492350319238647,
      "grad_norm": 1.1811223030090332,
      "learning_rate": 1.8650602409638556e-05,
      "loss": 1.0871,
      "step": 560
    },
    {
      "epoch": 0.13733285146367907,
      "grad_norm": 1.2066384553909302,
      "learning_rate": 1.8626506024096388e-05,
      "loss": 1.1144,
      "step": 570
    },
    {
      "epoch": 0.13974219973497168,
      "grad_norm": 1.1540757417678833,
      "learning_rate": 1.8602409638554217e-05,
      "loss": 1.118,
      "step": 580
    },
    {
      "epoch": 0.1421515480062643,
      "grad_norm": 1.0650665760040283,
      "learning_rate": 1.8578313253012052e-05,
      "loss": 1.1232,
      "step": 590
    },
    {
      "epoch": 0.14456089627755692,
      "grad_norm": 1.1721223592758179,
      "learning_rate": 1.855421686746988e-05,
      "loss": 1.1137,
      "step": 600
    },
    {
      "epoch": 0.14697024454884955,
      "grad_norm": 0.9749694466590881,
      "learning_rate": 1.8530120481927712e-05,
      "loss": 1.0574,
      "step": 610
    },
    {
      "epoch": 0.14937959282014215,
      "grad_norm": 1.0468711853027344,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 1.0967,
      "step": 620
    },
    {
      "epoch": 0.15178894109143476,
      "grad_norm": 0.9893456697463989,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 1.0804,
      "step": 630
    },
    {
      "epoch": 0.1541982893627274,
      "grad_norm": 1.4045124053955078,
      "learning_rate": 1.8457831325301204e-05,
      "loss": 1.0926,
      "step": 640
    },
    {
      "epoch": 0.15660763763402,
      "grad_norm": 1.3839199542999268,
      "learning_rate": 1.843373493975904e-05,
      "loss": 1.0971,
      "step": 650
    },
    {
      "epoch": 0.1590169859053126,
      "grad_norm": 1.1075477600097656,
      "learning_rate": 1.8409638554216867e-05,
      "loss": 1.0991,
      "step": 660
    },
    {
      "epoch": 0.16142633417660524,
      "grad_norm": 1.1056251525878906,
      "learning_rate": 1.83855421686747e-05,
      "loss": 1.1081,
      "step": 670
    },
    {
      "epoch": 0.16383568244789784,
      "grad_norm": 0.8574629426002502,
      "learning_rate": 1.836144578313253e-05,
      "loss": 1.1306,
      "step": 680
    },
    {
      "epoch": 0.16624503071919045,
      "grad_norm": 1.2023576498031616,
      "learning_rate": 1.8337349397590363e-05,
      "loss": 1.1073,
      "step": 690
    },
    {
      "epoch": 0.16865437899048308,
      "grad_norm": 1.0033574104309082,
      "learning_rate": 1.8313253012048194e-05,
      "loss": 1.0736,
      "step": 700
    },
    {
      "epoch": 0.17106372726177568,
      "grad_norm": 1.2584540843963623,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 1.1072,
      "step": 710
    },
    {
      "epoch": 0.17347307553306832,
      "grad_norm": 1.1961642503738403,
      "learning_rate": 1.8265060240963858e-05,
      "loss": 1.0928,
      "step": 720
    },
    {
      "epoch": 0.17588242380436092,
      "grad_norm": 1.0819092988967896,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 1.1167,
      "step": 730
    },
    {
      "epoch": 0.17829177207565353,
      "grad_norm": 1.0206191539764404,
      "learning_rate": 1.821686746987952e-05,
      "loss": 1.0565,
      "step": 740
    },
    {
      "epoch": 0.18070112034694616,
      "grad_norm": 1.0200886726379395,
      "learning_rate": 1.819277108433735e-05,
      "loss": 1.0851,
      "step": 750
    },
    {
      "epoch": 0.18311046861823876,
      "grad_norm": 1.292902946472168,
      "learning_rate": 1.816867469879518e-05,
      "loss": 1.1291,
      "step": 760
    },
    {
      "epoch": 0.18551981688953137,
      "grad_norm": 1.245489239692688,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 1.0606,
      "step": 770
    },
    {
      "epoch": 0.187929165160824,
      "grad_norm": 1.0169905424118042,
      "learning_rate": 1.8120481927710845e-05,
      "loss": 1.0924,
      "step": 780
    },
    {
      "epoch": 0.1903385134321166,
      "grad_norm": 1.0398852825164795,
      "learning_rate": 1.8096385542168677e-05,
      "loss": 1.1264,
      "step": 790
    },
    {
      "epoch": 0.19274786170340924,
      "grad_norm": 1.233620285987854,
      "learning_rate": 1.807228915662651e-05,
      "loss": 1.0986,
      "step": 800
    },
    {
      "epoch": 0.19515720997470185,
      "grad_norm": 1.1775087118148804,
      "learning_rate": 1.8048192771084337e-05,
      "loss": 1.123,
      "step": 810
    },
    {
      "epoch": 0.19756655824599445,
      "grad_norm": 1.2909103631973267,
      "learning_rate": 1.802409638554217e-05,
      "loss": 1.0799,
      "step": 820
    },
    {
      "epoch": 0.19997590651728708,
      "grad_norm": 1.081285834312439,
      "learning_rate": 1.8e-05,
      "loss": 1.061,
      "step": 830
    },
    {
      "epoch": 0.2023852547885797,
      "grad_norm": 0.963627278804779,
      "learning_rate": 1.7975903614457832e-05,
      "loss": 1.0562,
      "step": 840
    },
    {
      "epoch": 0.2047946030598723,
      "grad_norm": 1.145747184753418,
      "learning_rate": 1.7951807228915664e-05,
      "loss": 1.0914,
      "step": 850
    },
    {
      "epoch": 0.20720395133116493,
      "grad_norm": 0.9589347243309021,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 1.143,
      "step": 860
    },
    {
      "epoch": 0.20961329960245753,
      "grad_norm": 1.643786907196045,
      "learning_rate": 1.7903614457831327e-05,
      "loss": 1.1166,
      "step": 870
    },
    {
      "epoch": 0.21202264787375016,
      "grad_norm": 0.9508745074272156,
      "learning_rate": 1.7879518072289156e-05,
      "loss": 1.0941,
      "step": 880
    },
    {
      "epoch": 0.21443199614504277,
      "grad_norm": 1.3346177339553833,
      "learning_rate": 1.785542168674699e-05,
      "loss": 1.0507,
      "step": 890
    },
    {
      "epoch": 0.21684134441633537,
      "grad_norm": 1.2976255416870117,
      "learning_rate": 1.783132530120482e-05,
      "loss": 1.0888,
      "step": 900
    },
    {
      "epoch": 0.219250692687628,
      "grad_norm": 1.1353492736816406,
      "learning_rate": 1.780722891566265e-05,
      "loss": 1.0806,
      "step": 910
    },
    {
      "epoch": 0.2216600409589206,
      "grad_norm": 1.0453113317489624,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 1.0692,
      "step": 920
    },
    {
      "epoch": 0.22406938923021322,
      "grad_norm": 1.1286582946777344,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 1.1526,
      "step": 930
    },
    {
      "epoch": 0.22647873750150585,
      "grad_norm": 1.036206841468811,
      "learning_rate": 1.7734939759036146e-05,
      "loss": 1.0968,
      "step": 940
    },
    {
      "epoch": 0.22888808577279846,
      "grad_norm": 0.9141355156898499,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 1.0953,
      "step": 950
    },
    {
      "epoch": 0.23129743404409106,
      "grad_norm": 1.2504498958587646,
      "learning_rate": 1.768674698795181e-05,
      "loss": 1.1466,
      "step": 960
    },
    {
      "epoch": 0.2337067823153837,
      "grad_norm": 1.0719149112701416,
      "learning_rate": 1.766265060240964e-05,
      "loss": 1.073,
      "step": 970
    },
    {
      "epoch": 0.2361161305866763,
      "grad_norm": 1.1593096256256104,
      "learning_rate": 1.763855421686747e-05,
      "loss": 1.0347,
      "step": 980
    },
    {
      "epoch": 0.23852547885796893,
      "grad_norm": 1.5641217231750488,
      "learning_rate": 1.7614457831325302e-05,
      "loss": 1.0653,
      "step": 990
    },
    {
      "epoch": 0.24093482712926154,
      "grad_norm": 1.0853577852249146,
      "learning_rate": 1.7590361445783134e-05,
      "loss": 1.0559,
      "step": 1000
    },
    {
      "epoch": 0.24334417540055414,
      "grad_norm": 0.9054080247879028,
      "learning_rate": 1.7566265060240965e-05,
      "loss": 1.1294,
      "step": 1010
    },
    {
      "epoch": 0.24575352367184677,
      "grad_norm": 1.1215705871582031,
      "learning_rate": 1.7542168674698797e-05,
      "loss": 1.0982,
      "step": 1020
    },
    {
      "epoch": 0.24816287194313938,
      "grad_norm": 1.0005075931549072,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 1.0262,
      "step": 1030
    },
    {
      "epoch": 0.250572220214432,
      "grad_norm": 1.285381555557251,
      "learning_rate": 1.749397590361446e-05,
      "loss": 1.0963,
      "step": 1040
    },
    {
      "epoch": 0.2529815684857246,
      "grad_norm": 1.202582836151123,
      "learning_rate": 1.746987951807229e-05,
      "loss": 1.0302,
      "step": 1050
    },
    {
      "epoch": 0.25539091675701725,
      "grad_norm": 1.0953128337860107,
      "learning_rate": 1.7445783132530124e-05,
      "loss": 1.0721,
      "step": 1060
    },
    {
      "epoch": 0.2578002650283098,
      "grad_norm": 1.0882971286773682,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 1.0795,
      "step": 1070
    },
    {
      "epoch": 0.26020961329960246,
      "grad_norm": 1.465197205543518,
      "learning_rate": 1.7397590361445784e-05,
      "loss": 1.0431,
      "step": 1080
    },
    {
      "epoch": 0.2626189615708951,
      "grad_norm": 1.2779960632324219,
      "learning_rate": 1.7373493975903616e-05,
      "loss": 1.0739,
      "step": 1090
    },
    {
      "epoch": 0.26502830984218767,
      "grad_norm": 1.4842228889465332,
      "learning_rate": 1.7349397590361448e-05,
      "loss": 1.0251,
      "step": 1100
    },
    {
      "epoch": 0.2674376581134803,
      "grad_norm": 1.983972191810608,
      "learning_rate": 1.732530120481928e-05,
      "loss": 1.0825,
      "step": 1110
    },
    {
      "epoch": 0.26984700638477294,
      "grad_norm": 1.3031367063522339,
      "learning_rate": 1.730120481927711e-05,
      "loss": 1.1116,
      "step": 1120
    },
    {
      "epoch": 0.2722563546560655,
      "grad_norm": 1.5140386819839478,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 1.0937,
      "step": 1130
    },
    {
      "epoch": 0.27466570292735815,
      "grad_norm": 1.1708729267120361,
      "learning_rate": 1.725301204819277e-05,
      "loss": 1.0374,
      "step": 1140
    },
    {
      "epoch": 0.2770750511986508,
      "grad_norm": 1.0556375980377197,
      "learning_rate": 1.7228915662650603e-05,
      "loss": 1.1403,
      "step": 1150
    },
    {
      "epoch": 0.27948439946994336,
      "grad_norm": 1.2846438884735107,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 1.0752,
      "step": 1160
    },
    {
      "epoch": 0.281893747741236,
      "grad_norm": 1.3567779064178467,
      "learning_rate": 1.7180722891566267e-05,
      "loss": 1.1058,
      "step": 1170
    },
    {
      "epoch": 0.2843030960125286,
      "grad_norm": 1.4574179649353027,
      "learning_rate": 1.71566265060241e-05,
      "loss": 1.1037,
      "step": 1180
    },
    {
      "epoch": 0.2867124442838212,
      "grad_norm": 0.907355010509491,
      "learning_rate": 1.713253012048193e-05,
      "loss": 1.0653,
      "step": 1190
    },
    {
      "epoch": 0.28912179255511383,
      "grad_norm": 1.1412794589996338,
      "learning_rate": 1.710843373493976e-05,
      "loss": 1.1246,
      "step": 1200
    },
    {
      "epoch": 0.29153114082640647,
      "grad_norm": 1.3540143966674805,
      "learning_rate": 1.7084337349397594e-05,
      "loss": 1.1083,
      "step": 1210
    },
    {
      "epoch": 0.2939404890976991,
      "grad_norm": 1.1878900527954102,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 1.0803,
      "step": 1220
    },
    {
      "epoch": 0.2963498373689917,
      "grad_norm": 1.1130931377410889,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 1.0911,
      "step": 1230
    },
    {
      "epoch": 0.2987591856402843,
      "grad_norm": 1.3948734998703003,
      "learning_rate": 1.7012048192771086e-05,
      "loss": 1.0716,
      "step": 1240
    },
    {
      "epoch": 0.30116853391157694,
      "grad_norm": 1.1232366561889648,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 1.0978,
      "step": 1250
    },
    {
      "epoch": 0.3035778821828695,
      "grad_norm": 1.0728490352630615,
      "learning_rate": 1.696385542168675e-05,
      "loss": 1.1378,
      "step": 1260
    },
    {
      "epoch": 0.30598723045416215,
      "grad_norm": 1.1470845937728882,
      "learning_rate": 1.693975903614458e-05,
      "loss": 1.1042,
      "step": 1270
    },
    {
      "epoch": 0.3083965787254548,
      "grad_norm": 1.5216304063796997,
      "learning_rate": 1.6915662650602413e-05,
      "loss": 1.0855,
      "step": 1280
    },
    {
      "epoch": 0.31080592699674736,
      "grad_norm": 0.9697035551071167,
      "learning_rate": 1.689156626506024e-05,
      "loss": 1.0823,
      "step": 1290
    },
    {
      "epoch": 0.31321527526804,
      "grad_norm": 1.441155195236206,
      "learning_rate": 1.6867469879518076e-05,
      "loss": 1.1119,
      "step": 1300
    },
    {
      "epoch": 0.3156246235393326,
      "grad_norm": 1.1216671466827393,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 1.0895,
      "step": 1310
    },
    {
      "epoch": 0.3180339718106252,
      "grad_norm": 1.2504795789718628,
      "learning_rate": 1.6819277108433736e-05,
      "loss": 1.0666,
      "step": 1320
    },
    {
      "epoch": 0.32044332008191784,
      "grad_norm": 1.215458631515503,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 1.0117,
      "step": 1330
    },
    {
      "epoch": 0.32285266835321047,
      "grad_norm": 1.1242430210113525,
      "learning_rate": 1.67710843373494e-05,
      "loss": 1.0601,
      "step": 1340
    },
    {
      "epoch": 0.32526201662450305,
      "grad_norm": 1.2556761503219604,
      "learning_rate": 1.6746987951807228e-05,
      "loss": 1.104,
      "step": 1350
    },
    {
      "epoch": 0.3276713648957957,
      "grad_norm": 1.4223101139068604,
      "learning_rate": 1.6722891566265063e-05,
      "loss": 1.1194,
      "step": 1360
    },
    {
      "epoch": 0.3300807131670883,
      "grad_norm": 1.152877688407898,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 1.0421,
      "step": 1370
    },
    {
      "epoch": 0.3324900614383809,
      "grad_norm": 1.2185235023498535,
      "learning_rate": 1.6674698795180724e-05,
      "loss": 1.0268,
      "step": 1380
    },
    {
      "epoch": 0.3348994097096735,
      "grad_norm": 0.9038862586021423,
      "learning_rate": 1.6650602409638555e-05,
      "loss": 1.0213,
      "step": 1390
    },
    {
      "epoch": 0.33730875798096616,
      "grad_norm": 1.1122385263442993,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 1.1151,
      "step": 1400
    },
    {
      "epoch": 0.3397181062522588,
      "grad_norm": 1.0499073266983032,
      "learning_rate": 1.660240963855422e-05,
      "loss": 1.1202,
      "step": 1410
    },
    {
      "epoch": 0.34212745452355137,
      "grad_norm": 0.9883080720901489,
      "learning_rate": 1.657831325301205e-05,
      "loss": 1.149,
      "step": 1420
    },
    {
      "epoch": 0.344536802794844,
      "grad_norm": 1.0373371839523315,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 1.0361,
      "step": 1430
    },
    {
      "epoch": 0.34694615106613663,
      "grad_norm": 1.0946201086044312,
      "learning_rate": 1.653012048192771e-05,
      "loss": 1.1298,
      "step": 1440
    },
    {
      "epoch": 0.3493554993374292,
      "grad_norm": 1.4634495973587036,
      "learning_rate": 1.6506024096385546e-05,
      "loss": 1.0738,
      "step": 1450
    },
    {
      "epoch": 0.35176484760872184,
      "grad_norm": 1.4212238788604736,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 1.0513,
      "step": 1460
    },
    {
      "epoch": 0.3541741958800145,
      "grad_norm": 1.2430468797683716,
      "learning_rate": 1.6457831325301206e-05,
      "loss": 1.1211,
      "step": 1470
    },
    {
      "epoch": 0.35658354415130705,
      "grad_norm": 1.1858296394348145,
      "learning_rate": 1.6433734939759038e-05,
      "loss": 1.0632,
      "step": 1480
    },
    {
      "epoch": 0.3589928924225997,
      "grad_norm": 1.1231003999710083,
      "learning_rate": 1.640963855421687e-05,
      "loss": 1.068,
      "step": 1490
    },
    {
      "epoch": 0.3614022406938923,
      "grad_norm": 1.1776082515716553,
      "learning_rate": 1.63855421686747e-05,
      "loss": 1.0986,
      "step": 1500
    },
    {
      "epoch": 0.3638115889651849,
      "grad_norm": 1.2597529888153076,
      "learning_rate": 1.6361445783132533e-05,
      "loss": 1.0594,
      "step": 1510
    },
    {
      "epoch": 0.36622093723647753,
      "grad_norm": 1.4013510942459106,
      "learning_rate": 1.633734939759036e-05,
      "loss": 1.0753,
      "step": 1520
    },
    {
      "epoch": 0.36863028550777016,
      "grad_norm": 1.5053846836090088,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 1.1273,
      "step": 1530
    },
    {
      "epoch": 0.37103963377906274,
      "grad_norm": 1.7068979740142822,
      "learning_rate": 1.6289156626506025e-05,
      "loss": 1.0746,
      "step": 1540
    },
    {
      "epoch": 0.37344898205035537,
      "grad_norm": 0.8963245153427124,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 1.081,
      "step": 1550
    },
    {
      "epoch": 0.375858330321648,
      "grad_norm": 1.1075621843338013,
      "learning_rate": 1.624096385542169e-05,
      "loss": 1.0551,
      "step": 1560
    },
    {
      "epoch": 0.37826767859294064,
      "grad_norm": 1.031105637550354,
      "learning_rate": 1.621686746987952e-05,
      "loss": 1.0516,
      "step": 1570
    },
    {
      "epoch": 0.3806770268642332,
      "grad_norm": 1.1258034706115723,
      "learning_rate": 1.6192771084337352e-05,
      "loss": 1.1055,
      "step": 1580
    },
    {
      "epoch": 0.38308637513552585,
      "grad_norm": 1.2334988117218018,
      "learning_rate": 1.616867469879518e-05,
      "loss": 1.0587,
      "step": 1590
    },
    {
      "epoch": 0.3854957234068185,
      "grad_norm": 1.3382277488708496,
      "learning_rate": 1.6144578313253015e-05,
      "loss": 1.0332,
      "step": 1600
    },
    {
      "epoch": 0.38790507167811106,
      "grad_norm": 1.3910061120986938,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 1.0908,
      "step": 1610
    },
    {
      "epoch": 0.3903144199494037,
      "grad_norm": 1.2842658758163452,
      "learning_rate": 1.6096385542168676e-05,
      "loss": 1.078,
      "step": 1620
    },
    {
      "epoch": 0.3927237682206963,
      "grad_norm": 1.0779305696487427,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 1.0808,
      "step": 1630
    },
    {
      "epoch": 0.3951331164919889,
      "grad_norm": 0.9903162717819214,
      "learning_rate": 1.604819277108434e-05,
      "loss": 1.0786,
      "step": 1640
    },
    {
      "epoch": 0.39754246476328153,
      "grad_norm": 1.1745253801345825,
      "learning_rate": 1.602409638554217e-05,
      "loss": 1.06,
      "step": 1650
    },
    {
      "epoch": 0.39995181303457417,
      "grad_norm": 1.6953026056289673,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.1084,
      "step": 1660
    },
    {
      "epoch": 0.40236116130586674,
      "grad_norm": 1.335349440574646,
      "learning_rate": 1.5975903614457834e-05,
      "loss": 1.1376,
      "step": 1670
    },
    {
      "epoch": 0.4047705095771594,
      "grad_norm": 1.2389662265777588,
      "learning_rate": 1.5951807228915663e-05,
      "loss": 1.1472,
      "step": 1680
    },
    {
      "epoch": 0.407179857848452,
      "grad_norm": 1.0639702081680298,
      "learning_rate": 1.5927710843373495e-05,
      "loss": 0.9974,
      "step": 1690
    },
    {
      "epoch": 0.4095892061197446,
      "grad_norm": 1.2282291650772095,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 1.0403,
      "step": 1700
    },
    {
      "epoch": 0.4119985543910372,
      "grad_norm": 1.1119418144226074,
      "learning_rate": 1.5879518072289158e-05,
      "loss": 1.0711,
      "step": 1710
    },
    {
      "epoch": 0.41440790266232985,
      "grad_norm": 1.1571497917175293,
      "learning_rate": 1.585542168674699e-05,
      "loss": 1.0832,
      "step": 1720
    },
    {
      "epoch": 0.41681725093362243,
      "grad_norm": 1.1613320112228394,
      "learning_rate": 1.583132530120482e-05,
      "loss": 1.027,
      "step": 1730
    },
    {
      "epoch": 0.41922659920491506,
      "grad_norm": 1.0155863761901855,
      "learning_rate": 1.580722891566265e-05,
      "loss": 1.1016,
      "step": 1740
    },
    {
      "epoch": 0.4216359474762077,
      "grad_norm": 0.9931156039237976,
      "learning_rate": 1.5783132530120485e-05,
      "loss": 1.0626,
      "step": 1750
    },
    {
      "epoch": 0.42404529574750033,
      "grad_norm": 1.1504886150360107,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 1.0641,
      "step": 1760
    },
    {
      "epoch": 0.4264546440187929,
      "grad_norm": 1.5071449279785156,
      "learning_rate": 1.5734939759036145e-05,
      "loss": 1.0806,
      "step": 1770
    },
    {
      "epoch": 0.42886399229008554,
      "grad_norm": 1.265903353691101,
      "learning_rate": 1.5710843373493977e-05,
      "loss": 1.0893,
      "step": 1780
    },
    {
      "epoch": 0.43127334056137817,
      "grad_norm": 1.0198107957839966,
      "learning_rate": 1.568674698795181e-05,
      "loss": 1.0865,
      "step": 1790
    },
    {
      "epoch": 0.43368268883267075,
      "grad_norm": 1.113592505455017,
      "learning_rate": 1.566265060240964e-05,
      "loss": 1.0681,
      "step": 1800
    },
    {
      "epoch": 0.4360920371039634,
      "grad_norm": 1.6580913066864014,
      "learning_rate": 1.5638554216867472e-05,
      "loss": 1.0414,
      "step": 1810
    },
    {
      "epoch": 0.438501385375256,
      "grad_norm": 1.0688860416412354,
      "learning_rate": 1.5614457831325304e-05,
      "loss": 1.0612,
      "step": 1820
    },
    {
      "epoch": 0.4409107336465486,
      "grad_norm": 1.3284944295883179,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 1.0451,
      "step": 1830
    },
    {
      "epoch": 0.4433200819178412,
      "grad_norm": 0.839960515499115,
      "learning_rate": 1.5566265060240968e-05,
      "loss": 1.0582,
      "step": 1840
    },
    {
      "epoch": 0.44572943018913386,
      "grad_norm": 1.3038252592086792,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 1.0517,
      "step": 1850
    },
    {
      "epoch": 0.44813877846042643,
      "grad_norm": 1.11463463306427,
      "learning_rate": 1.5518072289156628e-05,
      "loss": 1.1307,
      "step": 1860
    },
    {
      "epoch": 0.45054812673171907,
      "grad_norm": 0.855150043964386,
      "learning_rate": 1.549397590361446e-05,
      "loss": 1.0839,
      "step": 1870
    },
    {
      "epoch": 0.4529574750030117,
      "grad_norm": 1.1594421863555908,
      "learning_rate": 1.546987951807229e-05,
      "loss": 1.0713,
      "step": 1880
    },
    {
      "epoch": 0.4553668232743043,
      "grad_norm": 1.330134630203247,
      "learning_rate": 1.544578313253012e-05,
      "loss": 1.0649,
      "step": 1890
    },
    {
      "epoch": 0.4577761715455969,
      "grad_norm": 1.06305730342865,
      "learning_rate": 1.5421686746987955e-05,
      "loss": 1.0483,
      "step": 1900
    },
    {
      "epoch": 0.46018551981688954,
      "grad_norm": 0.9369847178459167,
      "learning_rate": 1.5397590361445783e-05,
      "loss": 1.0699,
      "step": 1910
    },
    {
      "epoch": 0.4625948680881821,
      "grad_norm": 1.2702045440673828,
      "learning_rate": 1.5373493975903615e-05,
      "loss": 1.0572,
      "step": 1920
    },
    {
      "epoch": 0.46500421635947475,
      "grad_norm": 1.3986862897872925,
      "learning_rate": 1.5349397590361447e-05,
      "loss": 1.0402,
      "step": 1930
    },
    {
      "epoch": 0.4674135646307674,
      "grad_norm": 1.3780869245529175,
      "learning_rate": 1.532530120481928e-05,
      "loss": 1.0536,
      "step": 1940
    },
    {
      "epoch": 0.46982291290206,
      "grad_norm": 1.221693515777588,
      "learning_rate": 1.530120481927711e-05,
      "loss": 1.0908,
      "step": 1950
    },
    {
      "epoch": 0.4722322611733526,
      "grad_norm": 1.2705472707748413,
      "learning_rate": 1.5277108433734942e-05,
      "loss": 1.0003,
      "step": 1960
    },
    {
      "epoch": 0.47464160944464523,
      "grad_norm": 1.334762454032898,
      "learning_rate": 1.5253012048192772e-05,
      "loss": 1.1169,
      "step": 1970
    },
    {
      "epoch": 0.47705095771593786,
      "grad_norm": 1.1182944774627686,
      "learning_rate": 1.5228915662650604e-05,
      "loss": 1.124,
      "step": 1980
    },
    {
      "epoch": 0.47946030598723044,
      "grad_norm": 1.0123708248138428,
      "learning_rate": 1.5204819277108436e-05,
      "loss": 1.0587,
      "step": 1990
    },
    {
      "epoch": 0.4818696542585231,
      "grad_norm": 1.2366900444030762,
      "learning_rate": 1.5180722891566266e-05,
      "loss": 1.1041,
      "step": 2000
    },
    {
      "epoch": 0.4842790025298157,
      "grad_norm": 1.3598756790161133,
      "learning_rate": 1.5156626506024097e-05,
      "loss": 1.1114,
      "step": 2010
    },
    {
      "epoch": 0.4866883508011083,
      "grad_norm": 1.2292919158935547,
      "learning_rate": 1.5132530120481929e-05,
      "loss": 1.0683,
      "step": 2020
    },
    {
      "epoch": 0.4890976990724009,
      "grad_norm": 1.0397437810897827,
      "learning_rate": 1.5108433734939761e-05,
      "loss": 1.0908,
      "step": 2030
    },
    {
      "epoch": 0.49150704734369355,
      "grad_norm": 0.9707269072532654,
      "learning_rate": 1.5084337349397591e-05,
      "loss": 1.083,
      "step": 2040
    },
    {
      "epoch": 0.4939163956149861,
      "grad_norm": 1.0097709894180298,
      "learning_rate": 1.5060240963855424e-05,
      "loss": 1.1004,
      "step": 2050
    },
    {
      "epoch": 0.49632574388627876,
      "grad_norm": 0.8619704246520996,
      "learning_rate": 1.5036144578313254e-05,
      "loss": 1.0626,
      "step": 2060
    },
    {
      "epoch": 0.4987350921575714,
      "grad_norm": 0.9398052096366882,
      "learning_rate": 1.5012048192771084e-05,
      "loss": 1.0358,
      "step": 2070
    },
    {
      "epoch": 0.501144440428864,
      "grad_norm": 0.999670147895813,
      "learning_rate": 1.4987951807228918e-05,
      "loss": 1.0727,
      "step": 2080
    },
    {
      "epoch": 0.5035537887001567,
      "grad_norm": 0.9021243453025818,
      "learning_rate": 1.4963855421686748e-05,
      "loss": 1.1204,
      "step": 2090
    },
    {
      "epoch": 0.5059631369714492,
      "grad_norm": 1.0702189207077026,
      "learning_rate": 1.4939759036144578e-05,
      "loss": 1.0658,
      "step": 2100
    },
    {
      "epoch": 0.5083724852427418,
      "grad_norm": 1.3299261331558228,
      "learning_rate": 1.4915662650602412e-05,
      "loss": 1.0974,
      "step": 2110
    },
    {
      "epoch": 0.5107818335140345,
      "grad_norm": 1.5902736186981201,
      "learning_rate": 1.4891566265060242e-05,
      "loss": 1.056,
      "step": 2120
    },
    {
      "epoch": 0.5131911817853271,
      "grad_norm": 1.2101598978042603,
      "learning_rate": 1.4867469879518073e-05,
      "loss": 1.076,
      "step": 2130
    },
    {
      "epoch": 0.5156005300566197,
      "grad_norm": 0.9019172191619873,
      "learning_rate": 1.4843373493975905e-05,
      "loss": 1.047,
      "step": 2140
    },
    {
      "epoch": 0.5180098783279123,
      "grad_norm": 1.2587299346923828,
      "learning_rate": 1.4819277108433737e-05,
      "loss": 1.0339,
      "step": 2150
    },
    {
      "epoch": 0.5204192265992049,
      "grad_norm": 1.414908528327942,
      "learning_rate": 1.4795180722891567e-05,
      "loss": 0.9735,
      "step": 2160
    },
    {
      "epoch": 0.5228285748704975,
      "grad_norm": 1.0074955224990845,
      "learning_rate": 1.4771084337349399e-05,
      "loss": 1.0739,
      "step": 2170
    },
    {
      "epoch": 0.5252379231417902,
      "grad_norm": 1.0749152898788452,
      "learning_rate": 1.474698795180723e-05,
      "loss": 1.0479,
      "step": 2180
    },
    {
      "epoch": 0.5276472714130828,
      "grad_norm": 1.0188252925872803,
      "learning_rate": 1.472289156626506e-05,
      "loss": 1.0338,
      "step": 2190
    },
    {
      "epoch": 0.5300566196843753,
      "grad_norm": 1.1681623458862305,
      "learning_rate": 1.4698795180722894e-05,
      "loss": 1.0413,
      "step": 2200
    },
    {
      "epoch": 0.532465967955668,
      "grad_norm": 0.9779105186462402,
      "learning_rate": 1.4674698795180724e-05,
      "loss": 1.0406,
      "step": 2210
    },
    {
      "epoch": 0.5348753162269606,
      "grad_norm": 1.2096105813980103,
      "learning_rate": 1.4650602409638554e-05,
      "loss": 1.0462,
      "step": 2220
    },
    {
      "epoch": 0.5372846644982532,
      "grad_norm": 1.0210509300231934,
      "learning_rate": 1.4626506024096388e-05,
      "loss": 1.0499,
      "step": 2230
    },
    {
      "epoch": 0.5396940127695459,
      "grad_norm": 1.3432542085647583,
      "learning_rate": 1.4602409638554218e-05,
      "loss": 1.1101,
      "step": 2240
    },
    {
      "epoch": 0.5421033610408384,
      "grad_norm": 1.0124446153640747,
      "learning_rate": 1.457831325301205e-05,
      "loss": 1.0419,
      "step": 2250
    },
    {
      "epoch": 0.544512709312131,
      "grad_norm": 1.2406734228134155,
      "learning_rate": 1.4554216867469881e-05,
      "loss": 1.0929,
      "step": 2260
    },
    {
      "epoch": 0.5469220575834237,
      "grad_norm": 0.8891276717185974,
      "learning_rate": 1.4530120481927711e-05,
      "loss": 1.0638,
      "step": 2270
    },
    {
      "epoch": 0.5493314058547163,
      "grad_norm": 1.2486990690231323,
      "learning_rate": 1.4506024096385543e-05,
      "loss": 1.0809,
      "step": 2280
    },
    {
      "epoch": 0.5517407541260089,
      "grad_norm": 0.8601590991020203,
      "learning_rate": 1.4481927710843375e-05,
      "loss": 1.0605,
      "step": 2290
    },
    {
      "epoch": 0.5541501023973016,
      "grad_norm": 1.3612877130508423,
      "learning_rate": 1.4457831325301207e-05,
      "loss": 1.0705,
      "step": 2300
    },
    {
      "epoch": 0.5565594506685941,
      "grad_norm": 0.8703863620758057,
      "learning_rate": 1.4433734939759037e-05,
      "loss": 1.0845,
      "step": 2310
    },
    {
      "epoch": 0.5589687989398867,
      "grad_norm": 0.9585620164871216,
      "learning_rate": 1.440963855421687e-05,
      "loss": 1.1002,
      "step": 2320
    },
    {
      "epoch": 0.5613781472111794,
      "grad_norm": 0.8924010992050171,
      "learning_rate": 1.43855421686747e-05,
      "loss": 1.0389,
      "step": 2330
    },
    {
      "epoch": 0.563787495482472,
      "grad_norm": 1.129115104675293,
      "learning_rate": 1.436144578313253e-05,
      "loss": 1.1063,
      "step": 2340
    },
    {
      "epoch": 0.5661968437537646,
      "grad_norm": 1.2618082761764526,
      "learning_rate": 1.4337349397590364e-05,
      "loss": 1.0446,
      "step": 2350
    },
    {
      "epoch": 0.5686061920250572,
      "grad_norm": 1.1265227794647217,
      "learning_rate": 1.4313253012048194e-05,
      "loss": 1.042,
      "step": 2360
    },
    {
      "epoch": 0.5710155402963498,
      "grad_norm": 1.0009351968765259,
      "learning_rate": 1.4289156626506024e-05,
      "loss": 1.064,
      "step": 2370
    },
    {
      "epoch": 0.5734248885676424,
      "grad_norm": 1.2457886934280396,
      "learning_rate": 1.4265060240963857e-05,
      "loss": 1.1046,
      "step": 2380
    },
    {
      "epoch": 0.5758342368389351,
      "grad_norm": 0.9788379073143005,
      "learning_rate": 1.4240963855421687e-05,
      "loss": 1.0398,
      "step": 2390
    },
    {
      "epoch": 0.5782435851102277,
      "grad_norm": 1.2211261987686157,
      "learning_rate": 1.4216867469879519e-05,
      "loss": 1.1018,
      "step": 2400
    },
    {
      "epoch": 0.5806529333815204,
      "grad_norm": 1.0143029689788818,
      "learning_rate": 1.419277108433735e-05,
      "loss": 1.0974,
      "step": 2410
    },
    {
      "epoch": 0.5830622816528129,
      "grad_norm": 0.994465172290802,
      "learning_rate": 1.4168674698795183e-05,
      "loss": 1.0952,
      "step": 2420
    },
    {
      "epoch": 0.5854716299241055,
      "grad_norm": 1.5943942070007324,
      "learning_rate": 1.4144578313253013e-05,
      "loss": 1.0708,
      "step": 2430
    },
    {
      "epoch": 0.5878809781953982,
      "grad_norm": 1.209542989730835,
      "learning_rate": 1.4120481927710844e-05,
      "loss": 1.0679,
      "step": 2440
    },
    {
      "epoch": 0.5902903264666908,
      "grad_norm": 1.3313206434249878,
      "learning_rate": 1.4096385542168676e-05,
      "loss": 1.0471,
      "step": 2450
    },
    {
      "epoch": 0.5926996747379834,
      "grad_norm": 1.2893224954605103,
      "learning_rate": 1.4072289156626506e-05,
      "loss": 1.0492,
      "step": 2460
    },
    {
      "epoch": 0.595109023009276,
      "grad_norm": 1.2975902557373047,
      "learning_rate": 1.404819277108434e-05,
      "loss": 1.0379,
      "step": 2470
    },
    {
      "epoch": 0.5975183712805686,
      "grad_norm": 1.202708125114441,
      "learning_rate": 1.402409638554217e-05,
      "loss": 1.0899,
      "step": 2480
    },
    {
      "epoch": 0.5999277195518612,
      "grad_norm": 1.3983291387557983,
      "learning_rate": 1.4e-05,
      "loss": 1.0453,
      "step": 2490
    },
    {
      "epoch": 0.6023370678231539,
      "grad_norm": 1.3143515586853027,
      "learning_rate": 1.3975903614457833e-05,
      "loss": 1.0249,
      "step": 2500
    },
    {
      "epoch": 0.6047464160944465,
      "grad_norm": 1.2963542938232422,
      "learning_rate": 1.3951807228915663e-05,
      "loss": 1.0288,
      "step": 2510
    },
    {
      "epoch": 0.607155764365739,
      "grad_norm": 1.537133812904358,
      "learning_rate": 1.3927710843373493e-05,
      "loss": 1.0508,
      "step": 2520
    },
    {
      "epoch": 0.6095651126370317,
      "grad_norm": 1.6918185949325562,
      "learning_rate": 1.3903614457831327e-05,
      "loss": 1.0687,
      "step": 2530
    },
    {
      "epoch": 0.6119744609083243,
      "grad_norm": 1.2960115671157837,
      "learning_rate": 1.3879518072289157e-05,
      "loss": 1.0372,
      "step": 2540
    },
    {
      "epoch": 0.6143838091796169,
      "grad_norm": 0.9670565128326416,
      "learning_rate": 1.3855421686746989e-05,
      "loss": 1.0349,
      "step": 2550
    },
    {
      "epoch": 0.6167931574509096,
      "grad_norm": 1.0521252155303955,
      "learning_rate": 1.383132530120482e-05,
      "loss": 0.9855,
      "step": 2560
    },
    {
      "epoch": 0.6192025057222021,
      "grad_norm": 1.2695661783218384,
      "learning_rate": 1.3807228915662652e-05,
      "loss": 1.0898,
      "step": 2570
    },
    {
      "epoch": 0.6216118539934947,
      "grad_norm": 1.3540352582931519,
      "learning_rate": 1.3783132530120482e-05,
      "loss": 1.0259,
      "step": 2580
    },
    {
      "epoch": 0.6240212022647874,
      "grad_norm": 1.3018428087234497,
      "learning_rate": 1.3759036144578316e-05,
      "loss": 1.0639,
      "step": 2590
    },
    {
      "epoch": 0.62643055053608,
      "grad_norm": 1.1728243827819824,
      "learning_rate": 1.3734939759036146e-05,
      "loss": 1.0373,
      "step": 2600
    },
    {
      "epoch": 0.6288398988073726,
      "grad_norm": 0.9277067184448242,
      "learning_rate": 1.3710843373493976e-05,
      "loss": 1.0499,
      "step": 2610
    },
    {
      "epoch": 0.6312492470786653,
      "grad_norm": 1.2825024127960205,
      "learning_rate": 1.368674698795181e-05,
      "loss": 1.0788,
      "step": 2620
    },
    {
      "epoch": 0.6336585953499578,
      "grad_norm": 0.9017518758773804,
      "learning_rate": 1.366265060240964e-05,
      "loss": 1.1115,
      "step": 2630
    },
    {
      "epoch": 0.6360679436212504,
      "grad_norm": 1.4473471641540527,
      "learning_rate": 1.363855421686747e-05,
      "loss": 1.1113,
      "step": 2640
    },
    {
      "epoch": 0.6384772918925431,
      "grad_norm": 1.1152899265289307,
      "learning_rate": 1.3614457831325303e-05,
      "loss": 1.0851,
      "step": 2650
    },
    {
      "epoch": 0.6408866401638357,
      "grad_norm": 1.0814735889434814,
      "learning_rate": 1.3590361445783133e-05,
      "loss": 1.0509,
      "step": 2660
    },
    {
      "epoch": 0.6432959884351283,
      "grad_norm": 1.409906268119812,
      "learning_rate": 1.3566265060240965e-05,
      "loss": 1.0257,
      "step": 2670
    },
    {
      "epoch": 0.6457053367064209,
      "grad_norm": 1.2779557704925537,
      "learning_rate": 1.3542168674698796e-05,
      "loss": 1.0726,
      "step": 2680
    },
    {
      "epoch": 0.6481146849777135,
      "grad_norm": 1.097123622894287,
      "learning_rate": 1.3518072289156628e-05,
      "loss": 1.0741,
      "step": 2690
    },
    {
      "epoch": 0.6505240332490061,
      "grad_norm": 1.271962285041809,
      "learning_rate": 1.3493975903614458e-05,
      "loss": 1.0451,
      "step": 2700
    },
    {
      "epoch": 0.6529333815202988,
      "grad_norm": 1.214073657989502,
      "learning_rate": 1.346987951807229e-05,
      "loss": 1.0413,
      "step": 2710
    },
    {
      "epoch": 0.6553427297915914,
      "grad_norm": 1.2177257537841797,
      "learning_rate": 1.3445783132530122e-05,
      "loss": 1.0567,
      "step": 2720
    },
    {
      "epoch": 0.6577520780628839,
      "grad_norm": 1.894587755203247,
      "learning_rate": 1.3421686746987952e-05,
      "loss": 1.049,
      "step": 2730
    },
    {
      "epoch": 0.6601614263341766,
      "grad_norm": 1.1642674207687378,
      "learning_rate": 1.3397590361445785e-05,
      "loss": 1.092,
      "step": 2740
    },
    {
      "epoch": 0.6625707746054692,
      "grad_norm": 0.8337126970291138,
      "learning_rate": 1.3373493975903615e-05,
      "loss": 1.0895,
      "step": 2750
    },
    {
      "epoch": 0.6649801228767618,
      "grad_norm": 1.0512491464614868,
      "learning_rate": 1.3349397590361445e-05,
      "loss": 1.0807,
      "step": 2760
    },
    {
      "epoch": 0.6673894711480545,
      "grad_norm": 1.3378207683563232,
      "learning_rate": 1.3325301204819279e-05,
      "loss": 1.0537,
      "step": 2770
    },
    {
      "epoch": 0.669798819419347,
      "grad_norm": 1.113577127456665,
      "learning_rate": 1.3301204819277109e-05,
      "loss": 1.0942,
      "step": 2780
    },
    {
      "epoch": 0.6722081676906397,
      "grad_norm": 1.0029550790786743,
      "learning_rate": 1.3277108433734939e-05,
      "loss": 1.0774,
      "step": 2790
    },
    {
      "epoch": 0.6746175159619323,
      "grad_norm": 1.2590173482894897,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 1.1078,
      "step": 2800
    },
    {
      "epoch": 0.6770268642332249,
      "grad_norm": 1.2168339490890503,
      "learning_rate": 1.3228915662650603e-05,
      "loss": 1.0778,
      "step": 2810
    },
    {
      "epoch": 0.6794362125045176,
      "grad_norm": 1.1501671075820923,
      "learning_rate": 1.3204819277108434e-05,
      "loss": 1.0694,
      "step": 2820
    },
    {
      "epoch": 0.6818455607758102,
      "grad_norm": 1.2432115077972412,
      "learning_rate": 1.3180722891566266e-05,
      "loss": 1.0687,
      "step": 2830
    },
    {
      "epoch": 0.6842549090471027,
      "grad_norm": 1.2431529760360718,
      "learning_rate": 1.3156626506024098e-05,
      "loss": 1.0483,
      "step": 2840
    },
    {
      "epoch": 0.6866642573183954,
      "grad_norm": 0.9995725750923157,
      "learning_rate": 1.3132530120481928e-05,
      "loss": 1.0419,
      "step": 2850
    },
    {
      "epoch": 0.689073605589688,
      "grad_norm": 1.0947074890136719,
      "learning_rate": 1.3108433734939761e-05,
      "loss": 1.0355,
      "step": 2860
    },
    {
      "epoch": 0.6914829538609806,
      "grad_norm": 1.3645734786987305,
      "learning_rate": 1.3084337349397591e-05,
      "loss": 1.0357,
      "step": 2870
    },
    {
      "epoch": 0.6938923021322733,
      "grad_norm": 1.0784367322921753,
      "learning_rate": 1.3060240963855421e-05,
      "loss": 1.1065,
      "step": 2880
    },
    {
      "epoch": 0.6963016504035658,
      "grad_norm": 1.451483130455017,
      "learning_rate": 1.3036144578313255e-05,
      "loss": 1.0011,
      "step": 2890
    },
    {
      "epoch": 0.6987109986748584,
      "grad_norm": 1.0335642099380493,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 1.067,
      "step": 2900
    },
    {
      "epoch": 0.7011203469461511,
      "grad_norm": 1.1702817678451538,
      "learning_rate": 1.2987951807228915e-05,
      "loss": 1.0697,
      "step": 2910
    },
    {
      "epoch": 0.7035296952174437,
      "grad_norm": 0.9623212814331055,
      "learning_rate": 1.2963855421686749e-05,
      "loss": 1.1092,
      "step": 2920
    },
    {
      "epoch": 0.7059390434887363,
      "grad_norm": 1.087522029876709,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 1.0789,
      "step": 2930
    },
    {
      "epoch": 0.708348391760029,
      "grad_norm": 1.2138935327529907,
      "learning_rate": 1.291566265060241e-05,
      "loss": 1.0853,
      "step": 2940
    },
    {
      "epoch": 0.7107577400313215,
      "grad_norm": 1.544046401977539,
      "learning_rate": 1.2891566265060242e-05,
      "loss": 1.0577,
      "step": 2950
    },
    {
      "epoch": 0.7131670883026141,
      "grad_norm": 1.8348742723464966,
      "learning_rate": 1.2867469879518072e-05,
      "loss": 1.087,
      "step": 2960
    },
    {
      "epoch": 0.7155764365739068,
      "grad_norm": 1.0549408197402954,
      "learning_rate": 1.2843373493975904e-05,
      "loss": 1.09,
      "step": 2970
    },
    {
      "epoch": 0.7179857848451994,
      "grad_norm": 1.1676640510559082,
      "learning_rate": 1.2819277108433736e-05,
      "loss": 1.0357,
      "step": 2980
    },
    {
      "epoch": 0.720395133116492,
      "grad_norm": 1.3352258205413818,
      "learning_rate": 1.2795180722891567e-05,
      "loss": 1.0715,
      "step": 2990
    },
    {
      "epoch": 0.7228044813877846,
      "grad_norm": 1.313672423362732,
      "learning_rate": 1.2771084337349398e-05,
      "loss": 1.0029,
      "step": 3000
    },
    {
      "epoch": 0.7252138296590772,
      "grad_norm": 1.1628161668777466,
      "learning_rate": 1.2746987951807231e-05,
      "loss": 1.0659,
      "step": 3010
    },
    {
      "epoch": 0.7276231779303698,
      "grad_norm": 1.0737929344177246,
      "learning_rate": 1.2722891566265061e-05,
      "loss": 1.0613,
      "step": 3020
    },
    {
      "epoch": 0.7300325262016625,
      "grad_norm": 1.204840064048767,
      "learning_rate": 1.2698795180722891e-05,
      "loss": 1.0453,
      "step": 3030
    },
    {
      "epoch": 0.7324418744729551,
      "grad_norm": 1.299336314201355,
      "learning_rate": 1.2674698795180725e-05,
      "loss": 1.0287,
      "step": 3040
    },
    {
      "epoch": 0.7348512227442476,
      "grad_norm": 0.9885721802711487,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 1.0569,
      "step": 3050
    },
    {
      "epoch": 0.7372605710155403,
      "grad_norm": 1.3819657564163208,
      "learning_rate": 1.2626506024096385e-05,
      "loss": 1.0805,
      "step": 3060
    },
    {
      "epoch": 0.7396699192868329,
      "grad_norm": 1.2249561548233032,
      "learning_rate": 1.2602409638554218e-05,
      "loss": 1.0686,
      "step": 3070
    },
    {
      "epoch": 0.7420792675581255,
      "grad_norm": 1.2627493143081665,
      "learning_rate": 1.2578313253012048e-05,
      "loss": 1.085,
      "step": 3080
    },
    {
      "epoch": 0.7444886158294182,
      "grad_norm": 1.069544792175293,
      "learning_rate": 1.255421686746988e-05,
      "loss": 1.0922,
      "step": 3090
    },
    {
      "epoch": 0.7468979641007107,
      "grad_norm": 0.8631856441497803,
      "learning_rate": 1.2530120481927712e-05,
      "loss": 1.0083,
      "step": 3100
    },
    {
      "epoch": 0.7493073123720033,
      "grad_norm": 1.3083171844482422,
      "learning_rate": 1.2506024096385544e-05,
      "loss": 1.0681,
      "step": 3110
    },
    {
      "epoch": 0.751716660643296,
      "grad_norm": 1.2350841760635376,
      "learning_rate": 1.2481927710843375e-05,
      "loss": 1.0621,
      "step": 3120
    },
    {
      "epoch": 0.7541260089145886,
      "grad_norm": 1.0158532857894897,
      "learning_rate": 1.2457831325301207e-05,
      "loss": 1.0651,
      "step": 3130
    },
    {
      "epoch": 0.7565353571858813,
      "grad_norm": 1.2366600036621094,
      "learning_rate": 1.2433734939759037e-05,
      "loss": 1.1004,
      "step": 3140
    },
    {
      "epoch": 0.7589447054571739,
      "grad_norm": 1.093170166015625,
      "learning_rate": 1.2409638554216869e-05,
      "loss": 1.0489,
      "step": 3150
    },
    {
      "epoch": 0.7613540537284664,
      "grad_norm": 1.3701095581054688,
      "learning_rate": 1.23855421686747e-05,
      "loss": 1.1068,
      "step": 3160
    },
    {
      "epoch": 0.7637634019997591,
      "grad_norm": 1.1338834762573242,
      "learning_rate": 1.236144578313253e-05,
      "loss": 1.0455,
      "step": 3170
    },
    {
      "epoch": 0.7661727502710517,
      "grad_norm": 0.9023853540420532,
      "learning_rate": 1.2337349397590364e-05,
      "loss": 1.1044,
      "step": 3180
    },
    {
      "epoch": 0.7685820985423443,
      "grad_norm": 1.3887590169906616,
      "learning_rate": 1.2313253012048194e-05,
      "loss": 1.0807,
      "step": 3190
    },
    {
      "epoch": 0.770991446813637,
      "grad_norm": 1.9590461254119873,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 1.0332,
      "step": 3200
    },
    {
      "epoch": 0.7734007950849295,
      "grad_norm": 1.289347529411316,
      "learning_rate": 1.2265060240963858e-05,
      "loss": 1.0749,
      "step": 3210
    },
    {
      "epoch": 0.7758101433562221,
      "grad_norm": 1.2455658912658691,
      "learning_rate": 1.2240963855421688e-05,
      "loss": 1.0745,
      "step": 3220
    },
    {
      "epoch": 0.7782194916275148,
      "grad_norm": 1.415050745010376,
      "learning_rate": 1.2216867469879518e-05,
      "loss": 1.0361,
      "step": 3230
    },
    {
      "epoch": 0.7806288398988074,
      "grad_norm": 1.2445203065872192,
      "learning_rate": 1.2192771084337351e-05,
      "loss": 1.0592,
      "step": 3240
    },
    {
      "epoch": 0.7830381881701,
      "grad_norm": 0.8800524473190308,
      "learning_rate": 1.2168674698795181e-05,
      "loss": 1.0537,
      "step": 3250
    },
    {
      "epoch": 0.7854475364413926,
      "grad_norm": 1.2798070907592773,
      "learning_rate": 1.2144578313253013e-05,
      "loss": 1.0702,
      "step": 3260
    },
    {
      "epoch": 0.7878568847126852,
      "grad_norm": 1.481606125831604,
      "learning_rate": 1.2120481927710845e-05,
      "loss": 1.0465,
      "step": 3270
    },
    {
      "epoch": 0.7902662329839778,
      "grad_norm": 1.0579975843429565,
      "learning_rate": 1.2096385542168677e-05,
      "loss": 1.0809,
      "step": 3280
    },
    {
      "epoch": 0.7926755812552705,
      "grad_norm": 1.3933204412460327,
      "learning_rate": 1.2072289156626507e-05,
      "loss": 1.1084,
      "step": 3290
    },
    {
      "epoch": 0.7950849295265631,
      "grad_norm": 1.2217134237289429,
      "learning_rate": 1.204819277108434e-05,
      "loss": 1.0685,
      "step": 3300
    },
    {
      "epoch": 0.7974942777978556,
      "grad_norm": 1.2321386337280273,
      "learning_rate": 1.202409638554217e-05,
      "loss": 1.0918,
      "step": 3310
    },
    {
      "epoch": 0.7999036260691483,
      "grad_norm": 0.9320940971374512,
      "learning_rate": 1.2e-05,
      "loss": 1.074,
      "step": 3320
    },
    {
      "epoch": 0.8023129743404409,
      "grad_norm": 0.9462363123893738,
      "learning_rate": 1.1975903614457834e-05,
      "loss": 1.0715,
      "step": 3330
    },
    {
      "epoch": 0.8047223226117335,
      "grad_norm": 1.0891231298446655,
      "learning_rate": 1.1951807228915664e-05,
      "loss": 1.0573,
      "step": 3340
    },
    {
      "epoch": 0.8071316708830262,
      "grad_norm": 0.91768479347229,
      "learning_rate": 1.1927710843373494e-05,
      "loss": 1.104,
      "step": 3350
    },
    {
      "epoch": 0.8095410191543188,
      "grad_norm": 1.0414189100265503,
      "learning_rate": 1.1903614457831327e-05,
      "loss": 1.0752,
      "step": 3360
    },
    {
      "epoch": 0.8119503674256113,
      "grad_norm": 1.025572419166565,
      "learning_rate": 1.1879518072289157e-05,
      "loss": 1.0715,
      "step": 3370
    },
    {
      "epoch": 0.814359715696904,
      "grad_norm": 1.4587481021881104,
      "learning_rate": 1.185542168674699e-05,
      "loss": 1.1617,
      "step": 3380
    },
    {
      "epoch": 0.8167690639681966,
      "grad_norm": 1.2988139390945435,
      "learning_rate": 1.1831325301204821e-05,
      "loss": 1.0404,
      "step": 3390
    },
    {
      "epoch": 0.8191784122394892,
      "grad_norm": 1.1185351610183716,
      "learning_rate": 1.1807228915662651e-05,
      "loss": 1.001,
      "step": 3400
    },
    {
      "epoch": 0.8215877605107819,
      "grad_norm": 1.0958516597747803,
      "learning_rate": 1.1783132530120483e-05,
      "loss": 1.0311,
      "step": 3410
    },
    {
      "epoch": 0.8239971087820744,
      "grad_norm": 1.254984736442566,
      "learning_rate": 1.1759036144578315e-05,
      "loss": 1.0793,
      "step": 3420
    },
    {
      "epoch": 0.826406457053367,
      "grad_norm": 1.2261725664138794,
      "learning_rate": 1.1734939759036146e-05,
      "loss": 1.0789,
      "step": 3430
    },
    {
      "epoch": 0.8288158053246597,
      "grad_norm": 1.0799239873886108,
      "learning_rate": 1.1710843373493976e-05,
      "loss": 1.0468,
      "step": 3440
    },
    {
      "epoch": 0.8312251535959523,
      "grad_norm": 1.2760955095291138,
      "learning_rate": 1.168674698795181e-05,
      "loss": 1.0718,
      "step": 3450
    },
    {
      "epoch": 0.8336345018672449,
      "grad_norm": 1.1932228803634644,
      "learning_rate": 1.166265060240964e-05,
      "loss": 1.0406,
      "step": 3460
    },
    {
      "epoch": 0.8360438501385375,
      "grad_norm": 1.2222548723220825,
      "learning_rate": 1.163855421686747e-05,
      "loss": 1.0496,
      "step": 3470
    },
    {
      "epoch": 0.8384531984098301,
      "grad_norm": 1.102812647819519,
      "learning_rate": 1.1614457831325303e-05,
      "loss": 1.1028,
      "step": 3480
    },
    {
      "epoch": 0.8408625466811227,
      "grad_norm": 1.0112932920455933,
      "learning_rate": 1.1590361445783133e-05,
      "loss": 1.0418,
      "step": 3490
    },
    {
      "epoch": 0.8432718949524154,
      "grad_norm": 1.6207104921340942,
      "learning_rate": 1.1566265060240964e-05,
      "loss": 1.0639,
      "step": 3500
    },
    {
      "epoch": 0.845681243223708,
      "grad_norm": 0.9575868844985962,
      "learning_rate": 1.1542168674698797e-05,
      "loss": 1.0753,
      "step": 3510
    },
    {
      "epoch": 0.8480905914950007,
      "grad_norm": 1.104003667831421,
      "learning_rate": 1.1518072289156627e-05,
      "loss": 1.0661,
      "step": 3520
    },
    {
      "epoch": 0.8504999397662932,
      "grad_norm": 1.3745124340057373,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 1.0822,
      "step": 3530
    },
    {
      "epoch": 0.8529092880375858,
      "grad_norm": 1.2038781642913818,
      "learning_rate": 1.146987951807229e-05,
      "loss": 1.0645,
      "step": 3540
    },
    {
      "epoch": 0.8553186363088785,
      "grad_norm": 1.093827724456787,
      "learning_rate": 1.1445783132530122e-05,
      "loss": 1.078,
      "step": 3550
    },
    {
      "epoch": 0.8577279845801711,
      "grad_norm": 1.1275607347488403,
      "learning_rate": 1.1421686746987952e-05,
      "loss": 1.056,
      "step": 3560
    },
    {
      "epoch": 0.8601373328514637,
      "grad_norm": 1.022834062576294,
      "learning_rate": 1.1397590361445786e-05,
      "loss": 1.0824,
      "step": 3570
    },
    {
      "epoch": 0.8625466811227563,
      "grad_norm": 0.9430524110794067,
      "learning_rate": 1.1373493975903616e-05,
      "loss": 1.0738,
      "step": 3580
    },
    {
      "epoch": 0.8649560293940489,
      "grad_norm": 1.0582646131515503,
      "learning_rate": 1.1349397590361446e-05,
      "loss": 1.0982,
      "step": 3590
    },
    {
      "epoch": 0.8673653776653415,
      "grad_norm": 1.2372702360153198,
      "learning_rate": 1.132530120481928e-05,
      "loss": 1.0851,
      "step": 3600
    },
    {
      "epoch": 0.8697747259366342,
      "grad_norm": 1.423063039779663,
      "learning_rate": 1.130120481927711e-05,
      "loss": 1.09,
      "step": 3610
    },
    {
      "epoch": 0.8721840742079268,
      "grad_norm": 1.4239047765731812,
      "learning_rate": 1.127710843373494e-05,
      "loss": 1.0613,
      "step": 3620
    },
    {
      "epoch": 0.8745934224792193,
      "grad_norm": 0.9529085755348206,
      "learning_rate": 1.1253012048192773e-05,
      "loss": 1.0512,
      "step": 3630
    },
    {
      "epoch": 0.877002770750512,
      "grad_norm": 1.2654656171798706,
      "learning_rate": 1.1228915662650603e-05,
      "loss": 1.1182,
      "step": 3640
    },
    {
      "epoch": 0.8794121190218046,
      "grad_norm": 1.4972842931747437,
      "learning_rate": 1.1204819277108435e-05,
      "loss": 1.048,
      "step": 3650
    },
    {
      "epoch": 0.8818214672930972,
      "grad_norm": 0.9709852933883667,
      "learning_rate": 1.1180722891566267e-05,
      "loss": 1.0554,
      "step": 3660
    },
    {
      "epoch": 0.8842308155643899,
      "grad_norm": 1.2554410696029663,
      "learning_rate": 1.1156626506024097e-05,
      "loss": 1.0678,
      "step": 3670
    },
    {
      "epoch": 0.8866401638356824,
      "grad_norm": 0.9628530740737915,
      "learning_rate": 1.1132530120481928e-05,
      "loss": 1.1404,
      "step": 3680
    },
    {
      "epoch": 0.889049512106975,
      "grad_norm": 1.095138430595398,
      "learning_rate": 1.110843373493976e-05,
      "loss": 1.0482,
      "step": 3690
    },
    {
      "epoch": 0.8914588603782677,
      "grad_norm": 1.1658117771148682,
      "learning_rate": 1.1084337349397592e-05,
      "loss": 1.1017,
      "step": 3700
    },
    {
      "epoch": 0.8938682086495603,
      "grad_norm": 1.3945298194885254,
      "learning_rate": 1.1060240963855422e-05,
      "loss": 1.0595,
      "step": 3710
    },
    {
      "epoch": 0.8962775569208529,
      "grad_norm": 1.4431962966918945,
      "learning_rate": 1.1036144578313255e-05,
      "loss": 0.9944,
      "step": 3720
    },
    {
      "epoch": 0.8986869051921456,
      "grad_norm": 1.2830113172531128,
      "learning_rate": 1.1012048192771086e-05,
      "loss": 1.0284,
      "step": 3730
    },
    {
      "epoch": 0.9010962534634381,
      "grad_norm": 1.4337266683578491,
      "learning_rate": 1.0987951807228916e-05,
      "loss": 1.0663,
      "step": 3740
    },
    {
      "epoch": 0.9035056017347307,
      "grad_norm": 1.470160961151123,
      "learning_rate": 1.0963855421686749e-05,
      "loss": 1.118,
      "step": 3750
    },
    {
      "epoch": 0.9059149500060234,
      "grad_norm": 1.8030811548233032,
      "learning_rate": 1.0939759036144579e-05,
      "loss": 1.0286,
      "step": 3760
    },
    {
      "epoch": 0.908324298277316,
      "grad_norm": 1.500046968460083,
      "learning_rate": 1.091566265060241e-05,
      "loss": 1.0757,
      "step": 3770
    },
    {
      "epoch": 0.9107336465486086,
      "grad_norm": 1.3380200862884521,
      "learning_rate": 1.0891566265060243e-05,
      "loss": 1.0968,
      "step": 3780
    },
    {
      "epoch": 0.9131429948199012,
      "grad_norm": 1.097645878791809,
      "learning_rate": 1.0867469879518073e-05,
      "loss": 1.0706,
      "step": 3790
    },
    {
      "epoch": 0.9155523430911938,
      "grad_norm": 1.4178792238235474,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 1.0399,
      "step": 3800
    },
    {
      "epoch": 0.9179616913624864,
      "grad_norm": 1.1937217712402344,
      "learning_rate": 1.0819277108433736e-05,
      "loss": 1.0655,
      "step": 3810
    },
    {
      "epoch": 0.9203710396337791,
      "grad_norm": 0.9505431652069092,
      "learning_rate": 1.0795180722891568e-05,
      "loss": 1.0231,
      "step": 3820
    },
    {
      "epoch": 0.9227803879050717,
      "grad_norm": 1.264988899230957,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 1.03,
      "step": 3830
    },
    {
      "epoch": 0.9251897361763642,
      "grad_norm": 0.8678158521652222,
      "learning_rate": 1.074698795180723e-05,
      "loss": 1.0069,
      "step": 3840
    },
    {
      "epoch": 0.9275990844476569,
      "grad_norm": 1.2234654426574707,
      "learning_rate": 1.0722891566265062e-05,
      "loss": 1.062,
      "step": 3850
    },
    {
      "epoch": 0.9300084327189495,
      "grad_norm": 1.4451696872711182,
      "learning_rate": 1.0698795180722892e-05,
      "loss": 1.0679,
      "step": 3860
    },
    {
      "epoch": 0.9324177809902421,
      "grad_norm": 1.623793125152588,
      "learning_rate": 1.0674698795180725e-05,
      "loss": 1.1061,
      "step": 3870
    },
    {
      "epoch": 0.9348271292615348,
      "grad_norm": 1.0387338399887085,
      "learning_rate": 1.0650602409638555e-05,
      "loss": 1.0448,
      "step": 3880
    },
    {
      "epoch": 0.9372364775328274,
      "grad_norm": 1.1788618564605713,
      "learning_rate": 1.0626506024096385e-05,
      "loss": 1.106,
      "step": 3890
    },
    {
      "epoch": 0.93964582580412,
      "grad_norm": 1.0842303037643433,
      "learning_rate": 1.0602409638554219e-05,
      "loss": 1.0207,
      "step": 3900
    },
    {
      "epoch": 0.9420551740754126,
      "grad_norm": 1.2815858125686646,
      "learning_rate": 1.0578313253012049e-05,
      "loss": 1.0542,
      "step": 3910
    },
    {
      "epoch": 0.9444645223467052,
      "grad_norm": 1.1277310848236084,
      "learning_rate": 1.055421686746988e-05,
      "loss": 1.0805,
      "step": 3920
    },
    {
      "epoch": 0.9468738706179979,
      "grad_norm": 1.0634822845458984,
      "learning_rate": 1.0530120481927712e-05,
      "loss": 1.0862,
      "step": 3930
    },
    {
      "epoch": 0.9492832188892905,
      "grad_norm": 1.0224390029907227,
      "learning_rate": 1.0506024096385542e-05,
      "loss": 1.0936,
      "step": 3940
    },
    {
      "epoch": 0.951692567160583,
      "grad_norm": 0.9791370630264282,
      "learning_rate": 1.0481927710843374e-05,
      "loss": 1.0781,
      "step": 3950
    },
    {
      "epoch": 0.9541019154318757,
      "grad_norm": 1.2072722911834717,
      "learning_rate": 1.0457831325301206e-05,
      "loss": 1.0552,
      "step": 3960
    },
    {
      "epoch": 0.9565112637031683,
      "grad_norm": 0.9098756909370422,
      "learning_rate": 1.0433734939759038e-05,
      "loss": 1.0542,
      "step": 3970
    },
    {
      "epoch": 0.9589206119744609,
      "grad_norm": 1.6675397157669067,
      "learning_rate": 1.0409638554216868e-05,
      "loss": 1.0479,
      "step": 3980
    },
    {
      "epoch": 0.9613299602457536,
      "grad_norm": 1.298235297203064,
      "learning_rate": 1.0385542168674701e-05,
      "loss": 1.0616,
      "step": 3990
    },
    {
      "epoch": 0.9637393085170461,
      "grad_norm": 1.1132138967514038,
      "learning_rate": 1.0361445783132531e-05,
      "loss": 1.0037,
      "step": 4000
    },
    {
      "epoch": 0.9661486567883387,
      "grad_norm": 0.9633668065071106,
      "learning_rate": 1.0337349397590361e-05,
      "loss": 1.0344,
      "step": 4010
    },
    {
      "epoch": 0.9685580050596314,
      "grad_norm": 1.0440102815628052,
      "learning_rate": 1.0313253012048195e-05,
      "loss": 1.0683,
      "step": 4020
    },
    {
      "epoch": 0.970967353330924,
      "grad_norm": 0.9898460507392883,
      "learning_rate": 1.0289156626506025e-05,
      "loss": 1.0255,
      "step": 4030
    },
    {
      "epoch": 0.9733767016022166,
      "grad_norm": 1.1561310291290283,
      "learning_rate": 1.0265060240963855e-05,
      "loss": 1.0466,
      "step": 4040
    },
    {
      "epoch": 0.9757860498735093,
      "grad_norm": 0.8030654788017273,
      "learning_rate": 1.0240963855421688e-05,
      "loss": 1.0045,
      "step": 4050
    },
    {
      "epoch": 0.9781953981448018,
      "grad_norm": 1.551672101020813,
      "learning_rate": 1.0216867469879518e-05,
      "loss": 1.0599,
      "step": 4060
    },
    {
      "epoch": 0.9806047464160944,
      "grad_norm": 1.2245995998382568,
      "learning_rate": 1.019277108433735e-05,
      "loss": 1.1141,
      "step": 4070
    },
    {
      "epoch": 0.9830140946873871,
      "grad_norm": 1.0136462450027466,
      "learning_rate": 1.0168674698795182e-05,
      "loss": 1.0733,
      "step": 4080
    },
    {
      "epoch": 0.9854234429586797,
      "grad_norm": 1.4626801013946533,
      "learning_rate": 1.0144578313253014e-05,
      "loss": 1.025,
      "step": 4090
    },
    {
      "epoch": 0.9878327912299723,
      "grad_norm": 1.2209069728851318,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 1.0438,
      "step": 4100
    },
    {
      "epoch": 0.9902421395012649,
      "grad_norm": 1.2005772590637207,
      "learning_rate": 1.0096385542168675e-05,
      "loss": 1.0717,
      "step": 4110
    },
    {
      "epoch": 0.9926514877725575,
      "grad_norm": 1.1214889287948608,
      "learning_rate": 1.0072289156626507e-05,
      "loss": 1.1057,
      "step": 4120
    },
    {
      "epoch": 0.9950608360438501,
      "grad_norm": 1.422575831413269,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 1.0323,
      "step": 4130
    },
    {
      "epoch": 0.9974701843151428,
      "grad_norm": 1.4101718664169312,
      "learning_rate": 1.002409638554217e-05,
      "loss": 1.0825,
      "step": 4140
    },
    {
      "epoch": 0.9998795325864354,
      "grad_norm": 1.0636157989501953,
      "learning_rate": 1e-05,
      "loss": 1.0537,
      "step": 4150
    }
  ],
  "logging_steps": 10,
  "max_steps": 8300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.92260687120302e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
