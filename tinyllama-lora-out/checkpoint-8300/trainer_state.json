{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.999638597759306,
  "eval_steps": 500,
  "global_step": 8300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0024093482712926155,
      "grad_norm": 0.778272807598114,
      "learning_rate": 1.9975903614457833e-05,
      "loss": 1.7877,
      "step": 10
    },
    {
      "epoch": 0.004818696542585231,
      "grad_norm": 0.7076205611228943,
      "learning_rate": 1.9951807228915665e-05,
      "loss": 1.7033,
      "step": 20
    },
    {
      "epoch": 0.007228044813877846,
      "grad_norm": 0.6755002737045288,
      "learning_rate": 1.9927710843373497e-05,
      "loss": 1.7309,
      "step": 30
    },
    {
      "epoch": 0.009637393085170462,
      "grad_norm": 0.7528151273727417,
      "learning_rate": 1.9903614457831325e-05,
      "loss": 1.7177,
      "step": 40
    },
    {
      "epoch": 0.012046741356463078,
      "grad_norm": 0.7398552894592285,
      "learning_rate": 1.987951807228916e-05,
      "loss": 1.6826,
      "step": 50
    },
    {
      "epoch": 0.014456089627755691,
      "grad_norm": 0.6689538359642029,
      "learning_rate": 1.985542168674699e-05,
      "loss": 1.6262,
      "step": 60
    },
    {
      "epoch": 0.01686543789904831,
      "grad_norm": 0.8494299054145813,
      "learning_rate": 1.983132530120482e-05,
      "loss": 1.5772,
      "step": 70
    },
    {
      "epoch": 0.019274786170340924,
      "grad_norm": 0.8741278648376465,
      "learning_rate": 1.9807228915662652e-05,
      "loss": 1.5601,
      "step": 80
    },
    {
      "epoch": 0.02168413444163354,
      "grad_norm": 0.9824590086936951,
      "learning_rate": 1.9783132530120484e-05,
      "loss": 1.4793,
      "step": 90
    },
    {
      "epoch": 0.024093482712926155,
      "grad_norm": 0.8975394368171692,
      "learning_rate": 1.9759036144578312e-05,
      "loss": 1.4605,
      "step": 100
    },
    {
      "epoch": 0.02650283098421877,
      "grad_norm": 1.0387011766433716,
      "learning_rate": 1.9734939759036148e-05,
      "loss": 1.4309,
      "step": 110
    },
    {
      "epoch": 0.028912179255511383,
      "grad_norm": 1.1360622644424438,
      "learning_rate": 1.9710843373493976e-05,
      "loss": 1.3897,
      "step": 120
    },
    {
      "epoch": 0.031321527526804,
      "grad_norm": 0.8835365176200867,
      "learning_rate": 1.9686746987951808e-05,
      "loss": 1.2697,
      "step": 130
    },
    {
      "epoch": 0.03373087579809662,
      "grad_norm": 1.3133453130722046,
      "learning_rate": 1.966265060240964e-05,
      "loss": 1.2546,
      "step": 140
    },
    {
      "epoch": 0.03614022406938923,
      "grad_norm": 1.0252336263656616,
      "learning_rate": 1.963855421686747e-05,
      "loss": 1.2842,
      "step": 150
    },
    {
      "epoch": 0.03854957234068185,
      "grad_norm": 0.9969293475151062,
      "learning_rate": 1.9614457831325303e-05,
      "loss": 1.2192,
      "step": 160
    },
    {
      "epoch": 0.04095892061197446,
      "grad_norm": 0.8924717307090759,
      "learning_rate": 1.9590361445783135e-05,
      "loss": 1.2718,
      "step": 170
    },
    {
      "epoch": 0.04336826888326708,
      "grad_norm": 1.1445220708847046,
      "learning_rate": 1.9566265060240967e-05,
      "loss": 1.2669,
      "step": 180
    },
    {
      "epoch": 0.04577761715455969,
      "grad_norm": 0.8756242990493774,
      "learning_rate": 1.9542168674698795e-05,
      "loss": 1.2184,
      "step": 190
    },
    {
      "epoch": 0.04818696542585231,
      "grad_norm": 0.9437810778617859,
      "learning_rate": 1.951807228915663e-05,
      "loss": 1.2006,
      "step": 200
    },
    {
      "epoch": 0.05059631369714492,
      "grad_norm": 0.8347366452217102,
      "learning_rate": 1.949397590361446e-05,
      "loss": 1.1787,
      "step": 210
    },
    {
      "epoch": 0.05300566196843754,
      "grad_norm": 1.04587721824646,
      "learning_rate": 1.946987951807229e-05,
      "loss": 1.1493,
      "step": 220
    },
    {
      "epoch": 0.05541501023973015,
      "grad_norm": 1.071115493774414,
      "learning_rate": 1.9445783132530122e-05,
      "loss": 1.1795,
      "step": 230
    },
    {
      "epoch": 0.057824358511022765,
      "grad_norm": 1.1713043451309204,
      "learning_rate": 1.9421686746987954e-05,
      "loss": 1.0934,
      "step": 240
    },
    {
      "epoch": 0.060233706782315384,
      "grad_norm": 0.9322252869606018,
      "learning_rate": 1.9397590361445785e-05,
      "loss": 1.1258,
      "step": 250
    },
    {
      "epoch": 0.062643055053608,
      "grad_norm": 0.8990157246589661,
      "learning_rate": 1.9373493975903617e-05,
      "loss": 1.1739,
      "step": 260
    },
    {
      "epoch": 0.06505240332490062,
      "grad_norm": 0.8893855810165405,
      "learning_rate": 1.9349397590361446e-05,
      "loss": 1.1577,
      "step": 270
    },
    {
      "epoch": 0.06746175159619323,
      "grad_norm": 1.1032131910324097,
      "learning_rate": 1.9325301204819277e-05,
      "loss": 1.0794,
      "step": 280
    },
    {
      "epoch": 0.06987109986748584,
      "grad_norm": 1.3081083297729492,
      "learning_rate": 1.930120481927711e-05,
      "loss": 1.0782,
      "step": 290
    },
    {
      "epoch": 0.07228044813877846,
      "grad_norm": 0.9143674969673157,
      "learning_rate": 1.927710843373494e-05,
      "loss": 1.1114,
      "step": 300
    },
    {
      "epoch": 0.07468979641007108,
      "grad_norm": 1.19508957862854,
      "learning_rate": 1.9253012048192773e-05,
      "loss": 1.1457,
      "step": 310
    },
    {
      "epoch": 0.0770991446813637,
      "grad_norm": 1.0510634183883667,
      "learning_rate": 1.9228915662650604e-05,
      "loss": 1.1496,
      "step": 320
    },
    {
      "epoch": 0.0795084929526563,
      "grad_norm": 1.41334867477417,
      "learning_rate": 1.9204819277108436e-05,
      "loss": 1.1344,
      "step": 330
    },
    {
      "epoch": 0.08191784122394892,
      "grad_norm": 1.275490164756775,
      "learning_rate": 1.9180722891566265e-05,
      "loss": 1.0732,
      "step": 340
    },
    {
      "epoch": 0.08432718949524154,
      "grad_norm": 1.463879942893982,
      "learning_rate": 1.91566265060241e-05,
      "loss": 1.1524,
      "step": 350
    },
    {
      "epoch": 0.08673653776653416,
      "grad_norm": 0.8707205653190613,
      "learning_rate": 1.9132530120481928e-05,
      "loss": 1.15,
      "step": 360
    },
    {
      "epoch": 0.08914588603782676,
      "grad_norm": 0.9129836559295654,
      "learning_rate": 1.910843373493976e-05,
      "loss": 1.1522,
      "step": 370
    },
    {
      "epoch": 0.09155523430911938,
      "grad_norm": 0.9253113865852356,
      "learning_rate": 1.908433734939759e-05,
      "loss": 1.1306,
      "step": 380
    },
    {
      "epoch": 0.093964582580412,
      "grad_norm": 1.0518560409545898,
      "learning_rate": 1.9060240963855423e-05,
      "loss": 1.0591,
      "step": 390
    },
    {
      "epoch": 0.09637393085170462,
      "grad_norm": 1.1177632808685303,
      "learning_rate": 1.9036144578313255e-05,
      "loss": 1.0948,
      "step": 400
    },
    {
      "epoch": 0.09878327912299723,
      "grad_norm": 1.1873198747634888,
      "learning_rate": 1.9012048192771087e-05,
      "loss": 1.1042,
      "step": 410
    },
    {
      "epoch": 0.10119262739428984,
      "grad_norm": 0.9943903088569641,
      "learning_rate": 1.898795180722892e-05,
      "loss": 1.1161,
      "step": 420
    },
    {
      "epoch": 0.10360197566558246,
      "grad_norm": 0.9248993396759033,
      "learning_rate": 1.8963855421686747e-05,
      "loss": 1.1091,
      "step": 430
    },
    {
      "epoch": 0.10601132393687508,
      "grad_norm": 1.708941102027893,
      "learning_rate": 1.893975903614458e-05,
      "loss": 1.0747,
      "step": 440
    },
    {
      "epoch": 0.10842067220816769,
      "grad_norm": 1.084115743637085,
      "learning_rate": 1.891566265060241e-05,
      "loss": 1.168,
      "step": 450
    },
    {
      "epoch": 0.1108300204794603,
      "grad_norm": 1.0397188663482666,
      "learning_rate": 1.8891566265060242e-05,
      "loss": 1.1396,
      "step": 460
    },
    {
      "epoch": 0.11323936875075293,
      "grad_norm": 1.003334403038025,
      "learning_rate": 1.8867469879518074e-05,
      "loss": 1.1563,
      "step": 470
    },
    {
      "epoch": 0.11564871702204553,
      "grad_norm": 1.1543530225753784,
      "learning_rate": 1.8843373493975906e-05,
      "loss": 1.0877,
      "step": 480
    },
    {
      "epoch": 0.11805806529333815,
      "grad_norm": 1.2510093450546265,
      "learning_rate": 1.8819277108433734e-05,
      "loss": 1.1235,
      "step": 490
    },
    {
      "epoch": 0.12046741356463077,
      "grad_norm": 0.8050975203514099,
      "learning_rate": 1.879518072289157e-05,
      "loss": 1.1216,
      "step": 500
    },
    {
      "epoch": 0.12287676183592339,
      "grad_norm": 1.5139371156692505,
      "learning_rate": 1.8771084337349398e-05,
      "loss": 1.1365,
      "step": 510
    },
    {
      "epoch": 0.125286110107216,
      "grad_norm": 1.0474332571029663,
      "learning_rate": 1.874698795180723e-05,
      "loss": 1.09,
      "step": 520
    },
    {
      "epoch": 0.12769545837850863,
      "grad_norm": 1.2310971021652222,
      "learning_rate": 1.872289156626506e-05,
      "loss": 1.1175,
      "step": 530
    },
    {
      "epoch": 0.13010480664980123,
      "grad_norm": 1.172333836555481,
      "learning_rate": 1.8698795180722893e-05,
      "loss": 1.1018,
      "step": 540
    },
    {
      "epoch": 0.13251415492109384,
      "grad_norm": 1.0365737676620483,
      "learning_rate": 1.8674698795180725e-05,
      "loss": 1.0509,
      "step": 550
    },
    {
      "epoch": 0.13492350319238647,
      "grad_norm": 1.1811223030090332,
      "learning_rate": 1.8650602409638556e-05,
      "loss": 1.0871,
      "step": 560
    },
    {
      "epoch": 0.13733285146367907,
      "grad_norm": 1.2066384553909302,
      "learning_rate": 1.8626506024096388e-05,
      "loss": 1.1144,
      "step": 570
    },
    {
      "epoch": 0.13974219973497168,
      "grad_norm": 1.1540757417678833,
      "learning_rate": 1.8602409638554217e-05,
      "loss": 1.118,
      "step": 580
    },
    {
      "epoch": 0.1421515480062643,
      "grad_norm": 1.0650665760040283,
      "learning_rate": 1.8578313253012052e-05,
      "loss": 1.1232,
      "step": 590
    },
    {
      "epoch": 0.14456089627755692,
      "grad_norm": 1.1721223592758179,
      "learning_rate": 1.855421686746988e-05,
      "loss": 1.1137,
      "step": 600
    },
    {
      "epoch": 0.14697024454884955,
      "grad_norm": 0.9749694466590881,
      "learning_rate": 1.8530120481927712e-05,
      "loss": 1.0574,
      "step": 610
    },
    {
      "epoch": 0.14937959282014215,
      "grad_norm": 1.0468711853027344,
      "learning_rate": 1.8506024096385544e-05,
      "loss": 1.0967,
      "step": 620
    },
    {
      "epoch": 0.15178894109143476,
      "grad_norm": 0.9893456697463989,
      "learning_rate": 1.8481927710843375e-05,
      "loss": 1.0804,
      "step": 630
    },
    {
      "epoch": 0.1541982893627274,
      "grad_norm": 1.4045124053955078,
      "learning_rate": 1.8457831325301204e-05,
      "loss": 1.0926,
      "step": 640
    },
    {
      "epoch": 0.15660763763402,
      "grad_norm": 1.3839199542999268,
      "learning_rate": 1.843373493975904e-05,
      "loss": 1.0971,
      "step": 650
    },
    {
      "epoch": 0.1590169859053126,
      "grad_norm": 1.1075477600097656,
      "learning_rate": 1.8409638554216867e-05,
      "loss": 1.0991,
      "step": 660
    },
    {
      "epoch": 0.16142633417660524,
      "grad_norm": 1.1056251525878906,
      "learning_rate": 1.83855421686747e-05,
      "loss": 1.1081,
      "step": 670
    },
    {
      "epoch": 0.16383568244789784,
      "grad_norm": 0.8574629426002502,
      "learning_rate": 1.836144578313253e-05,
      "loss": 1.1306,
      "step": 680
    },
    {
      "epoch": 0.16624503071919045,
      "grad_norm": 1.2023576498031616,
      "learning_rate": 1.8337349397590363e-05,
      "loss": 1.1073,
      "step": 690
    },
    {
      "epoch": 0.16865437899048308,
      "grad_norm": 1.0033574104309082,
      "learning_rate": 1.8313253012048194e-05,
      "loss": 1.0736,
      "step": 700
    },
    {
      "epoch": 0.17106372726177568,
      "grad_norm": 1.2584540843963623,
      "learning_rate": 1.8289156626506026e-05,
      "loss": 1.1072,
      "step": 710
    },
    {
      "epoch": 0.17347307553306832,
      "grad_norm": 1.1961642503738403,
      "learning_rate": 1.8265060240963858e-05,
      "loss": 1.0928,
      "step": 720
    },
    {
      "epoch": 0.17588242380436092,
      "grad_norm": 1.0819092988967896,
      "learning_rate": 1.8240963855421686e-05,
      "loss": 1.1167,
      "step": 730
    },
    {
      "epoch": 0.17829177207565353,
      "grad_norm": 1.0206191539764404,
      "learning_rate": 1.821686746987952e-05,
      "loss": 1.0565,
      "step": 740
    },
    {
      "epoch": 0.18070112034694616,
      "grad_norm": 1.0200886726379395,
      "learning_rate": 1.819277108433735e-05,
      "loss": 1.0851,
      "step": 750
    },
    {
      "epoch": 0.18311046861823876,
      "grad_norm": 1.292902946472168,
      "learning_rate": 1.816867469879518e-05,
      "loss": 1.1291,
      "step": 760
    },
    {
      "epoch": 0.18551981688953137,
      "grad_norm": 1.245489239692688,
      "learning_rate": 1.8144578313253013e-05,
      "loss": 1.0606,
      "step": 770
    },
    {
      "epoch": 0.187929165160824,
      "grad_norm": 1.0169905424118042,
      "learning_rate": 1.8120481927710845e-05,
      "loss": 1.0924,
      "step": 780
    },
    {
      "epoch": 0.1903385134321166,
      "grad_norm": 1.0398852825164795,
      "learning_rate": 1.8096385542168677e-05,
      "loss": 1.1264,
      "step": 790
    },
    {
      "epoch": 0.19274786170340924,
      "grad_norm": 1.233620285987854,
      "learning_rate": 1.807228915662651e-05,
      "loss": 1.0986,
      "step": 800
    },
    {
      "epoch": 0.19515720997470185,
      "grad_norm": 1.1775087118148804,
      "learning_rate": 1.8048192771084337e-05,
      "loss": 1.123,
      "step": 810
    },
    {
      "epoch": 0.19756655824599445,
      "grad_norm": 1.2909103631973267,
      "learning_rate": 1.802409638554217e-05,
      "loss": 1.0799,
      "step": 820
    },
    {
      "epoch": 0.19997590651728708,
      "grad_norm": 1.081285834312439,
      "learning_rate": 1.8e-05,
      "loss": 1.061,
      "step": 830
    },
    {
      "epoch": 0.2023852547885797,
      "grad_norm": 0.963627278804779,
      "learning_rate": 1.7975903614457832e-05,
      "loss": 1.0562,
      "step": 840
    },
    {
      "epoch": 0.2047946030598723,
      "grad_norm": 1.145747184753418,
      "learning_rate": 1.7951807228915664e-05,
      "loss": 1.0914,
      "step": 850
    },
    {
      "epoch": 0.20720395133116493,
      "grad_norm": 0.9589347243309021,
      "learning_rate": 1.7927710843373496e-05,
      "loss": 1.143,
      "step": 860
    },
    {
      "epoch": 0.20961329960245753,
      "grad_norm": 1.643786907196045,
      "learning_rate": 1.7903614457831327e-05,
      "loss": 1.1166,
      "step": 870
    },
    {
      "epoch": 0.21202264787375016,
      "grad_norm": 0.9508745074272156,
      "learning_rate": 1.7879518072289156e-05,
      "loss": 1.0941,
      "step": 880
    },
    {
      "epoch": 0.21443199614504277,
      "grad_norm": 1.3346177339553833,
      "learning_rate": 1.785542168674699e-05,
      "loss": 1.0507,
      "step": 890
    },
    {
      "epoch": 0.21684134441633537,
      "grad_norm": 1.2976255416870117,
      "learning_rate": 1.783132530120482e-05,
      "loss": 1.0888,
      "step": 900
    },
    {
      "epoch": 0.219250692687628,
      "grad_norm": 1.1353492736816406,
      "learning_rate": 1.780722891566265e-05,
      "loss": 1.0806,
      "step": 910
    },
    {
      "epoch": 0.2216600409589206,
      "grad_norm": 1.0453113317489624,
      "learning_rate": 1.7783132530120483e-05,
      "loss": 1.0692,
      "step": 920
    },
    {
      "epoch": 0.22406938923021322,
      "grad_norm": 1.1286582946777344,
      "learning_rate": 1.7759036144578315e-05,
      "loss": 1.1526,
      "step": 930
    },
    {
      "epoch": 0.22647873750150585,
      "grad_norm": 1.036206841468811,
      "learning_rate": 1.7734939759036146e-05,
      "loss": 1.0968,
      "step": 940
    },
    {
      "epoch": 0.22888808577279846,
      "grad_norm": 0.9141355156898499,
      "learning_rate": 1.7710843373493978e-05,
      "loss": 1.0953,
      "step": 950
    },
    {
      "epoch": 0.23129743404409106,
      "grad_norm": 1.2504498958587646,
      "learning_rate": 1.768674698795181e-05,
      "loss": 1.1466,
      "step": 960
    },
    {
      "epoch": 0.2337067823153837,
      "grad_norm": 1.0719149112701416,
      "learning_rate": 1.766265060240964e-05,
      "loss": 1.073,
      "step": 970
    },
    {
      "epoch": 0.2361161305866763,
      "grad_norm": 1.1593096256256104,
      "learning_rate": 1.763855421686747e-05,
      "loss": 1.0347,
      "step": 980
    },
    {
      "epoch": 0.23852547885796893,
      "grad_norm": 1.5641217231750488,
      "learning_rate": 1.7614457831325302e-05,
      "loss": 1.0653,
      "step": 990
    },
    {
      "epoch": 0.24093482712926154,
      "grad_norm": 1.0853577852249146,
      "learning_rate": 1.7590361445783134e-05,
      "loss": 1.0559,
      "step": 1000
    },
    {
      "epoch": 0.24334417540055414,
      "grad_norm": 0.9054080247879028,
      "learning_rate": 1.7566265060240965e-05,
      "loss": 1.1294,
      "step": 1010
    },
    {
      "epoch": 0.24575352367184677,
      "grad_norm": 1.1215705871582031,
      "learning_rate": 1.7542168674698797e-05,
      "loss": 1.0982,
      "step": 1020
    },
    {
      "epoch": 0.24816287194313938,
      "grad_norm": 1.0005075931549072,
      "learning_rate": 1.7518072289156625e-05,
      "loss": 1.0262,
      "step": 1030
    },
    {
      "epoch": 0.250572220214432,
      "grad_norm": 1.285381555557251,
      "learning_rate": 1.749397590361446e-05,
      "loss": 1.0963,
      "step": 1040
    },
    {
      "epoch": 0.2529815684857246,
      "grad_norm": 1.202582836151123,
      "learning_rate": 1.746987951807229e-05,
      "loss": 1.0302,
      "step": 1050
    },
    {
      "epoch": 0.25539091675701725,
      "grad_norm": 1.0953128337860107,
      "learning_rate": 1.7445783132530124e-05,
      "loss": 1.0721,
      "step": 1060
    },
    {
      "epoch": 0.2578002650283098,
      "grad_norm": 1.0882971286773682,
      "learning_rate": 1.7421686746987953e-05,
      "loss": 1.0795,
      "step": 1070
    },
    {
      "epoch": 0.26020961329960246,
      "grad_norm": 1.465197205543518,
      "learning_rate": 1.7397590361445784e-05,
      "loss": 1.0431,
      "step": 1080
    },
    {
      "epoch": 0.2626189615708951,
      "grad_norm": 1.2779960632324219,
      "learning_rate": 1.7373493975903616e-05,
      "loss": 1.0739,
      "step": 1090
    },
    {
      "epoch": 0.26502830984218767,
      "grad_norm": 1.4842228889465332,
      "learning_rate": 1.7349397590361448e-05,
      "loss": 1.0251,
      "step": 1100
    },
    {
      "epoch": 0.2674376581134803,
      "grad_norm": 1.983972191810608,
      "learning_rate": 1.732530120481928e-05,
      "loss": 1.0825,
      "step": 1110
    },
    {
      "epoch": 0.26984700638477294,
      "grad_norm": 1.3031367063522339,
      "learning_rate": 1.730120481927711e-05,
      "loss": 1.1116,
      "step": 1120
    },
    {
      "epoch": 0.2722563546560655,
      "grad_norm": 1.5140386819839478,
      "learning_rate": 1.7277108433734943e-05,
      "loss": 1.0937,
      "step": 1130
    },
    {
      "epoch": 0.27466570292735815,
      "grad_norm": 1.1708729267120361,
      "learning_rate": 1.725301204819277e-05,
      "loss": 1.0374,
      "step": 1140
    },
    {
      "epoch": 0.2770750511986508,
      "grad_norm": 1.0556375980377197,
      "learning_rate": 1.7228915662650603e-05,
      "loss": 1.1403,
      "step": 1150
    },
    {
      "epoch": 0.27948439946994336,
      "grad_norm": 1.2846438884735107,
      "learning_rate": 1.7204819277108435e-05,
      "loss": 1.0752,
      "step": 1160
    },
    {
      "epoch": 0.281893747741236,
      "grad_norm": 1.3567779064178467,
      "learning_rate": 1.7180722891566267e-05,
      "loss": 1.1058,
      "step": 1170
    },
    {
      "epoch": 0.2843030960125286,
      "grad_norm": 1.4574179649353027,
      "learning_rate": 1.71566265060241e-05,
      "loss": 1.1037,
      "step": 1180
    },
    {
      "epoch": 0.2867124442838212,
      "grad_norm": 0.907355010509491,
      "learning_rate": 1.713253012048193e-05,
      "loss": 1.0653,
      "step": 1190
    },
    {
      "epoch": 0.28912179255511383,
      "grad_norm": 1.1412794589996338,
      "learning_rate": 1.710843373493976e-05,
      "loss": 1.1246,
      "step": 1200
    },
    {
      "epoch": 0.29153114082640647,
      "grad_norm": 1.3540143966674805,
      "learning_rate": 1.7084337349397594e-05,
      "loss": 1.1083,
      "step": 1210
    },
    {
      "epoch": 0.2939404890976991,
      "grad_norm": 1.1878900527954102,
      "learning_rate": 1.7060240963855422e-05,
      "loss": 1.0803,
      "step": 1220
    },
    {
      "epoch": 0.2963498373689917,
      "grad_norm": 1.1130931377410889,
      "learning_rate": 1.7036144578313254e-05,
      "loss": 1.0911,
      "step": 1230
    },
    {
      "epoch": 0.2987591856402843,
      "grad_norm": 1.3948734998703003,
      "learning_rate": 1.7012048192771086e-05,
      "loss": 1.0716,
      "step": 1240
    },
    {
      "epoch": 0.30116853391157694,
      "grad_norm": 1.1232366561889648,
      "learning_rate": 1.6987951807228917e-05,
      "loss": 1.0978,
      "step": 1250
    },
    {
      "epoch": 0.3035778821828695,
      "grad_norm": 1.0728490352630615,
      "learning_rate": 1.696385542168675e-05,
      "loss": 1.1378,
      "step": 1260
    },
    {
      "epoch": 0.30598723045416215,
      "grad_norm": 1.1470845937728882,
      "learning_rate": 1.693975903614458e-05,
      "loss": 1.1042,
      "step": 1270
    },
    {
      "epoch": 0.3083965787254548,
      "grad_norm": 1.5216304063796997,
      "learning_rate": 1.6915662650602413e-05,
      "loss": 1.0855,
      "step": 1280
    },
    {
      "epoch": 0.31080592699674736,
      "grad_norm": 0.9697035551071167,
      "learning_rate": 1.689156626506024e-05,
      "loss": 1.0823,
      "step": 1290
    },
    {
      "epoch": 0.31321527526804,
      "grad_norm": 1.441155195236206,
      "learning_rate": 1.6867469879518076e-05,
      "loss": 1.1119,
      "step": 1300
    },
    {
      "epoch": 0.3156246235393326,
      "grad_norm": 1.1216671466827393,
      "learning_rate": 1.6843373493975905e-05,
      "loss": 1.0895,
      "step": 1310
    },
    {
      "epoch": 0.3180339718106252,
      "grad_norm": 1.2504795789718628,
      "learning_rate": 1.6819277108433736e-05,
      "loss": 1.0666,
      "step": 1320
    },
    {
      "epoch": 0.32044332008191784,
      "grad_norm": 1.215458631515503,
      "learning_rate": 1.6795180722891568e-05,
      "loss": 1.0117,
      "step": 1330
    },
    {
      "epoch": 0.32285266835321047,
      "grad_norm": 1.1242430210113525,
      "learning_rate": 1.67710843373494e-05,
      "loss": 1.0601,
      "step": 1340
    },
    {
      "epoch": 0.32526201662450305,
      "grad_norm": 1.2556761503219604,
      "learning_rate": 1.6746987951807228e-05,
      "loss": 1.104,
      "step": 1350
    },
    {
      "epoch": 0.3276713648957957,
      "grad_norm": 1.4223101139068604,
      "learning_rate": 1.6722891566265063e-05,
      "loss": 1.1194,
      "step": 1360
    },
    {
      "epoch": 0.3300807131670883,
      "grad_norm": 1.152877688407898,
      "learning_rate": 1.6698795180722892e-05,
      "loss": 1.0421,
      "step": 1370
    },
    {
      "epoch": 0.3324900614383809,
      "grad_norm": 1.2185235023498535,
      "learning_rate": 1.6674698795180724e-05,
      "loss": 1.0268,
      "step": 1380
    },
    {
      "epoch": 0.3348994097096735,
      "grad_norm": 0.9038862586021423,
      "learning_rate": 1.6650602409638555e-05,
      "loss": 1.0213,
      "step": 1390
    },
    {
      "epoch": 0.33730875798096616,
      "grad_norm": 1.1122385263442993,
      "learning_rate": 1.6626506024096387e-05,
      "loss": 1.1151,
      "step": 1400
    },
    {
      "epoch": 0.3397181062522588,
      "grad_norm": 1.0499073266983032,
      "learning_rate": 1.660240963855422e-05,
      "loss": 1.1202,
      "step": 1410
    },
    {
      "epoch": 0.34212745452355137,
      "grad_norm": 0.9883080720901489,
      "learning_rate": 1.657831325301205e-05,
      "loss": 1.149,
      "step": 1420
    },
    {
      "epoch": 0.344536802794844,
      "grad_norm": 1.0373371839523315,
      "learning_rate": 1.6554216867469882e-05,
      "loss": 1.0361,
      "step": 1430
    },
    {
      "epoch": 0.34694615106613663,
      "grad_norm": 1.0946201086044312,
      "learning_rate": 1.653012048192771e-05,
      "loss": 1.1298,
      "step": 1440
    },
    {
      "epoch": 0.3493554993374292,
      "grad_norm": 1.4634495973587036,
      "learning_rate": 1.6506024096385546e-05,
      "loss": 1.0738,
      "step": 1450
    },
    {
      "epoch": 0.35176484760872184,
      "grad_norm": 1.4212238788604736,
      "learning_rate": 1.6481927710843374e-05,
      "loss": 1.0513,
      "step": 1460
    },
    {
      "epoch": 0.3541741958800145,
      "grad_norm": 1.2430468797683716,
      "learning_rate": 1.6457831325301206e-05,
      "loss": 1.1211,
      "step": 1470
    },
    {
      "epoch": 0.35658354415130705,
      "grad_norm": 1.1858296394348145,
      "learning_rate": 1.6433734939759038e-05,
      "loss": 1.0632,
      "step": 1480
    },
    {
      "epoch": 0.3589928924225997,
      "grad_norm": 1.1231003999710083,
      "learning_rate": 1.640963855421687e-05,
      "loss": 1.068,
      "step": 1490
    },
    {
      "epoch": 0.3614022406938923,
      "grad_norm": 1.1776082515716553,
      "learning_rate": 1.63855421686747e-05,
      "loss": 1.0986,
      "step": 1500
    },
    {
      "epoch": 0.3638115889651849,
      "grad_norm": 1.2597529888153076,
      "learning_rate": 1.6361445783132533e-05,
      "loss": 1.0594,
      "step": 1510
    },
    {
      "epoch": 0.36622093723647753,
      "grad_norm": 1.4013510942459106,
      "learning_rate": 1.633734939759036e-05,
      "loss": 1.0753,
      "step": 1520
    },
    {
      "epoch": 0.36863028550777016,
      "grad_norm": 1.5053846836090088,
      "learning_rate": 1.6313253012048193e-05,
      "loss": 1.1273,
      "step": 1530
    },
    {
      "epoch": 0.37103963377906274,
      "grad_norm": 1.7068979740142822,
      "learning_rate": 1.6289156626506025e-05,
      "loss": 1.0746,
      "step": 1540
    },
    {
      "epoch": 0.37344898205035537,
      "grad_norm": 0.8963245153427124,
      "learning_rate": 1.6265060240963857e-05,
      "loss": 1.081,
      "step": 1550
    },
    {
      "epoch": 0.375858330321648,
      "grad_norm": 1.1075621843338013,
      "learning_rate": 1.624096385542169e-05,
      "loss": 1.0551,
      "step": 1560
    },
    {
      "epoch": 0.37826767859294064,
      "grad_norm": 1.031105637550354,
      "learning_rate": 1.621686746987952e-05,
      "loss": 1.0516,
      "step": 1570
    },
    {
      "epoch": 0.3806770268642332,
      "grad_norm": 1.1258034706115723,
      "learning_rate": 1.6192771084337352e-05,
      "loss": 1.1055,
      "step": 1580
    },
    {
      "epoch": 0.38308637513552585,
      "grad_norm": 1.2334988117218018,
      "learning_rate": 1.616867469879518e-05,
      "loss": 1.0587,
      "step": 1590
    },
    {
      "epoch": 0.3854957234068185,
      "grad_norm": 1.3382277488708496,
      "learning_rate": 1.6144578313253015e-05,
      "loss": 1.0332,
      "step": 1600
    },
    {
      "epoch": 0.38790507167811106,
      "grad_norm": 1.3910061120986938,
      "learning_rate": 1.6120481927710844e-05,
      "loss": 1.0908,
      "step": 1610
    },
    {
      "epoch": 0.3903144199494037,
      "grad_norm": 1.2842658758163452,
      "learning_rate": 1.6096385542168676e-05,
      "loss": 1.078,
      "step": 1620
    },
    {
      "epoch": 0.3927237682206963,
      "grad_norm": 1.0779305696487427,
      "learning_rate": 1.6072289156626507e-05,
      "loss": 1.0808,
      "step": 1630
    },
    {
      "epoch": 0.3951331164919889,
      "grad_norm": 0.9903162717819214,
      "learning_rate": 1.604819277108434e-05,
      "loss": 1.0786,
      "step": 1640
    },
    {
      "epoch": 0.39754246476328153,
      "grad_norm": 1.1745253801345825,
      "learning_rate": 1.602409638554217e-05,
      "loss": 1.06,
      "step": 1650
    },
    {
      "epoch": 0.39995181303457417,
      "grad_norm": 1.6953026056289673,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.1084,
      "step": 1660
    },
    {
      "epoch": 0.40236116130586674,
      "grad_norm": 1.335349440574646,
      "learning_rate": 1.5975903614457834e-05,
      "loss": 1.1376,
      "step": 1670
    },
    {
      "epoch": 0.4047705095771594,
      "grad_norm": 1.2389662265777588,
      "learning_rate": 1.5951807228915663e-05,
      "loss": 1.1472,
      "step": 1680
    },
    {
      "epoch": 0.407179857848452,
      "grad_norm": 1.0639702081680298,
      "learning_rate": 1.5927710843373495e-05,
      "loss": 0.9974,
      "step": 1690
    },
    {
      "epoch": 0.4095892061197446,
      "grad_norm": 1.2282291650772095,
      "learning_rate": 1.5903614457831326e-05,
      "loss": 1.0403,
      "step": 1700
    },
    {
      "epoch": 0.4119985543910372,
      "grad_norm": 1.1119418144226074,
      "learning_rate": 1.5879518072289158e-05,
      "loss": 1.0711,
      "step": 1710
    },
    {
      "epoch": 0.41440790266232985,
      "grad_norm": 1.1571497917175293,
      "learning_rate": 1.585542168674699e-05,
      "loss": 1.0832,
      "step": 1720
    },
    {
      "epoch": 0.41681725093362243,
      "grad_norm": 1.1613320112228394,
      "learning_rate": 1.583132530120482e-05,
      "loss": 1.027,
      "step": 1730
    },
    {
      "epoch": 0.41922659920491506,
      "grad_norm": 1.0155863761901855,
      "learning_rate": 1.580722891566265e-05,
      "loss": 1.1016,
      "step": 1740
    },
    {
      "epoch": 0.4216359474762077,
      "grad_norm": 0.9931156039237976,
      "learning_rate": 1.5783132530120485e-05,
      "loss": 1.0626,
      "step": 1750
    },
    {
      "epoch": 0.42404529574750033,
      "grad_norm": 1.1504886150360107,
      "learning_rate": 1.5759036144578313e-05,
      "loss": 1.0641,
      "step": 1760
    },
    {
      "epoch": 0.4264546440187929,
      "grad_norm": 1.5071449279785156,
      "learning_rate": 1.5734939759036145e-05,
      "loss": 1.0806,
      "step": 1770
    },
    {
      "epoch": 0.42886399229008554,
      "grad_norm": 1.265903353691101,
      "learning_rate": 1.5710843373493977e-05,
      "loss": 1.0893,
      "step": 1780
    },
    {
      "epoch": 0.43127334056137817,
      "grad_norm": 1.0198107957839966,
      "learning_rate": 1.568674698795181e-05,
      "loss": 1.0865,
      "step": 1790
    },
    {
      "epoch": 0.43368268883267075,
      "grad_norm": 1.113592505455017,
      "learning_rate": 1.566265060240964e-05,
      "loss": 1.0681,
      "step": 1800
    },
    {
      "epoch": 0.4360920371039634,
      "grad_norm": 1.6580913066864014,
      "learning_rate": 1.5638554216867472e-05,
      "loss": 1.0414,
      "step": 1810
    },
    {
      "epoch": 0.438501385375256,
      "grad_norm": 1.0688860416412354,
      "learning_rate": 1.5614457831325304e-05,
      "loss": 1.0612,
      "step": 1820
    },
    {
      "epoch": 0.4409107336465486,
      "grad_norm": 1.3284944295883179,
      "learning_rate": 1.5590361445783132e-05,
      "loss": 1.0451,
      "step": 1830
    },
    {
      "epoch": 0.4433200819178412,
      "grad_norm": 0.839960515499115,
      "learning_rate": 1.5566265060240968e-05,
      "loss": 1.0582,
      "step": 1840
    },
    {
      "epoch": 0.44572943018913386,
      "grad_norm": 1.3038252592086792,
      "learning_rate": 1.5542168674698796e-05,
      "loss": 1.0517,
      "step": 1850
    },
    {
      "epoch": 0.44813877846042643,
      "grad_norm": 1.11463463306427,
      "learning_rate": 1.5518072289156628e-05,
      "loss": 1.1307,
      "step": 1860
    },
    {
      "epoch": 0.45054812673171907,
      "grad_norm": 0.855150043964386,
      "learning_rate": 1.549397590361446e-05,
      "loss": 1.0839,
      "step": 1870
    },
    {
      "epoch": 0.4529574750030117,
      "grad_norm": 1.1594421863555908,
      "learning_rate": 1.546987951807229e-05,
      "loss": 1.0713,
      "step": 1880
    },
    {
      "epoch": 0.4553668232743043,
      "grad_norm": 1.330134630203247,
      "learning_rate": 1.544578313253012e-05,
      "loss": 1.0649,
      "step": 1890
    },
    {
      "epoch": 0.4577761715455969,
      "grad_norm": 1.06305730342865,
      "learning_rate": 1.5421686746987955e-05,
      "loss": 1.0483,
      "step": 1900
    },
    {
      "epoch": 0.46018551981688954,
      "grad_norm": 0.9369847178459167,
      "learning_rate": 1.5397590361445783e-05,
      "loss": 1.0699,
      "step": 1910
    },
    {
      "epoch": 0.4625948680881821,
      "grad_norm": 1.2702045440673828,
      "learning_rate": 1.5373493975903615e-05,
      "loss": 1.0572,
      "step": 1920
    },
    {
      "epoch": 0.46500421635947475,
      "grad_norm": 1.3986862897872925,
      "learning_rate": 1.5349397590361447e-05,
      "loss": 1.0402,
      "step": 1930
    },
    {
      "epoch": 0.4674135646307674,
      "grad_norm": 1.3780869245529175,
      "learning_rate": 1.532530120481928e-05,
      "loss": 1.0536,
      "step": 1940
    },
    {
      "epoch": 0.46982291290206,
      "grad_norm": 1.221693515777588,
      "learning_rate": 1.530120481927711e-05,
      "loss": 1.0908,
      "step": 1950
    },
    {
      "epoch": 0.4722322611733526,
      "grad_norm": 1.2705472707748413,
      "learning_rate": 1.5277108433734942e-05,
      "loss": 1.0003,
      "step": 1960
    },
    {
      "epoch": 0.47464160944464523,
      "grad_norm": 1.334762454032898,
      "learning_rate": 1.5253012048192772e-05,
      "loss": 1.1169,
      "step": 1970
    },
    {
      "epoch": 0.47705095771593786,
      "grad_norm": 1.1182944774627686,
      "learning_rate": 1.5228915662650604e-05,
      "loss": 1.124,
      "step": 1980
    },
    {
      "epoch": 0.47946030598723044,
      "grad_norm": 1.0123708248138428,
      "learning_rate": 1.5204819277108436e-05,
      "loss": 1.0587,
      "step": 1990
    },
    {
      "epoch": 0.4818696542585231,
      "grad_norm": 1.2366900444030762,
      "learning_rate": 1.5180722891566266e-05,
      "loss": 1.1041,
      "step": 2000
    },
    {
      "epoch": 0.4842790025298157,
      "grad_norm": 1.3598756790161133,
      "learning_rate": 1.5156626506024097e-05,
      "loss": 1.1114,
      "step": 2010
    },
    {
      "epoch": 0.4866883508011083,
      "grad_norm": 1.2292919158935547,
      "learning_rate": 1.5132530120481929e-05,
      "loss": 1.0683,
      "step": 2020
    },
    {
      "epoch": 0.4890976990724009,
      "grad_norm": 1.0397437810897827,
      "learning_rate": 1.5108433734939761e-05,
      "loss": 1.0908,
      "step": 2030
    },
    {
      "epoch": 0.49150704734369355,
      "grad_norm": 0.9707269072532654,
      "learning_rate": 1.5084337349397591e-05,
      "loss": 1.083,
      "step": 2040
    },
    {
      "epoch": 0.4939163956149861,
      "grad_norm": 1.0097709894180298,
      "learning_rate": 1.5060240963855424e-05,
      "loss": 1.1004,
      "step": 2050
    },
    {
      "epoch": 0.49632574388627876,
      "grad_norm": 0.8619704246520996,
      "learning_rate": 1.5036144578313254e-05,
      "loss": 1.0626,
      "step": 2060
    },
    {
      "epoch": 0.4987350921575714,
      "grad_norm": 0.9398052096366882,
      "learning_rate": 1.5012048192771084e-05,
      "loss": 1.0358,
      "step": 2070
    },
    {
      "epoch": 0.501144440428864,
      "grad_norm": 0.999670147895813,
      "learning_rate": 1.4987951807228918e-05,
      "loss": 1.0727,
      "step": 2080
    },
    {
      "epoch": 0.5035537887001567,
      "grad_norm": 0.9021243453025818,
      "learning_rate": 1.4963855421686748e-05,
      "loss": 1.1204,
      "step": 2090
    },
    {
      "epoch": 0.5059631369714492,
      "grad_norm": 1.0702189207077026,
      "learning_rate": 1.4939759036144578e-05,
      "loss": 1.0658,
      "step": 2100
    },
    {
      "epoch": 0.5083724852427418,
      "grad_norm": 1.3299261331558228,
      "learning_rate": 1.4915662650602412e-05,
      "loss": 1.0974,
      "step": 2110
    },
    {
      "epoch": 0.5107818335140345,
      "grad_norm": 1.5902736186981201,
      "learning_rate": 1.4891566265060242e-05,
      "loss": 1.056,
      "step": 2120
    },
    {
      "epoch": 0.5131911817853271,
      "grad_norm": 1.2101598978042603,
      "learning_rate": 1.4867469879518073e-05,
      "loss": 1.076,
      "step": 2130
    },
    {
      "epoch": 0.5156005300566197,
      "grad_norm": 0.9019172191619873,
      "learning_rate": 1.4843373493975905e-05,
      "loss": 1.047,
      "step": 2140
    },
    {
      "epoch": 0.5180098783279123,
      "grad_norm": 1.2587299346923828,
      "learning_rate": 1.4819277108433737e-05,
      "loss": 1.0339,
      "step": 2150
    },
    {
      "epoch": 0.5204192265992049,
      "grad_norm": 1.414908528327942,
      "learning_rate": 1.4795180722891567e-05,
      "loss": 0.9735,
      "step": 2160
    },
    {
      "epoch": 0.5228285748704975,
      "grad_norm": 1.0074955224990845,
      "learning_rate": 1.4771084337349399e-05,
      "loss": 1.0739,
      "step": 2170
    },
    {
      "epoch": 0.5252379231417902,
      "grad_norm": 1.0749152898788452,
      "learning_rate": 1.474698795180723e-05,
      "loss": 1.0479,
      "step": 2180
    },
    {
      "epoch": 0.5276472714130828,
      "grad_norm": 1.0188252925872803,
      "learning_rate": 1.472289156626506e-05,
      "loss": 1.0338,
      "step": 2190
    },
    {
      "epoch": 0.5300566196843753,
      "grad_norm": 1.1681623458862305,
      "learning_rate": 1.4698795180722894e-05,
      "loss": 1.0413,
      "step": 2200
    },
    {
      "epoch": 0.532465967955668,
      "grad_norm": 0.9779105186462402,
      "learning_rate": 1.4674698795180724e-05,
      "loss": 1.0406,
      "step": 2210
    },
    {
      "epoch": 0.5348753162269606,
      "grad_norm": 1.2096105813980103,
      "learning_rate": 1.4650602409638554e-05,
      "loss": 1.0462,
      "step": 2220
    },
    {
      "epoch": 0.5372846644982532,
      "grad_norm": 1.0210509300231934,
      "learning_rate": 1.4626506024096388e-05,
      "loss": 1.0499,
      "step": 2230
    },
    {
      "epoch": 0.5396940127695459,
      "grad_norm": 1.3432542085647583,
      "learning_rate": 1.4602409638554218e-05,
      "loss": 1.1101,
      "step": 2240
    },
    {
      "epoch": 0.5421033610408384,
      "grad_norm": 1.0124446153640747,
      "learning_rate": 1.457831325301205e-05,
      "loss": 1.0419,
      "step": 2250
    },
    {
      "epoch": 0.544512709312131,
      "grad_norm": 1.2406734228134155,
      "learning_rate": 1.4554216867469881e-05,
      "loss": 1.0929,
      "step": 2260
    },
    {
      "epoch": 0.5469220575834237,
      "grad_norm": 0.8891276717185974,
      "learning_rate": 1.4530120481927711e-05,
      "loss": 1.0638,
      "step": 2270
    },
    {
      "epoch": 0.5493314058547163,
      "grad_norm": 1.2486990690231323,
      "learning_rate": 1.4506024096385543e-05,
      "loss": 1.0809,
      "step": 2280
    },
    {
      "epoch": 0.5517407541260089,
      "grad_norm": 0.8601590991020203,
      "learning_rate": 1.4481927710843375e-05,
      "loss": 1.0605,
      "step": 2290
    },
    {
      "epoch": 0.5541501023973016,
      "grad_norm": 1.3612877130508423,
      "learning_rate": 1.4457831325301207e-05,
      "loss": 1.0705,
      "step": 2300
    },
    {
      "epoch": 0.5565594506685941,
      "grad_norm": 0.8703863620758057,
      "learning_rate": 1.4433734939759037e-05,
      "loss": 1.0845,
      "step": 2310
    },
    {
      "epoch": 0.5589687989398867,
      "grad_norm": 0.9585620164871216,
      "learning_rate": 1.440963855421687e-05,
      "loss": 1.1002,
      "step": 2320
    },
    {
      "epoch": 0.5613781472111794,
      "grad_norm": 0.8924010992050171,
      "learning_rate": 1.43855421686747e-05,
      "loss": 1.0389,
      "step": 2330
    },
    {
      "epoch": 0.563787495482472,
      "grad_norm": 1.129115104675293,
      "learning_rate": 1.436144578313253e-05,
      "loss": 1.1063,
      "step": 2340
    },
    {
      "epoch": 0.5661968437537646,
      "grad_norm": 1.2618082761764526,
      "learning_rate": 1.4337349397590364e-05,
      "loss": 1.0446,
      "step": 2350
    },
    {
      "epoch": 0.5686061920250572,
      "grad_norm": 1.1265227794647217,
      "learning_rate": 1.4313253012048194e-05,
      "loss": 1.042,
      "step": 2360
    },
    {
      "epoch": 0.5710155402963498,
      "grad_norm": 1.0009351968765259,
      "learning_rate": 1.4289156626506024e-05,
      "loss": 1.064,
      "step": 2370
    },
    {
      "epoch": 0.5734248885676424,
      "grad_norm": 1.2457886934280396,
      "learning_rate": 1.4265060240963857e-05,
      "loss": 1.1046,
      "step": 2380
    },
    {
      "epoch": 0.5758342368389351,
      "grad_norm": 0.9788379073143005,
      "learning_rate": 1.4240963855421687e-05,
      "loss": 1.0398,
      "step": 2390
    },
    {
      "epoch": 0.5782435851102277,
      "grad_norm": 1.2211261987686157,
      "learning_rate": 1.4216867469879519e-05,
      "loss": 1.1018,
      "step": 2400
    },
    {
      "epoch": 0.5806529333815204,
      "grad_norm": 1.0143029689788818,
      "learning_rate": 1.419277108433735e-05,
      "loss": 1.0974,
      "step": 2410
    },
    {
      "epoch": 0.5830622816528129,
      "grad_norm": 0.994465172290802,
      "learning_rate": 1.4168674698795183e-05,
      "loss": 1.0952,
      "step": 2420
    },
    {
      "epoch": 0.5854716299241055,
      "grad_norm": 1.5943942070007324,
      "learning_rate": 1.4144578313253013e-05,
      "loss": 1.0708,
      "step": 2430
    },
    {
      "epoch": 0.5878809781953982,
      "grad_norm": 1.209542989730835,
      "learning_rate": 1.4120481927710844e-05,
      "loss": 1.0679,
      "step": 2440
    },
    {
      "epoch": 0.5902903264666908,
      "grad_norm": 1.3313206434249878,
      "learning_rate": 1.4096385542168676e-05,
      "loss": 1.0471,
      "step": 2450
    },
    {
      "epoch": 0.5926996747379834,
      "grad_norm": 1.2893224954605103,
      "learning_rate": 1.4072289156626506e-05,
      "loss": 1.0492,
      "step": 2460
    },
    {
      "epoch": 0.595109023009276,
      "grad_norm": 1.2975902557373047,
      "learning_rate": 1.404819277108434e-05,
      "loss": 1.0379,
      "step": 2470
    },
    {
      "epoch": 0.5975183712805686,
      "grad_norm": 1.202708125114441,
      "learning_rate": 1.402409638554217e-05,
      "loss": 1.0899,
      "step": 2480
    },
    {
      "epoch": 0.5999277195518612,
      "grad_norm": 1.3983291387557983,
      "learning_rate": 1.4e-05,
      "loss": 1.0453,
      "step": 2490
    },
    {
      "epoch": 0.6023370678231539,
      "grad_norm": 1.3143515586853027,
      "learning_rate": 1.3975903614457833e-05,
      "loss": 1.0249,
      "step": 2500
    },
    {
      "epoch": 0.6047464160944465,
      "grad_norm": 1.2963542938232422,
      "learning_rate": 1.3951807228915663e-05,
      "loss": 1.0288,
      "step": 2510
    },
    {
      "epoch": 0.607155764365739,
      "grad_norm": 1.537133812904358,
      "learning_rate": 1.3927710843373493e-05,
      "loss": 1.0508,
      "step": 2520
    },
    {
      "epoch": 0.6095651126370317,
      "grad_norm": 1.6918185949325562,
      "learning_rate": 1.3903614457831327e-05,
      "loss": 1.0687,
      "step": 2530
    },
    {
      "epoch": 0.6119744609083243,
      "grad_norm": 1.2960115671157837,
      "learning_rate": 1.3879518072289157e-05,
      "loss": 1.0372,
      "step": 2540
    },
    {
      "epoch": 0.6143838091796169,
      "grad_norm": 0.9670565128326416,
      "learning_rate": 1.3855421686746989e-05,
      "loss": 1.0349,
      "step": 2550
    },
    {
      "epoch": 0.6167931574509096,
      "grad_norm": 1.0521252155303955,
      "learning_rate": 1.383132530120482e-05,
      "loss": 0.9855,
      "step": 2560
    },
    {
      "epoch": 0.6192025057222021,
      "grad_norm": 1.2695661783218384,
      "learning_rate": 1.3807228915662652e-05,
      "loss": 1.0898,
      "step": 2570
    },
    {
      "epoch": 0.6216118539934947,
      "grad_norm": 1.3540352582931519,
      "learning_rate": 1.3783132530120482e-05,
      "loss": 1.0259,
      "step": 2580
    },
    {
      "epoch": 0.6240212022647874,
      "grad_norm": 1.3018428087234497,
      "learning_rate": 1.3759036144578316e-05,
      "loss": 1.0639,
      "step": 2590
    },
    {
      "epoch": 0.62643055053608,
      "grad_norm": 1.1728243827819824,
      "learning_rate": 1.3734939759036146e-05,
      "loss": 1.0373,
      "step": 2600
    },
    {
      "epoch": 0.6288398988073726,
      "grad_norm": 0.9277067184448242,
      "learning_rate": 1.3710843373493976e-05,
      "loss": 1.0499,
      "step": 2610
    },
    {
      "epoch": 0.6312492470786653,
      "grad_norm": 1.2825024127960205,
      "learning_rate": 1.368674698795181e-05,
      "loss": 1.0788,
      "step": 2620
    },
    {
      "epoch": 0.6336585953499578,
      "grad_norm": 0.9017518758773804,
      "learning_rate": 1.366265060240964e-05,
      "loss": 1.1115,
      "step": 2630
    },
    {
      "epoch": 0.6360679436212504,
      "grad_norm": 1.4473471641540527,
      "learning_rate": 1.363855421686747e-05,
      "loss": 1.1113,
      "step": 2640
    },
    {
      "epoch": 0.6384772918925431,
      "grad_norm": 1.1152899265289307,
      "learning_rate": 1.3614457831325303e-05,
      "loss": 1.0851,
      "step": 2650
    },
    {
      "epoch": 0.6408866401638357,
      "grad_norm": 1.0814735889434814,
      "learning_rate": 1.3590361445783133e-05,
      "loss": 1.0509,
      "step": 2660
    },
    {
      "epoch": 0.6432959884351283,
      "grad_norm": 1.409906268119812,
      "learning_rate": 1.3566265060240965e-05,
      "loss": 1.0257,
      "step": 2670
    },
    {
      "epoch": 0.6457053367064209,
      "grad_norm": 1.2779557704925537,
      "learning_rate": 1.3542168674698796e-05,
      "loss": 1.0726,
      "step": 2680
    },
    {
      "epoch": 0.6481146849777135,
      "grad_norm": 1.097123622894287,
      "learning_rate": 1.3518072289156628e-05,
      "loss": 1.0741,
      "step": 2690
    },
    {
      "epoch": 0.6505240332490061,
      "grad_norm": 1.271962285041809,
      "learning_rate": 1.3493975903614458e-05,
      "loss": 1.0451,
      "step": 2700
    },
    {
      "epoch": 0.6529333815202988,
      "grad_norm": 1.214073657989502,
      "learning_rate": 1.346987951807229e-05,
      "loss": 1.0413,
      "step": 2710
    },
    {
      "epoch": 0.6553427297915914,
      "grad_norm": 1.2177257537841797,
      "learning_rate": 1.3445783132530122e-05,
      "loss": 1.0567,
      "step": 2720
    },
    {
      "epoch": 0.6577520780628839,
      "grad_norm": 1.894587755203247,
      "learning_rate": 1.3421686746987952e-05,
      "loss": 1.049,
      "step": 2730
    },
    {
      "epoch": 0.6601614263341766,
      "grad_norm": 1.1642674207687378,
      "learning_rate": 1.3397590361445785e-05,
      "loss": 1.092,
      "step": 2740
    },
    {
      "epoch": 0.6625707746054692,
      "grad_norm": 0.8337126970291138,
      "learning_rate": 1.3373493975903615e-05,
      "loss": 1.0895,
      "step": 2750
    },
    {
      "epoch": 0.6649801228767618,
      "grad_norm": 1.0512491464614868,
      "learning_rate": 1.3349397590361445e-05,
      "loss": 1.0807,
      "step": 2760
    },
    {
      "epoch": 0.6673894711480545,
      "grad_norm": 1.3378207683563232,
      "learning_rate": 1.3325301204819279e-05,
      "loss": 1.0537,
      "step": 2770
    },
    {
      "epoch": 0.669798819419347,
      "grad_norm": 1.113577127456665,
      "learning_rate": 1.3301204819277109e-05,
      "loss": 1.0942,
      "step": 2780
    },
    {
      "epoch": 0.6722081676906397,
      "grad_norm": 1.0029550790786743,
      "learning_rate": 1.3277108433734939e-05,
      "loss": 1.0774,
      "step": 2790
    },
    {
      "epoch": 0.6746175159619323,
      "grad_norm": 1.2590173482894897,
      "learning_rate": 1.3253012048192772e-05,
      "loss": 1.1078,
      "step": 2800
    },
    {
      "epoch": 0.6770268642332249,
      "grad_norm": 1.2168339490890503,
      "learning_rate": 1.3228915662650603e-05,
      "loss": 1.0778,
      "step": 2810
    },
    {
      "epoch": 0.6794362125045176,
      "grad_norm": 1.1501671075820923,
      "learning_rate": 1.3204819277108434e-05,
      "loss": 1.0694,
      "step": 2820
    },
    {
      "epoch": 0.6818455607758102,
      "grad_norm": 1.2432115077972412,
      "learning_rate": 1.3180722891566266e-05,
      "loss": 1.0687,
      "step": 2830
    },
    {
      "epoch": 0.6842549090471027,
      "grad_norm": 1.2431529760360718,
      "learning_rate": 1.3156626506024098e-05,
      "loss": 1.0483,
      "step": 2840
    },
    {
      "epoch": 0.6866642573183954,
      "grad_norm": 0.9995725750923157,
      "learning_rate": 1.3132530120481928e-05,
      "loss": 1.0419,
      "step": 2850
    },
    {
      "epoch": 0.689073605589688,
      "grad_norm": 1.0947074890136719,
      "learning_rate": 1.3108433734939761e-05,
      "loss": 1.0355,
      "step": 2860
    },
    {
      "epoch": 0.6914829538609806,
      "grad_norm": 1.3645734786987305,
      "learning_rate": 1.3084337349397591e-05,
      "loss": 1.0357,
      "step": 2870
    },
    {
      "epoch": 0.6938923021322733,
      "grad_norm": 1.0784367322921753,
      "learning_rate": 1.3060240963855421e-05,
      "loss": 1.1065,
      "step": 2880
    },
    {
      "epoch": 0.6963016504035658,
      "grad_norm": 1.451483130455017,
      "learning_rate": 1.3036144578313255e-05,
      "loss": 1.0011,
      "step": 2890
    },
    {
      "epoch": 0.6987109986748584,
      "grad_norm": 1.0335642099380493,
      "learning_rate": 1.3012048192771085e-05,
      "loss": 1.067,
      "step": 2900
    },
    {
      "epoch": 0.7011203469461511,
      "grad_norm": 1.1702817678451538,
      "learning_rate": 1.2987951807228915e-05,
      "loss": 1.0697,
      "step": 2910
    },
    {
      "epoch": 0.7035296952174437,
      "grad_norm": 0.9623212814331055,
      "learning_rate": 1.2963855421686749e-05,
      "loss": 1.1092,
      "step": 2920
    },
    {
      "epoch": 0.7059390434887363,
      "grad_norm": 1.087522029876709,
      "learning_rate": 1.2939759036144579e-05,
      "loss": 1.0789,
      "step": 2930
    },
    {
      "epoch": 0.708348391760029,
      "grad_norm": 1.2138935327529907,
      "learning_rate": 1.291566265060241e-05,
      "loss": 1.0853,
      "step": 2940
    },
    {
      "epoch": 0.7107577400313215,
      "grad_norm": 1.544046401977539,
      "learning_rate": 1.2891566265060242e-05,
      "loss": 1.0577,
      "step": 2950
    },
    {
      "epoch": 0.7131670883026141,
      "grad_norm": 1.8348742723464966,
      "learning_rate": 1.2867469879518072e-05,
      "loss": 1.087,
      "step": 2960
    },
    {
      "epoch": 0.7155764365739068,
      "grad_norm": 1.0549408197402954,
      "learning_rate": 1.2843373493975904e-05,
      "loss": 1.09,
      "step": 2970
    },
    {
      "epoch": 0.7179857848451994,
      "grad_norm": 1.1676640510559082,
      "learning_rate": 1.2819277108433736e-05,
      "loss": 1.0357,
      "step": 2980
    },
    {
      "epoch": 0.720395133116492,
      "grad_norm": 1.3352258205413818,
      "learning_rate": 1.2795180722891567e-05,
      "loss": 1.0715,
      "step": 2990
    },
    {
      "epoch": 0.7228044813877846,
      "grad_norm": 1.313672423362732,
      "learning_rate": 1.2771084337349398e-05,
      "loss": 1.0029,
      "step": 3000
    },
    {
      "epoch": 0.7252138296590772,
      "grad_norm": 1.1628161668777466,
      "learning_rate": 1.2746987951807231e-05,
      "loss": 1.0659,
      "step": 3010
    },
    {
      "epoch": 0.7276231779303698,
      "grad_norm": 1.0737929344177246,
      "learning_rate": 1.2722891566265061e-05,
      "loss": 1.0613,
      "step": 3020
    },
    {
      "epoch": 0.7300325262016625,
      "grad_norm": 1.204840064048767,
      "learning_rate": 1.2698795180722891e-05,
      "loss": 1.0453,
      "step": 3030
    },
    {
      "epoch": 0.7324418744729551,
      "grad_norm": 1.299336314201355,
      "learning_rate": 1.2674698795180725e-05,
      "loss": 1.0287,
      "step": 3040
    },
    {
      "epoch": 0.7348512227442476,
      "grad_norm": 0.9885721802711487,
      "learning_rate": 1.2650602409638555e-05,
      "loss": 1.0569,
      "step": 3050
    },
    {
      "epoch": 0.7372605710155403,
      "grad_norm": 1.3819657564163208,
      "learning_rate": 1.2626506024096385e-05,
      "loss": 1.0805,
      "step": 3060
    },
    {
      "epoch": 0.7396699192868329,
      "grad_norm": 1.2249561548233032,
      "learning_rate": 1.2602409638554218e-05,
      "loss": 1.0686,
      "step": 3070
    },
    {
      "epoch": 0.7420792675581255,
      "grad_norm": 1.2627493143081665,
      "learning_rate": 1.2578313253012048e-05,
      "loss": 1.085,
      "step": 3080
    },
    {
      "epoch": 0.7444886158294182,
      "grad_norm": 1.069544792175293,
      "learning_rate": 1.255421686746988e-05,
      "loss": 1.0922,
      "step": 3090
    },
    {
      "epoch": 0.7468979641007107,
      "grad_norm": 0.8631856441497803,
      "learning_rate": 1.2530120481927712e-05,
      "loss": 1.0083,
      "step": 3100
    },
    {
      "epoch": 0.7493073123720033,
      "grad_norm": 1.3083171844482422,
      "learning_rate": 1.2506024096385544e-05,
      "loss": 1.0681,
      "step": 3110
    },
    {
      "epoch": 0.751716660643296,
      "grad_norm": 1.2350841760635376,
      "learning_rate": 1.2481927710843375e-05,
      "loss": 1.0621,
      "step": 3120
    },
    {
      "epoch": 0.7541260089145886,
      "grad_norm": 1.0158532857894897,
      "learning_rate": 1.2457831325301207e-05,
      "loss": 1.0651,
      "step": 3130
    },
    {
      "epoch": 0.7565353571858813,
      "grad_norm": 1.2366600036621094,
      "learning_rate": 1.2433734939759037e-05,
      "loss": 1.1004,
      "step": 3140
    },
    {
      "epoch": 0.7589447054571739,
      "grad_norm": 1.093170166015625,
      "learning_rate": 1.2409638554216869e-05,
      "loss": 1.0489,
      "step": 3150
    },
    {
      "epoch": 0.7613540537284664,
      "grad_norm": 1.3701095581054688,
      "learning_rate": 1.23855421686747e-05,
      "loss": 1.1068,
      "step": 3160
    },
    {
      "epoch": 0.7637634019997591,
      "grad_norm": 1.1338834762573242,
      "learning_rate": 1.236144578313253e-05,
      "loss": 1.0455,
      "step": 3170
    },
    {
      "epoch": 0.7661727502710517,
      "grad_norm": 0.9023853540420532,
      "learning_rate": 1.2337349397590364e-05,
      "loss": 1.1044,
      "step": 3180
    },
    {
      "epoch": 0.7685820985423443,
      "grad_norm": 1.3887590169906616,
      "learning_rate": 1.2313253012048194e-05,
      "loss": 1.0807,
      "step": 3190
    },
    {
      "epoch": 0.770991446813637,
      "grad_norm": 1.9590461254119873,
      "learning_rate": 1.2289156626506024e-05,
      "loss": 1.0332,
      "step": 3200
    },
    {
      "epoch": 0.7734007950849295,
      "grad_norm": 1.289347529411316,
      "learning_rate": 1.2265060240963858e-05,
      "loss": 1.0749,
      "step": 3210
    },
    {
      "epoch": 0.7758101433562221,
      "grad_norm": 1.2455658912658691,
      "learning_rate": 1.2240963855421688e-05,
      "loss": 1.0745,
      "step": 3220
    },
    {
      "epoch": 0.7782194916275148,
      "grad_norm": 1.415050745010376,
      "learning_rate": 1.2216867469879518e-05,
      "loss": 1.0361,
      "step": 3230
    },
    {
      "epoch": 0.7806288398988074,
      "grad_norm": 1.2445203065872192,
      "learning_rate": 1.2192771084337351e-05,
      "loss": 1.0592,
      "step": 3240
    },
    {
      "epoch": 0.7830381881701,
      "grad_norm": 0.8800524473190308,
      "learning_rate": 1.2168674698795181e-05,
      "loss": 1.0537,
      "step": 3250
    },
    {
      "epoch": 0.7854475364413926,
      "grad_norm": 1.2798070907592773,
      "learning_rate": 1.2144578313253013e-05,
      "loss": 1.0702,
      "step": 3260
    },
    {
      "epoch": 0.7878568847126852,
      "grad_norm": 1.481606125831604,
      "learning_rate": 1.2120481927710845e-05,
      "loss": 1.0465,
      "step": 3270
    },
    {
      "epoch": 0.7902662329839778,
      "grad_norm": 1.0579975843429565,
      "learning_rate": 1.2096385542168677e-05,
      "loss": 1.0809,
      "step": 3280
    },
    {
      "epoch": 0.7926755812552705,
      "grad_norm": 1.3933204412460327,
      "learning_rate": 1.2072289156626507e-05,
      "loss": 1.1084,
      "step": 3290
    },
    {
      "epoch": 0.7950849295265631,
      "grad_norm": 1.2217134237289429,
      "learning_rate": 1.204819277108434e-05,
      "loss": 1.0685,
      "step": 3300
    },
    {
      "epoch": 0.7974942777978556,
      "grad_norm": 1.2321386337280273,
      "learning_rate": 1.202409638554217e-05,
      "loss": 1.0918,
      "step": 3310
    },
    {
      "epoch": 0.7999036260691483,
      "grad_norm": 0.9320940971374512,
      "learning_rate": 1.2e-05,
      "loss": 1.074,
      "step": 3320
    },
    {
      "epoch": 0.8023129743404409,
      "grad_norm": 0.9462363123893738,
      "learning_rate": 1.1975903614457834e-05,
      "loss": 1.0715,
      "step": 3330
    },
    {
      "epoch": 0.8047223226117335,
      "grad_norm": 1.0891231298446655,
      "learning_rate": 1.1951807228915664e-05,
      "loss": 1.0573,
      "step": 3340
    },
    {
      "epoch": 0.8071316708830262,
      "grad_norm": 0.91768479347229,
      "learning_rate": 1.1927710843373494e-05,
      "loss": 1.104,
      "step": 3350
    },
    {
      "epoch": 0.8095410191543188,
      "grad_norm": 1.0414189100265503,
      "learning_rate": 1.1903614457831327e-05,
      "loss": 1.0752,
      "step": 3360
    },
    {
      "epoch": 0.8119503674256113,
      "grad_norm": 1.025572419166565,
      "learning_rate": 1.1879518072289157e-05,
      "loss": 1.0715,
      "step": 3370
    },
    {
      "epoch": 0.814359715696904,
      "grad_norm": 1.4587481021881104,
      "learning_rate": 1.185542168674699e-05,
      "loss": 1.1617,
      "step": 3380
    },
    {
      "epoch": 0.8167690639681966,
      "grad_norm": 1.2988139390945435,
      "learning_rate": 1.1831325301204821e-05,
      "loss": 1.0404,
      "step": 3390
    },
    {
      "epoch": 0.8191784122394892,
      "grad_norm": 1.1185351610183716,
      "learning_rate": 1.1807228915662651e-05,
      "loss": 1.001,
      "step": 3400
    },
    {
      "epoch": 0.8215877605107819,
      "grad_norm": 1.0958516597747803,
      "learning_rate": 1.1783132530120483e-05,
      "loss": 1.0311,
      "step": 3410
    },
    {
      "epoch": 0.8239971087820744,
      "grad_norm": 1.254984736442566,
      "learning_rate": 1.1759036144578315e-05,
      "loss": 1.0793,
      "step": 3420
    },
    {
      "epoch": 0.826406457053367,
      "grad_norm": 1.2261725664138794,
      "learning_rate": 1.1734939759036146e-05,
      "loss": 1.0789,
      "step": 3430
    },
    {
      "epoch": 0.8288158053246597,
      "grad_norm": 1.0799239873886108,
      "learning_rate": 1.1710843373493976e-05,
      "loss": 1.0468,
      "step": 3440
    },
    {
      "epoch": 0.8312251535959523,
      "grad_norm": 1.2760955095291138,
      "learning_rate": 1.168674698795181e-05,
      "loss": 1.0718,
      "step": 3450
    },
    {
      "epoch": 0.8336345018672449,
      "grad_norm": 1.1932228803634644,
      "learning_rate": 1.166265060240964e-05,
      "loss": 1.0406,
      "step": 3460
    },
    {
      "epoch": 0.8360438501385375,
      "grad_norm": 1.2222548723220825,
      "learning_rate": 1.163855421686747e-05,
      "loss": 1.0496,
      "step": 3470
    },
    {
      "epoch": 0.8384531984098301,
      "grad_norm": 1.102812647819519,
      "learning_rate": 1.1614457831325303e-05,
      "loss": 1.1028,
      "step": 3480
    },
    {
      "epoch": 0.8408625466811227,
      "grad_norm": 1.0112932920455933,
      "learning_rate": 1.1590361445783133e-05,
      "loss": 1.0418,
      "step": 3490
    },
    {
      "epoch": 0.8432718949524154,
      "grad_norm": 1.6207104921340942,
      "learning_rate": 1.1566265060240964e-05,
      "loss": 1.0639,
      "step": 3500
    },
    {
      "epoch": 0.845681243223708,
      "grad_norm": 0.9575868844985962,
      "learning_rate": 1.1542168674698797e-05,
      "loss": 1.0753,
      "step": 3510
    },
    {
      "epoch": 0.8480905914950007,
      "grad_norm": 1.104003667831421,
      "learning_rate": 1.1518072289156627e-05,
      "loss": 1.0661,
      "step": 3520
    },
    {
      "epoch": 0.8504999397662932,
      "grad_norm": 1.3745124340057373,
      "learning_rate": 1.1493975903614459e-05,
      "loss": 1.0822,
      "step": 3530
    },
    {
      "epoch": 0.8529092880375858,
      "grad_norm": 1.2038781642913818,
      "learning_rate": 1.146987951807229e-05,
      "loss": 1.0645,
      "step": 3540
    },
    {
      "epoch": 0.8553186363088785,
      "grad_norm": 1.093827724456787,
      "learning_rate": 1.1445783132530122e-05,
      "loss": 1.078,
      "step": 3550
    },
    {
      "epoch": 0.8577279845801711,
      "grad_norm": 1.1275607347488403,
      "learning_rate": 1.1421686746987952e-05,
      "loss": 1.056,
      "step": 3560
    },
    {
      "epoch": 0.8601373328514637,
      "grad_norm": 1.022834062576294,
      "learning_rate": 1.1397590361445786e-05,
      "loss": 1.0824,
      "step": 3570
    },
    {
      "epoch": 0.8625466811227563,
      "grad_norm": 0.9430524110794067,
      "learning_rate": 1.1373493975903616e-05,
      "loss": 1.0738,
      "step": 3580
    },
    {
      "epoch": 0.8649560293940489,
      "grad_norm": 1.0582646131515503,
      "learning_rate": 1.1349397590361446e-05,
      "loss": 1.0982,
      "step": 3590
    },
    {
      "epoch": 0.8673653776653415,
      "grad_norm": 1.2372702360153198,
      "learning_rate": 1.132530120481928e-05,
      "loss": 1.0851,
      "step": 3600
    },
    {
      "epoch": 0.8697747259366342,
      "grad_norm": 1.423063039779663,
      "learning_rate": 1.130120481927711e-05,
      "loss": 1.09,
      "step": 3610
    },
    {
      "epoch": 0.8721840742079268,
      "grad_norm": 1.4239047765731812,
      "learning_rate": 1.127710843373494e-05,
      "loss": 1.0613,
      "step": 3620
    },
    {
      "epoch": 0.8745934224792193,
      "grad_norm": 0.9529085755348206,
      "learning_rate": 1.1253012048192773e-05,
      "loss": 1.0512,
      "step": 3630
    },
    {
      "epoch": 0.877002770750512,
      "grad_norm": 1.2654656171798706,
      "learning_rate": 1.1228915662650603e-05,
      "loss": 1.1182,
      "step": 3640
    },
    {
      "epoch": 0.8794121190218046,
      "grad_norm": 1.4972842931747437,
      "learning_rate": 1.1204819277108435e-05,
      "loss": 1.048,
      "step": 3650
    },
    {
      "epoch": 0.8818214672930972,
      "grad_norm": 0.9709852933883667,
      "learning_rate": 1.1180722891566267e-05,
      "loss": 1.0554,
      "step": 3660
    },
    {
      "epoch": 0.8842308155643899,
      "grad_norm": 1.2554410696029663,
      "learning_rate": 1.1156626506024097e-05,
      "loss": 1.0678,
      "step": 3670
    },
    {
      "epoch": 0.8866401638356824,
      "grad_norm": 0.9628530740737915,
      "learning_rate": 1.1132530120481928e-05,
      "loss": 1.1404,
      "step": 3680
    },
    {
      "epoch": 0.889049512106975,
      "grad_norm": 1.095138430595398,
      "learning_rate": 1.110843373493976e-05,
      "loss": 1.0482,
      "step": 3690
    },
    {
      "epoch": 0.8914588603782677,
      "grad_norm": 1.1658117771148682,
      "learning_rate": 1.1084337349397592e-05,
      "loss": 1.1017,
      "step": 3700
    },
    {
      "epoch": 0.8938682086495603,
      "grad_norm": 1.3945298194885254,
      "learning_rate": 1.1060240963855422e-05,
      "loss": 1.0595,
      "step": 3710
    },
    {
      "epoch": 0.8962775569208529,
      "grad_norm": 1.4431962966918945,
      "learning_rate": 1.1036144578313255e-05,
      "loss": 0.9944,
      "step": 3720
    },
    {
      "epoch": 0.8986869051921456,
      "grad_norm": 1.2830113172531128,
      "learning_rate": 1.1012048192771086e-05,
      "loss": 1.0284,
      "step": 3730
    },
    {
      "epoch": 0.9010962534634381,
      "grad_norm": 1.4337266683578491,
      "learning_rate": 1.0987951807228916e-05,
      "loss": 1.0663,
      "step": 3740
    },
    {
      "epoch": 0.9035056017347307,
      "grad_norm": 1.470160961151123,
      "learning_rate": 1.0963855421686749e-05,
      "loss": 1.118,
      "step": 3750
    },
    {
      "epoch": 0.9059149500060234,
      "grad_norm": 1.8030811548233032,
      "learning_rate": 1.0939759036144579e-05,
      "loss": 1.0286,
      "step": 3760
    },
    {
      "epoch": 0.908324298277316,
      "grad_norm": 1.500046968460083,
      "learning_rate": 1.091566265060241e-05,
      "loss": 1.0757,
      "step": 3770
    },
    {
      "epoch": 0.9107336465486086,
      "grad_norm": 1.3380200862884521,
      "learning_rate": 1.0891566265060243e-05,
      "loss": 1.0968,
      "step": 3780
    },
    {
      "epoch": 0.9131429948199012,
      "grad_norm": 1.097645878791809,
      "learning_rate": 1.0867469879518073e-05,
      "loss": 1.0706,
      "step": 3790
    },
    {
      "epoch": 0.9155523430911938,
      "grad_norm": 1.4178792238235474,
      "learning_rate": 1.0843373493975904e-05,
      "loss": 1.0399,
      "step": 3800
    },
    {
      "epoch": 0.9179616913624864,
      "grad_norm": 1.1937217712402344,
      "learning_rate": 1.0819277108433736e-05,
      "loss": 1.0655,
      "step": 3810
    },
    {
      "epoch": 0.9203710396337791,
      "grad_norm": 0.9505431652069092,
      "learning_rate": 1.0795180722891568e-05,
      "loss": 1.0231,
      "step": 3820
    },
    {
      "epoch": 0.9227803879050717,
      "grad_norm": 1.264988899230957,
      "learning_rate": 1.0771084337349398e-05,
      "loss": 1.03,
      "step": 3830
    },
    {
      "epoch": 0.9251897361763642,
      "grad_norm": 0.8678158521652222,
      "learning_rate": 1.074698795180723e-05,
      "loss": 1.0069,
      "step": 3840
    },
    {
      "epoch": 0.9275990844476569,
      "grad_norm": 1.2234654426574707,
      "learning_rate": 1.0722891566265062e-05,
      "loss": 1.062,
      "step": 3850
    },
    {
      "epoch": 0.9300084327189495,
      "grad_norm": 1.4451696872711182,
      "learning_rate": 1.0698795180722892e-05,
      "loss": 1.0679,
      "step": 3860
    },
    {
      "epoch": 0.9324177809902421,
      "grad_norm": 1.623793125152588,
      "learning_rate": 1.0674698795180725e-05,
      "loss": 1.1061,
      "step": 3870
    },
    {
      "epoch": 0.9348271292615348,
      "grad_norm": 1.0387338399887085,
      "learning_rate": 1.0650602409638555e-05,
      "loss": 1.0448,
      "step": 3880
    },
    {
      "epoch": 0.9372364775328274,
      "grad_norm": 1.1788618564605713,
      "learning_rate": 1.0626506024096385e-05,
      "loss": 1.106,
      "step": 3890
    },
    {
      "epoch": 0.93964582580412,
      "grad_norm": 1.0842303037643433,
      "learning_rate": 1.0602409638554219e-05,
      "loss": 1.0207,
      "step": 3900
    },
    {
      "epoch": 0.9420551740754126,
      "grad_norm": 1.2815858125686646,
      "learning_rate": 1.0578313253012049e-05,
      "loss": 1.0542,
      "step": 3910
    },
    {
      "epoch": 0.9444645223467052,
      "grad_norm": 1.1277310848236084,
      "learning_rate": 1.055421686746988e-05,
      "loss": 1.0805,
      "step": 3920
    },
    {
      "epoch": 0.9468738706179979,
      "grad_norm": 1.0634822845458984,
      "learning_rate": 1.0530120481927712e-05,
      "loss": 1.0862,
      "step": 3930
    },
    {
      "epoch": 0.9492832188892905,
      "grad_norm": 1.0224390029907227,
      "learning_rate": 1.0506024096385542e-05,
      "loss": 1.0936,
      "step": 3940
    },
    {
      "epoch": 0.951692567160583,
      "grad_norm": 0.9791370630264282,
      "learning_rate": 1.0481927710843374e-05,
      "loss": 1.0781,
      "step": 3950
    },
    {
      "epoch": 0.9541019154318757,
      "grad_norm": 1.2072722911834717,
      "learning_rate": 1.0457831325301206e-05,
      "loss": 1.0552,
      "step": 3960
    },
    {
      "epoch": 0.9565112637031683,
      "grad_norm": 0.9098756909370422,
      "learning_rate": 1.0433734939759038e-05,
      "loss": 1.0542,
      "step": 3970
    },
    {
      "epoch": 0.9589206119744609,
      "grad_norm": 1.6675397157669067,
      "learning_rate": 1.0409638554216868e-05,
      "loss": 1.0479,
      "step": 3980
    },
    {
      "epoch": 0.9613299602457536,
      "grad_norm": 1.298235297203064,
      "learning_rate": 1.0385542168674701e-05,
      "loss": 1.0616,
      "step": 3990
    },
    {
      "epoch": 0.9637393085170461,
      "grad_norm": 1.1132138967514038,
      "learning_rate": 1.0361445783132531e-05,
      "loss": 1.0037,
      "step": 4000
    },
    {
      "epoch": 0.9661486567883387,
      "grad_norm": 0.9633668065071106,
      "learning_rate": 1.0337349397590361e-05,
      "loss": 1.0344,
      "step": 4010
    },
    {
      "epoch": 0.9685580050596314,
      "grad_norm": 1.0440102815628052,
      "learning_rate": 1.0313253012048195e-05,
      "loss": 1.0683,
      "step": 4020
    },
    {
      "epoch": 0.970967353330924,
      "grad_norm": 0.9898460507392883,
      "learning_rate": 1.0289156626506025e-05,
      "loss": 1.0255,
      "step": 4030
    },
    {
      "epoch": 0.9733767016022166,
      "grad_norm": 1.1561310291290283,
      "learning_rate": 1.0265060240963855e-05,
      "loss": 1.0466,
      "step": 4040
    },
    {
      "epoch": 0.9757860498735093,
      "grad_norm": 0.8030654788017273,
      "learning_rate": 1.0240963855421688e-05,
      "loss": 1.0045,
      "step": 4050
    },
    {
      "epoch": 0.9781953981448018,
      "grad_norm": 1.551672101020813,
      "learning_rate": 1.0216867469879518e-05,
      "loss": 1.0599,
      "step": 4060
    },
    {
      "epoch": 0.9806047464160944,
      "grad_norm": 1.2245995998382568,
      "learning_rate": 1.019277108433735e-05,
      "loss": 1.1141,
      "step": 4070
    },
    {
      "epoch": 0.9830140946873871,
      "grad_norm": 1.0136462450027466,
      "learning_rate": 1.0168674698795182e-05,
      "loss": 1.0733,
      "step": 4080
    },
    {
      "epoch": 0.9854234429586797,
      "grad_norm": 1.4626801013946533,
      "learning_rate": 1.0144578313253014e-05,
      "loss": 1.025,
      "step": 4090
    },
    {
      "epoch": 0.9878327912299723,
      "grad_norm": 1.2209069728851318,
      "learning_rate": 1.0120481927710844e-05,
      "loss": 1.0438,
      "step": 4100
    },
    {
      "epoch": 0.9902421395012649,
      "grad_norm": 1.2005772590637207,
      "learning_rate": 1.0096385542168675e-05,
      "loss": 1.0717,
      "step": 4110
    },
    {
      "epoch": 0.9926514877725575,
      "grad_norm": 1.1214889287948608,
      "learning_rate": 1.0072289156626507e-05,
      "loss": 1.1057,
      "step": 4120
    },
    {
      "epoch": 0.9950608360438501,
      "grad_norm": 1.422575831413269,
      "learning_rate": 1.0048192771084337e-05,
      "loss": 1.0323,
      "step": 4130
    },
    {
      "epoch": 0.9974701843151428,
      "grad_norm": 1.4101718664169312,
      "learning_rate": 1.002409638554217e-05,
      "loss": 1.0825,
      "step": 4140
    },
    {
      "epoch": 0.9998795325864354,
      "grad_norm": 1.0636157989501953,
      "learning_rate": 1e-05,
      "loss": 1.0537,
      "step": 4150
    },
    {
      "epoch": 1.0021684134441633,
      "grad_norm": 0.955389142036438,
      "learning_rate": 9.975903614457833e-06,
      "loss": 1.1163,
      "step": 4160
    },
    {
      "epoch": 1.0045777617154559,
      "grad_norm": 1.0848870277404785,
      "learning_rate": 9.951807228915663e-06,
      "loss": 1.0895,
      "step": 4170
    },
    {
      "epoch": 1.0069871099867487,
      "grad_norm": 1.367184042930603,
      "learning_rate": 9.927710843373494e-06,
      "loss": 1.0624,
      "step": 4180
    },
    {
      "epoch": 1.0093964582580413,
      "grad_norm": 1.5451687574386597,
      "learning_rate": 9.903614457831326e-06,
      "loss": 1.0325,
      "step": 4190
    },
    {
      "epoch": 1.0118058065293338,
      "grad_norm": 1.0595101118087769,
      "learning_rate": 9.879518072289156e-06,
      "loss": 1.1055,
      "step": 4200
    },
    {
      "epoch": 1.0142151548006264,
      "grad_norm": 1.0381519794464111,
      "learning_rate": 9.855421686746988e-06,
      "loss": 1.0783,
      "step": 4210
    },
    {
      "epoch": 1.016624503071919,
      "grad_norm": 1.231255292892456,
      "learning_rate": 9.83132530120482e-06,
      "loss": 1.0444,
      "step": 4220
    },
    {
      "epoch": 1.0190338513432116,
      "grad_norm": 1.1485296487808228,
      "learning_rate": 9.807228915662652e-06,
      "loss": 1.0229,
      "step": 4230
    },
    {
      "epoch": 1.0214431996145044,
      "grad_norm": 1.2274607419967651,
      "learning_rate": 9.783132530120483e-06,
      "loss": 1.0842,
      "step": 4240
    },
    {
      "epoch": 1.023852547885797,
      "grad_norm": 1.1313589811325073,
      "learning_rate": 9.759036144578315e-06,
      "loss": 1.0432,
      "step": 4250
    },
    {
      "epoch": 1.0262618961570895,
      "grad_norm": 1.080929160118103,
      "learning_rate": 9.734939759036145e-06,
      "loss": 1.0494,
      "step": 4260
    },
    {
      "epoch": 1.028671244428382,
      "grad_norm": 1.7524614334106445,
      "learning_rate": 9.710843373493977e-06,
      "loss": 1.0401,
      "step": 4270
    },
    {
      "epoch": 1.0310805926996747,
      "grad_norm": 1.0978189706802368,
      "learning_rate": 9.686746987951809e-06,
      "loss": 1.0096,
      "step": 4280
    },
    {
      "epoch": 1.0334899409709672,
      "grad_norm": 1.141692042350769,
      "learning_rate": 9.662650602409639e-06,
      "loss": 1.0884,
      "step": 4290
    },
    {
      "epoch": 1.03589928924226,
      "grad_norm": 1.3385634422302246,
      "learning_rate": 9.63855421686747e-06,
      "loss": 1.0081,
      "step": 4300
    },
    {
      "epoch": 1.0383086375135526,
      "grad_norm": 1.61892831325531,
      "learning_rate": 9.614457831325302e-06,
      "loss": 1.0197,
      "step": 4310
    },
    {
      "epoch": 1.0407179857848452,
      "grad_norm": 0.9347498416900635,
      "learning_rate": 9.590361445783132e-06,
      "loss": 1.0475,
      "step": 4320
    },
    {
      "epoch": 1.0431273340561378,
      "grad_norm": 1.0301589965820312,
      "learning_rate": 9.566265060240964e-06,
      "loss": 1.0676,
      "step": 4330
    },
    {
      "epoch": 1.0455366823274304,
      "grad_norm": 1.2534948587417603,
      "learning_rate": 9.542168674698796e-06,
      "loss": 1.1123,
      "step": 4340
    },
    {
      "epoch": 1.0479460305987232,
      "grad_norm": 0.9216567873954773,
      "learning_rate": 9.518072289156628e-06,
      "loss": 1.0512,
      "step": 4350
    },
    {
      "epoch": 1.0503553788700157,
      "grad_norm": 1.1916710138320923,
      "learning_rate": 9.49397590361446e-06,
      "loss": 1.1119,
      "step": 4360
    },
    {
      "epoch": 1.0527647271413083,
      "grad_norm": 1.5539271831512451,
      "learning_rate": 9.46987951807229e-06,
      "loss": 1.0597,
      "step": 4370
    },
    {
      "epoch": 1.0551740754126009,
      "grad_norm": 2.380866289138794,
      "learning_rate": 9.445783132530121e-06,
      "loss": 1.0729,
      "step": 4380
    },
    {
      "epoch": 1.0575834236838935,
      "grad_norm": 1.1516473293304443,
      "learning_rate": 9.421686746987953e-06,
      "loss": 1.0802,
      "step": 4390
    },
    {
      "epoch": 1.059992771955186,
      "grad_norm": 1.029326319694519,
      "learning_rate": 9.397590361445785e-06,
      "loss": 0.9839,
      "step": 4400
    },
    {
      "epoch": 1.0624021202264788,
      "grad_norm": 1.418312430381775,
      "learning_rate": 9.373493975903615e-06,
      "loss": 1.0254,
      "step": 4410
    },
    {
      "epoch": 1.0648114684977714,
      "grad_norm": 1.3476191759109497,
      "learning_rate": 9.349397590361446e-06,
      "loss": 1.088,
      "step": 4420
    },
    {
      "epoch": 1.067220816769064,
      "grad_norm": 1.103535532951355,
      "learning_rate": 9.325301204819278e-06,
      "loss": 1.0606,
      "step": 4430
    },
    {
      "epoch": 1.0696301650403566,
      "grad_norm": 1.0361087322235107,
      "learning_rate": 9.301204819277108e-06,
      "loss": 1.0686,
      "step": 4440
    },
    {
      "epoch": 1.0720395133116492,
      "grad_norm": 1.2954866886138916,
      "learning_rate": 9.27710843373494e-06,
      "loss": 1.0685,
      "step": 4450
    },
    {
      "epoch": 1.0744488615829417,
      "grad_norm": 1.3358248472213745,
      "learning_rate": 9.253012048192772e-06,
      "loss": 0.9913,
      "step": 4460
    },
    {
      "epoch": 1.0768582098542345,
      "grad_norm": 1.2157261371612549,
      "learning_rate": 9.228915662650602e-06,
      "loss": 1.1036,
      "step": 4470
    },
    {
      "epoch": 1.079267558125527,
      "grad_norm": 1.5637160539627075,
      "learning_rate": 9.204819277108434e-06,
      "loss": 1.0718,
      "step": 4480
    },
    {
      "epoch": 1.0816769063968197,
      "grad_norm": 0.8671002984046936,
      "learning_rate": 9.180722891566265e-06,
      "loss": 1.0767,
      "step": 4490
    },
    {
      "epoch": 1.0840862546681123,
      "grad_norm": 1.074159860610962,
      "learning_rate": 9.156626506024097e-06,
      "loss": 1.0208,
      "step": 4500
    },
    {
      "epoch": 1.0864956029394048,
      "grad_norm": 0.937670886516571,
      "learning_rate": 9.132530120481929e-06,
      "loss": 1.0414,
      "step": 4510
    },
    {
      "epoch": 1.0889049512106974,
      "grad_norm": 1.0369689464569092,
      "learning_rate": 9.10843373493976e-06,
      "loss": 1.0276,
      "step": 4520
    },
    {
      "epoch": 1.0913142994819902,
      "grad_norm": 1.3966270685195923,
      "learning_rate": 9.08433734939759e-06,
      "loss": 1.0727,
      "step": 4530
    },
    {
      "epoch": 1.0937236477532828,
      "grad_norm": 0.9382047653198242,
      "learning_rate": 9.060240963855423e-06,
      "loss": 1.1121,
      "step": 4540
    },
    {
      "epoch": 1.0961329960245754,
      "grad_norm": 0.9806634783744812,
      "learning_rate": 9.036144578313254e-06,
      "loss": 1.0284,
      "step": 4550
    },
    {
      "epoch": 1.098542344295868,
      "grad_norm": 1.267842411994934,
      "learning_rate": 9.012048192771084e-06,
      "loss": 1.0293,
      "step": 4560
    },
    {
      "epoch": 1.1009516925671605,
      "grad_norm": 1.082773208618164,
      "learning_rate": 8.987951807228916e-06,
      "loss": 1.0981,
      "step": 4570
    },
    {
      "epoch": 1.103361040838453,
      "grad_norm": 1.0066516399383545,
      "learning_rate": 8.963855421686748e-06,
      "loss": 0.9759,
      "step": 4580
    },
    {
      "epoch": 1.105770389109746,
      "grad_norm": 1.1686195135116577,
      "learning_rate": 8.939759036144578e-06,
      "loss": 1.0504,
      "step": 4590
    },
    {
      "epoch": 1.1081797373810385,
      "grad_norm": 1.2521581649780273,
      "learning_rate": 8.91566265060241e-06,
      "loss": 1.0743,
      "step": 4600
    },
    {
      "epoch": 1.110589085652331,
      "grad_norm": 1.0243265628814697,
      "learning_rate": 8.891566265060241e-06,
      "loss": 1.0751,
      "step": 4610
    },
    {
      "epoch": 1.1129984339236236,
      "grad_norm": 1.1355316638946533,
      "learning_rate": 8.867469879518073e-06,
      "loss": 1.0256,
      "step": 4620
    },
    {
      "epoch": 1.1154077821949162,
      "grad_norm": 1.0975579023361206,
      "learning_rate": 8.843373493975905e-06,
      "loss": 1.0288,
      "step": 4630
    },
    {
      "epoch": 1.117817130466209,
      "grad_norm": 1.338641881942749,
      "learning_rate": 8.819277108433735e-06,
      "loss": 0.9902,
      "step": 4640
    },
    {
      "epoch": 1.1202264787375016,
      "grad_norm": 0.9319366812705994,
      "learning_rate": 8.795180722891567e-06,
      "loss": 1.0651,
      "step": 4650
    },
    {
      "epoch": 1.1226358270087942,
      "grad_norm": 0.9530186653137207,
      "learning_rate": 8.771084337349399e-06,
      "loss": 1.0668,
      "step": 4660
    },
    {
      "epoch": 1.1250451752800867,
      "grad_norm": 1.2884771823883057,
      "learning_rate": 8.74698795180723e-06,
      "loss": 1.0194,
      "step": 4670
    },
    {
      "epoch": 1.1274545235513793,
      "grad_norm": 1.131054162979126,
      "learning_rate": 8.722891566265062e-06,
      "loss": 1.02,
      "step": 4680
    },
    {
      "epoch": 1.129863871822672,
      "grad_norm": 1.2349952459335327,
      "learning_rate": 8.698795180722892e-06,
      "loss": 0.9956,
      "step": 4690
    },
    {
      "epoch": 1.1322732200939645,
      "grad_norm": 1.1912950277328491,
      "learning_rate": 8.674698795180724e-06,
      "loss": 1.0503,
      "step": 4700
    },
    {
      "epoch": 1.1346825683652573,
      "grad_norm": 0.8741796016693115,
      "learning_rate": 8.650602409638556e-06,
      "loss": 1.0133,
      "step": 4710
    },
    {
      "epoch": 1.1370919166365498,
      "grad_norm": 1.327195405960083,
      "learning_rate": 8.626506024096386e-06,
      "loss": 1.0751,
      "step": 4720
    },
    {
      "epoch": 1.1395012649078424,
      "grad_norm": 1.5031870603561401,
      "learning_rate": 8.602409638554217e-06,
      "loss": 1.0807,
      "step": 4730
    },
    {
      "epoch": 1.141910613179135,
      "grad_norm": 1.8642405271530151,
      "learning_rate": 8.57831325301205e-06,
      "loss": 1.0753,
      "step": 4740
    },
    {
      "epoch": 1.1443199614504276,
      "grad_norm": 1.1728261709213257,
      "learning_rate": 8.55421686746988e-06,
      "loss": 1.0833,
      "step": 4750
    },
    {
      "epoch": 1.1467293097217204,
      "grad_norm": 1.3073495626449585,
      "learning_rate": 8.530120481927711e-06,
      "loss": 1.1041,
      "step": 4760
    },
    {
      "epoch": 1.149138657993013,
      "grad_norm": 1.6029847860336304,
      "learning_rate": 8.506024096385543e-06,
      "loss": 1.0417,
      "step": 4770
    },
    {
      "epoch": 1.1515480062643055,
      "grad_norm": 1.5043456554412842,
      "learning_rate": 8.481927710843375e-06,
      "loss": 1.084,
      "step": 4780
    },
    {
      "epoch": 1.1539573545355981,
      "grad_norm": 1.205965518951416,
      "learning_rate": 8.457831325301206e-06,
      "loss": 1.0554,
      "step": 4790
    },
    {
      "epoch": 1.1563667028068907,
      "grad_norm": 1.0394619703292847,
      "learning_rate": 8.433734939759038e-06,
      "loss": 1.0438,
      "step": 4800
    },
    {
      "epoch": 1.1587760510781833,
      "grad_norm": 1.0974881649017334,
      "learning_rate": 8.409638554216868e-06,
      "loss": 1.0468,
      "step": 4810
    },
    {
      "epoch": 1.1611853993494758,
      "grad_norm": 1.1654354333877563,
      "learning_rate": 8.3855421686747e-06,
      "loss": 1.041,
      "step": 4820
    },
    {
      "epoch": 1.1635947476207686,
      "grad_norm": 1.2970919609069824,
      "learning_rate": 8.361445783132532e-06,
      "loss": 1.0713,
      "step": 4830
    },
    {
      "epoch": 1.1660040958920612,
      "grad_norm": 1.1126515865325928,
      "learning_rate": 8.337349397590362e-06,
      "loss": 1.023,
      "step": 4840
    },
    {
      "epoch": 1.1684134441633538,
      "grad_norm": 1.2143535614013672,
      "learning_rate": 8.313253012048194e-06,
      "loss": 1.0341,
      "step": 4850
    },
    {
      "epoch": 1.1708227924346464,
      "grad_norm": 1.272957682609558,
      "learning_rate": 8.289156626506025e-06,
      "loss": 1.0624,
      "step": 4860
    },
    {
      "epoch": 1.173232140705939,
      "grad_norm": 1.0081696510314941,
      "learning_rate": 8.265060240963855e-06,
      "loss": 1.0825,
      "step": 4870
    },
    {
      "epoch": 1.1756414889772318,
      "grad_norm": 1.326224684715271,
      "learning_rate": 8.240963855421687e-06,
      "loss": 1.1077,
      "step": 4880
    },
    {
      "epoch": 1.1780508372485243,
      "grad_norm": 0.999954342842102,
      "learning_rate": 8.216867469879519e-06,
      "loss": 1.0629,
      "step": 4890
    },
    {
      "epoch": 1.180460185519817,
      "grad_norm": 1.2020612955093384,
      "learning_rate": 8.19277108433735e-06,
      "loss": 1.0342,
      "step": 4900
    },
    {
      "epoch": 1.1828695337911095,
      "grad_norm": 1.0803396701812744,
      "learning_rate": 8.16867469879518e-06,
      "loss": 1.098,
      "step": 4910
    },
    {
      "epoch": 1.185278882062402,
      "grad_norm": 1.0082823038101196,
      "learning_rate": 8.144578313253012e-06,
      "loss": 1.0551,
      "step": 4920
    },
    {
      "epoch": 1.1876882303336946,
      "grad_norm": 1.1964569091796875,
      "learning_rate": 8.120481927710844e-06,
      "loss": 1.0418,
      "step": 4930
    },
    {
      "epoch": 1.1900975786049874,
      "grad_norm": 1.3007863759994507,
      "learning_rate": 8.096385542168676e-06,
      "loss": 1.0381,
      "step": 4940
    },
    {
      "epoch": 1.19250692687628,
      "grad_norm": 1.81092369556427,
      "learning_rate": 8.072289156626508e-06,
      "loss": 1.0615,
      "step": 4950
    },
    {
      "epoch": 1.1949162751475726,
      "grad_norm": 0.9774757027626038,
      "learning_rate": 8.048192771084338e-06,
      "loss": 1.0917,
      "step": 4960
    },
    {
      "epoch": 1.1973256234188652,
      "grad_norm": 1.1072337627410889,
      "learning_rate": 8.02409638554217e-06,
      "loss": 1.1213,
      "step": 4970
    },
    {
      "epoch": 1.1997349716901577,
      "grad_norm": 1.3430124521255493,
      "learning_rate": 8.000000000000001e-06,
      "loss": 1.0784,
      "step": 4980
    },
    {
      "epoch": 1.2021443199614503,
      "grad_norm": 1.4410043954849243,
      "learning_rate": 7.975903614457831e-06,
      "loss": 1.1124,
      "step": 4990
    },
    {
      "epoch": 1.2045536682327431,
      "grad_norm": 1.042974591255188,
      "learning_rate": 7.951807228915663e-06,
      "loss": 1.0101,
      "step": 5000
    },
    {
      "epoch": 1.2069630165040357,
      "grad_norm": 1.0219943523406982,
      "learning_rate": 7.927710843373495e-06,
      "loss": 1.022,
      "step": 5010
    },
    {
      "epoch": 1.2093723647753283,
      "grad_norm": 1.0661191940307617,
      "learning_rate": 7.903614457831325e-06,
      "loss": 1.0961,
      "step": 5020
    },
    {
      "epoch": 1.2117817130466209,
      "grad_norm": 1.339909315109253,
      "learning_rate": 7.879518072289157e-06,
      "loss": 1.0847,
      "step": 5030
    },
    {
      "epoch": 1.2141910613179134,
      "grad_norm": 1.1465933322906494,
      "learning_rate": 7.855421686746989e-06,
      "loss": 1.0573,
      "step": 5040
    },
    {
      "epoch": 1.2166004095892062,
      "grad_norm": 1.5044342279434204,
      "learning_rate": 7.83132530120482e-06,
      "loss": 1.1167,
      "step": 5050
    },
    {
      "epoch": 1.2190097578604988,
      "grad_norm": 1.1372592449188232,
      "learning_rate": 7.807228915662652e-06,
      "loss": 1.0706,
      "step": 5060
    },
    {
      "epoch": 1.2214191061317914,
      "grad_norm": 1.3615247011184692,
      "learning_rate": 7.783132530120484e-06,
      "loss": 1.0475,
      "step": 5070
    },
    {
      "epoch": 1.223828454403084,
      "grad_norm": 0.9810908436775208,
      "learning_rate": 7.759036144578314e-06,
      "loss": 1.0649,
      "step": 5080
    },
    {
      "epoch": 1.2262378026743765,
      "grad_norm": 1.3029550313949585,
      "learning_rate": 7.734939759036146e-06,
      "loss": 1.0139,
      "step": 5090
    },
    {
      "epoch": 1.2286471509456691,
      "grad_norm": 1.0340381860733032,
      "learning_rate": 7.710843373493977e-06,
      "loss": 1.065,
      "step": 5100
    },
    {
      "epoch": 1.2310564992169617,
      "grad_norm": 1.2936744689941406,
      "learning_rate": 7.686746987951807e-06,
      "loss": 1.0493,
      "step": 5110
    },
    {
      "epoch": 1.2334658474882545,
      "grad_norm": 1.0064294338226318,
      "learning_rate": 7.66265060240964e-06,
      "loss": 1.0675,
      "step": 5120
    },
    {
      "epoch": 1.235875195759547,
      "grad_norm": 1.059748888015747,
      "learning_rate": 7.638554216867471e-06,
      "loss": 1.0537,
      "step": 5130
    },
    {
      "epoch": 1.2382845440308397,
      "grad_norm": 1.111546277999878,
      "learning_rate": 7.614457831325302e-06,
      "loss": 1.0956,
      "step": 5140
    },
    {
      "epoch": 1.2406938923021322,
      "grad_norm": 1.0284005403518677,
      "learning_rate": 7.590361445783133e-06,
      "loss": 1.0494,
      "step": 5150
    },
    {
      "epoch": 1.2431032405734248,
      "grad_norm": 0.9329355359077454,
      "learning_rate": 7.5662650602409645e-06,
      "loss": 1.0617,
      "step": 5160
    },
    {
      "epoch": 1.2455125888447176,
      "grad_norm": 1.127557635307312,
      "learning_rate": 7.5421686746987955e-06,
      "loss": 1.0108,
      "step": 5170
    },
    {
      "epoch": 1.2479219371160102,
      "grad_norm": 0.8533710241317749,
      "learning_rate": 7.518072289156627e-06,
      "loss": 0.9798,
      "step": 5180
    },
    {
      "epoch": 1.2503312853873028,
      "grad_norm": 1.2544535398483276,
      "learning_rate": 7.493975903614459e-06,
      "loss": 1.0763,
      "step": 5190
    },
    {
      "epoch": 1.2527406336585953,
      "grad_norm": 1.2264515161514282,
      "learning_rate": 7.469879518072289e-06,
      "loss": 1.019,
      "step": 5200
    },
    {
      "epoch": 1.255149981929888,
      "grad_norm": 1.122025489807129,
      "learning_rate": 7.445783132530121e-06,
      "loss": 1.0682,
      "step": 5210
    },
    {
      "epoch": 1.2575593302011807,
      "grad_norm": 1.0614445209503174,
      "learning_rate": 7.4216867469879526e-06,
      "loss": 1.083,
      "step": 5220
    },
    {
      "epoch": 1.259968678472473,
      "grad_norm": 1.090955376625061,
      "learning_rate": 7.3975903614457835e-06,
      "loss": 1.0417,
      "step": 5230
    },
    {
      "epoch": 1.2623780267437659,
      "grad_norm": 1.3459092378616333,
      "learning_rate": 7.373493975903615e-06,
      "loss": 1.0701,
      "step": 5240
    },
    {
      "epoch": 1.2647873750150584,
      "grad_norm": 1.3863816261291504,
      "learning_rate": 7.349397590361447e-06,
      "loss": 1.0537,
      "step": 5250
    },
    {
      "epoch": 1.267196723286351,
      "grad_norm": 1.410431146621704,
      "learning_rate": 7.325301204819277e-06,
      "loss": 1.0691,
      "step": 5260
    },
    {
      "epoch": 1.2696060715576436,
      "grad_norm": 1.5664578676223755,
      "learning_rate": 7.301204819277109e-06,
      "loss": 1.0419,
      "step": 5270
    },
    {
      "epoch": 1.2720154198289362,
      "grad_norm": 1.179734468460083,
      "learning_rate": 7.277108433734941e-06,
      "loss": 1.0894,
      "step": 5280
    },
    {
      "epoch": 1.274424768100229,
      "grad_norm": 1.115445852279663,
      "learning_rate": 7.2530120481927715e-06,
      "loss": 0.9962,
      "step": 5290
    },
    {
      "epoch": 1.2768341163715216,
      "grad_norm": 0.929682731628418,
      "learning_rate": 7.228915662650603e-06,
      "loss": 1.0641,
      "step": 5300
    },
    {
      "epoch": 1.2792434646428141,
      "grad_norm": 1.4039603471755981,
      "learning_rate": 7.204819277108435e-06,
      "loss": 1.0245,
      "step": 5310
    },
    {
      "epoch": 1.2816528129141067,
      "grad_norm": 1.365718960762024,
      "learning_rate": 7.180722891566265e-06,
      "loss": 1.0474,
      "step": 5320
    },
    {
      "epoch": 1.2840621611853993,
      "grad_norm": 0.8701816201210022,
      "learning_rate": 7.156626506024097e-06,
      "loss": 1.0561,
      "step": 5330
    },
    {
      "epoch": 1.286471509456692,
      "grad_norm": 1.022215485572815,
      "learning_rate": 7.132530120481929e-06,
      "loss": 1.0084,
      "step": 5340
    },
    {
      "epoch": 1.2888808577279844,
      "grad_norm": 1.214841604232788,
      "learning_rate": 7.1084337349397595e-06,
      "loss": 1.0922,
      "step": 5350
    },
    {
      "epoch": 1.2912902059992772,
      "grad_norm": 1.064929485321045,
      "learning_rate": 7.084337349397591e-06,
      "loss": 1.0065,
      "step": 5360
    },
    {
      "epoch": 1.2936995542705698,
      "grad_norm": 1.523614764213562,
      "learning_rate": 7.060240963855422e-06,
      "loss": 1.0768,
      "step": 5370
    },
    {
      "epoch": 1.2961089025418624,
      "grad_norm": 0.8677517771720886,
      "learning_rate": 7.036144578313253e-06,
      "loss": 1.101,
      "step": 5380
    },
    {
      "epoch": 1.298518250813155,
      "grad_norm": 1.306146264076233,
      "learning_rate": 7.012048192771085e-06,
      "loss": 1.0554,
      "step": 5390
    },
    {
      "epoch": 1.3009275990844476,
      "grad_norm": 1.2013006210327148,
      "learning_rate": 6.987951807228917e-06,
      "loss": 1.0575,
      "step": 5400
    },
    {
      "epoch": 1.3033369473557403,
      "grad_norm": 1.048312783241272,
      "learning_rate": 6.963855421686747e-06,
      "loss": 1.0782,
      "step": 5410
    },
    {
      "epoch": 1.305746295627033,
      "grad_norm": 1.4140011072158813,
      "learning_rate": 6.9397590361445784e-06,
      "loss": 1.0807,
      "step": 5420
    },
    {
      "epoch": 1.3081556438983255,
      "grad_norm": 1.1441962718963623,
      "learning_rate": 6.91566265060241e-06,
      "loss": 1.0546,
      "step": 5430
    },
    {
      "epoch": 1.310564992169618,
      "grad_norm": 1.4099141359329224,
      "learning_rate": 6.891566265060241e-06,
      "loss": 1.0219,
      "step": 5440
    },
    {
      "epoch": 1.3129743404409107,
      "grad_norm": 1.176045536994934,
      "learning_rate": 6.867469879518073e-06,
      "loss": 1.0928,
      "step": 5450
    },
    {
      "epoch": 1.3153836887122035,
      "grad_norm": 1.2221660614013672,
      "learning_rate": 6.843373493975905e-06,
      "loss": 1.0803,
      "step": 5460
    },
    {
      "epoch": 1.317793036983496,
      "grad_norm": 1.1945198774337769,
      "learning_rate": 6.819277108433735e-06,
      "loss": 1.0987,
      "step": 5470
    },
    {
      "epoch": 1.3202023852547886,
      "grad_norm": 1.0464519262313843,
      "learning_rate": 6.7951807228915665e-06,
      "loss": 1.0201,
      "step": 5480
    },
    {
      "epoch": 1.3226117335260812,
      "grad_norm": 1.3000136613845825,
      "learning_rate": 6.771084337349398e-06,
      "loss": 1.0673,
      "step": 5490
    },
    {
      "epoch": 1.3250210817973738,
      "grad_norm": 1.286739706993103,
      "learning_rate": 6.746987951807229e-06,
      "loss": 1.0162,
      "step": 5500
    },
    {
      "epoch": 1.3274304300686663,
      "grad_norm": 1.3735085725784302,
      "learning_rate": 6.722891566265061e-06,
      "loss": 1.065,
      "step": 5510
    },
    {
      "epoch": 1.329839778339959,
      "grad_norm": 0.9719474911689758,
      "learning_rate": 6.698795180722893e-06,
      "loss": 1.0766,
      "step": 5520
    },
    {
      "epoch": 1.3322491266112517,
      "grad_norm": 0.9308100342750549,
      "learning_rate": 6.674698795180723e-06,
      "loss": 1.0419,
      "step": 5530
    },
    {
      "epoch": 1.3346584748825443,
      "grad_norm": 1.2777808904647827,
      "learning_rate": 6.6506024096385545e-06,
      "loss": 1.1364,
      "step": 5540
    },
    {
      "epoch": 1.3370678231538369,
      "grad_norm": 1.2865941524505615,
      "learning_rate": 6.626506024096386e-06,
      "loss": 1.0668,
      "step": 5550
    },
    {
      "epoch": 1.3394771714251295,
      "grad_norm": 1.372902274131775,
      "learning_rate": 6.602409638554217e-06,
      "loss": 1.0838,
      "step": 5560
    },
    {
      "epoch": 1.341886519696422,
      "grad_norm": 0.9757907390594482,
      "learning_rate": 6.578313253012049e-06,
      "loss": 1.0801,
      "step": 5570
    },
    {
      "epoch": 1.3442958679677148,
      "grad_norm": 1.2068222761154175,
      "learning_rate": 6.554216867469881e-06,
      "loss": 1.0546,
      "step": 5580
    },
    {
      "epoch": 1.3467052162390074,
      "grad_norm": 0.9710658192634583,
      "learning_rate": 6.530120481927711e-06,
      "loss": 1.0709,
      "step": 5590
    },
    {
      "epoch": 1.3491145645103,
      "grad_norm": 1.2690781354904175,
      "learning_rate": 6.5060240963855425e-06,
      "loss": 1.0656,
      "step": 5600
    },
    {
      "epoch": 1.3515239127815926,
      "grad_norm": 1.1778919696807861,
      "learning_rate": 6.481927710843374e-06,
      "loss": 1.0634,
      "step": 5610
    },
    {
      "epoch": 1.3539332610528851,
      "grad_norm": 1.1548833847045898,
      "learning_rate": 6.457831325301205e-06,
      "loss": 1.1326,
      "step": 5620
    },
    {
      "epoch": 1.356342609324178,
      "grad_norm": 1.3722690343856812,
      "learning_rate": 6.433734939759036e-06,
      "loss": 1.0743,
      "step": 5630
    },
    {
      "epoch": 1.3587519575954703,
      "grad_norm": 1.4498783349990845,
      "learning_rate": 6.409638554216868e-06,
      "loss": 1.046,
      "step": 5640
    },
    {
      "epoch": 1.361161305866763,
      "grad_norm": 1.3276584148406982,
      "learning_rate": 6.385542168674699e-06,
      "loss": 1.037,
      "step": 5650
    },
    {
      "epoch": 1.3635706541380557,
      "grad_norm": 1.3726023435592651,
      "learning_rate": 6.3614457831325305e-06,
      "loss": 1.0319,
      "step": 5660
    },
    {
      "epoch": 1.3659800024093482,
      "grad_norm": 0.8610029816627502,
      "learning_rate": 6.337349397590362e-06,
      "loss": 1.052,
      "step": 5670
    },
    {
      "epoch": 1.3683893506806408,
      "grad_norm": 1.4182190895080566,
      "learning_rate": 6.313253012048192e-06,
      "loss": 1.0915,
      "step": 5680
    },
    {
      "epoch": 1.3707986989519334,
      "grad_norm": 1.0350388288497925,
      "learning_rate": 6.289156626506024e-06,
      "loss": 1.0125,
      "step": 5690
    },
    {
      "epoch": 1.3732080472232262,
      "grad_norm": 1.3880605697631836,
      "learning_rate": 6.265060240963856e-06,
      "loss": 1.032,
      "step": 5700
    },
    {
      "epoch": 1.3756173954945188,
      "grad_norm": 1.5075660943984985,
      "learning_rate": 6.240963855421688e-06,
      "loss": 0.9953,
      "step": 5710
    },
    {
      "epoch": 1.3780267437658114,
      "grad_norm": 1.2683249711990356,
      "learning_rate": 6.2168674698795185e-06,
      "loss": 1.0366,
      "step": 5720
    },
    {
      "epoch": 1.380436092037104,
      "grad_norm": 1.2417895793914795,
      "learning_rate": 6.19277108433735e-06,
      "loss": 1.0514,
      "step": 5730
    },
    {
      "epoch": 1.3828454403083965,
      "grad_norm": 1.132732629776001,
      "learning_rate": 6.168674698795182e-06,
      "loss": 1.0286,
      "step": 5740
    },
    {
      "epoch": 1.3852547885796893,
      "grad_norm": 1.6390694379806519,
      "learning_rate": 6.144578313253012e-06,
      "loss": 1.0343,
      "step": 5750
    },
    {
      "epoch": 1.3876641368509819,
      "grad_norm": 1.4564303159713745,
      "learning_rate": 6.120481927710844e-06,
      "loss": 1.0391,
      "step": 5760
    },
    {
      "epoch": 1.3900734851222745,
      "grad_norm": 1.1686347723007202,
      "learning_rate": 6.096385542168676e-06,
      "loss": 1.106,
      "step": 5770
    },
    {
      "epoch": 1.392482833393567,
      "grad_norm": 1.764672040939331,
      "learning_rate": 6.0722891566265066e-06,
      "loss": 1.0851,
      "step": 5780
    },
    {
      "epoch": 1.3948921816648596,
      "grad_norm": 1.1413623094558716,
      "learning_rate": 6.048192771084338e-06,
      "loss": 1.0529,
      "step": 5790
    },
    {
      "epoch": 1.3973015299361522,
      "grad_norm": 1.3183711767196655,
      "learning_rate": 6.02409638554217e-06,
      "loss": 1.0532,
      "step": 5800
    },
    {
      "epoch": 1.3997108782074448,
      "grad_norm": 0.989388644695282,
      "learning_rate": 6e-06,
      "loss": 0.9912,
      "step": 5810
    },
    {
      "epoch": 1.4021202264787376,
      "grad_norm": 1.4761663675308228,
      "learning_rate": 5.975903614457832e-06,
      "loss": 1.0116,
      "step": 5820
    },
    {
      "epoch": 1.4045295747500302,
      "grad_norm": 1.0708205699920654,
      "learning_rate": 5.951807228915664e-06,
      "loss": 1.0925,
      "step": 5830
    },
    {
      "epoch": 1.4069389230213227,
      "grad_norm": 1.154844045639038,
      "learning_rate": 5.927710843373495e-06,
      "loss": 1.0462,
      "step": 5840
    },
    {
      "epoch": 1.4093482712926153,
      "grad_norm": 1.4816571474075317,
      "learning_rate": 5.9036144578313255e-06,
      "loss": 1.0681,
      "step": 5850
    },
    {
      "epoch": 1.4117576195639079,
      "grad_norm": 1.318259596824646,
      "learning_rate": 5.879518072289157e-06,
      "loss": 1.0282,
      "step": 5860
    },
    {
      "epoch": 1.4141669678352007,
      "grad_norm": 1.7267266511917114,
      "learning_rate": 5.855421686746988e-06,
      "loss": 1.0367,
      "step": 5870
    },
    {
      "epoch": 1.4165763161064933,
      "grad_norm": 0.9795017242431641,
      "learning_rate": 5.83132530120482e-06,
      "loss": 1.1285,
      "step": 5880
    },
    {
      "epoch": 1.4189856643777858,
      "grad_norm": 0.9361393451690674,
      "learning_rate": 5.807228915662652e-06,
      "loss": 1.0618,
      "step": 5890
    },
    {
      "epoch": 1.4213950126490784,
      "grad_norm": 1.0241286754608154,
      "learning_rate": 5.783132530120482e-06,
      "loss": 1.0343,
      "step": 5900
    },
    {
      "epoch": 1.423804360920371,
      "grad_norm": 1.0093908309936523,
      "learning_rate": 5.7590361445783135e-06,
      "loss": 1.0352,
      "step": 5910
    },
    {
      "epoch": 1.4262137091916638,
      "grad_norm": 1.2107731103897095,
      "learning_rate": 5.734939759036145e-06,
      "loss": 1.0625,
      "step": 5920
    },
    {
      "epoch": 1.4286230574629561,
      "grad_norm": 1.0375083684921265,
      "learning_rate": 5.710843373493976e-06,
      "loss": 1.1089,
      "step": 5930
    },
    {
      "epoch": 1.431032405734249,
      "grad_norm": 1.309830904006958,
      "learning_rate": 5.686746987951808e-06,
      "loss": 1.0575,
      "step": 5940
    },
    {
      "epoch": 1.4334417540055415,
      "grad_norm": 1.2153699398040771,
      "learning_rate": 5.66265060240964e-06,
      "loss": 1.0946,
      "step": 5950
    },
    {
      "epoch": 1.435851102276834,
      "grad_norm": 1.230863094329834,
      "learning_rate": 5.63855421686747e-06,
      "loss": 1.0673,
      "step": 5960
    },
    {
      "epoch": 1.4382604505481267,
      "grad_norm": 1.3616260290145874,
      "learning_rate": 5.6144578313253015e-06,
      "loss": 1.0986,
      "step": 5970
    },
    {
      "epoch": 1.4406697988194193,
      "grad_norm": 1.3114873170852661,
      "learning_rate": 5.590361445783133e-06,
      "loss": 1.0216,
      "step": 5980
    },
    {
      "epoch": 1.443079147090712,
      "grad_norm": 1.1914410591125488,
      "learning_rate": 5.566265060240964e-06,
      "loss": 1.0655,
      "step": 5990
    },
    {
      "epoch": 1.4454884953620046,
      "grad_norm": 1.2821882963180542,
      "learning_rate": 5.542168674698796e-06,
      "loss": 1.0286,
      "step": 6000
    },
    {
      "epoch": 1.4478978436332972,
      "grad_norm": 1.168956995010376,
      "learning_rate": 5.518072289156628e-06,
      "loss": 1.023,
      "step": 6010
    },
    {
      "epoch": 1.4503071919045898,
      "grad_norm": 1.2199087142944336,
      "learning_rate": 5.493975903614458e-06,
      "loss": 1.0694,
      "step": 6020
    },
    {
      "epoch": 1.4527165401758824,
      "grad_norm": 1.0333839654922485,
      "learning_rate": 5.4698795180722896e-06,
      "loss": 1.0888,
      "step": 6030
    },
    {
      "epoch": 1.4551258884471752,
      "grad_norm": 1.2749415636062622,
      "learning_rate": 5.445783132530121e-06,
      "loss": 1.1202,
      "step": 6040
    },
    {
      "epoch": 1.4575352367184675,
      "grad_norm": 1.4123252630233765,
      "learning_rate": 5.421686746987952e-06,
      "loss": 1.0546,
      "step": 6050
    },
    {
      "epoch": 1.4599445849897603,
      "grad_norm": 1.1620408296585083,
      "learning_rate": 5.400000000000001e-06,
      "loss": 1.1191,
      "step": 6060
    },
    {
      "epoch": 1.462353933261053,
      "grad_norm": 1.403988242149353,
      "learning_rate": 5.375903614457832e-06,
      "loss": 1.074,
      "step": 6070
    },
    {
      "epoch": 1.4647632815323455,
      "grad_norm": 1.223707914352417,
      "learning_rate": 5.3518072289156635e-06,
      "loss": 1.0556,
      "step": 6080
    },
    {
      "epoch": 1.467172629803638,
      "grad_norm": 1.1521142721176147,
      "learning_rate": 5.327710843373494e-06,
      "loss": 1.0975,
      "step": 6090
    },
    {
      "epoch": 1.4695819780749306,
      "grad_norm": 0.9658867716789246,
      "learning_rate": 5.303614457831325e-06,
      "loss": 1.0654,
      "step": 6100
    },
    {
      "epoch": 1.4719913263462234,
      "grad_norm": 1.1036266088485718,
      "learning_rate": 5.279518072289157e-06,
      "loss": 1.07,
      "step": 6110
    },
    {
      "epoch": 1.474400674617516,
      "grad_norm": 1.460463047027588,
      "learning_rate": 5.255421686746989e-06,
      "loss": 1.0777,
      "step": 6120
    },
    {
      "epoch": 1.4768100228888086,
      "grad_norm": 1.3064029216766357,
      "learning_rate": 5.231325301204819e-06,
      "loss": 1.0494,
      "step": 6130
    },
    {
      "epoch": 1.4792193711601012,
      "grad_norm": 1.0273518562316895,
      "learning_rate": 5.207228915662651e-06,
      "loss": 1.0503,
      "step": 6140
    },
    {
      "epoch": 1.4816287194313937,
      "grad_norm": 1.2819557189941406,
      "learning_rate": 5.183132530120482e-06,
      "loss": 1.0668,
      "step": 6150
    },
    {
      "epoch": 1.4840380677026865,
      "grad_norm": 1.3879796266555786,
      "learning_rate": 5.159036144578313e-06,
      "loss": 1.0471,
      "step": 6160
    },
    {
      "epoch": 1.4864474159739791,
      "grad_norm": 1.218497395515442,
      "learning_rate": 5.134939759036145e-06,
      "loss": 1.0732,
      "step": 6170
    },
    {
      "epoch": 1.4888567642452717,
      "grad_norm": 1.1448974609375,
      "learning_rate": 5.110843373493977e-06,
      "loss": 1.0252,
      "step": 6180
    },
    {
      "epoch": 1.4912661125165643,
      "grad_norm": 1.2517175674438477,
      "learning_rate": 5.086746987951807e-06,
      "loss": 1.075,
      "step": 6190
    },
    {
      "epoch": 1.4936754607878568,
      "grad_norm": 1.3928776979446411,
      "learning_rate": 5.062650602409639e-06,
      "loss": 1.0717,
      "step": 6200
    },
    {
      "epoch": 1.4960848090591494,
      "grad_norm": 1.5822433233261108,
      "learning_rate": 5.0385542168674704e-06,
      "loss": 1.0351,
      "step": 6210
    },
    {
      "epoch": 1.498494157330442,
      "grad_norm": 1.3117952346801758,
      "learning_rate": 5.014457831325301e-06,
      "loss": 1.0969,
      "step": 6220
    },
    {
      "epoch": 1.5009035056017348,
      "grad_norm": 1.3502949476242065,
      "learning_rate": 4.990361445783133e-06,
      "loss": 1.0628,
      "step": 6230
    },
    {
      "epoch": 1.5033128538730274,
      "grad_norm": 1.225053071975708,
      "learning_rate": 4.966265060240964e-06,
      "loss": 1.0966,
      "step": 6240
    },
    {
      "epoch": 1.50572220214432,
      "grad_norm": 1.0522305965423584,
      "learning_rate": 4.942168674698796e-06,
      "loss": 1.0549,
      "step": 6250
    },
    {
      "epoch": 1.5081315504156125,
      "grad_norm": 1.0244728326797485,
      "learning_rate": 4.918072289156627e-06,
      "loss": 1.0738,
      "step": 6260
    },
    {
      "epoch": 1.510540898686905,
      "grad_norm": 1.0076531171798706,
      "learning_rate": 4.893975903614458e-06,
      "loss": 1.0058,
      "step": 6270
    },
    {
      "epoch": 1.512950246958198,
      "grad_norm": 0.9336056113243103,
      "learning_rate": 4.869879518072289e-06,
      "loss": 1.0773,
      "step": 6280
    },
    {
      "epoch": 1.5153595952294903,
      "grad_norm": 1.1376596689224243,
      "learning_rate": 4.845783132530121e-06,
      "loss": 1.0077,
      "step": 6290
    },
    {
      "epoch": 1.517768943500783,
      "grad_norm": 1.3349212408065796,
      "learning_rate": 4.821686746987953e-06,
      "loss": 1.0973,
      "step": 6300
    },
    {
      "epoch": 1.5201782917720756,
      "grad_norm": 1.120282769203186,
      "learning_rate": 4.797590361445784e-06,
      "loss": 1.0201,
      "step": 6310
    },
    {
      "epoch": 1.5225876400433682,
      "grad_norm": 1.2328405380249023,
      "learning_rate": 4.773493975903615e-06,
      "loss": 1.0301,
      "step": 6320
    },
    {
      "epoch": 1.524996988314661,
      "grad_norm": 1.2452020645141602,
      "learning_rate": 4.7493975903614465e-06,
      "loss": 1.1069,
      "step": 6330
    },
    {
      "epoch": 1.5274063365859534,
      "grad_norm": 1.3190279006958008,
      "learning_rate": 4.725301204819277e-06,
      "loss": 1.05,
      "step": 6340
    },
    {
      "epoch": 1.5298156848572462,
      "grad_norm": 1.4065666198730469,
      "learning_rate": 4.701204819277108e-06,
      "loss": 1.0447,
      "step": 6350
    },
    {
      "epoch": 1.5322250331285387,
      "grad_norm": 1.211254596710205,
      "learning_rate": 4.67710843373494e-06,
      "loss": 1.0915,
      "step": 6360
    },
    {
      "epoch": 1.5346343813998313,
      "grad_norm": 0.9968616962432861,
      "learning_rate": 4.653012048192772e-06,
      "loss": 1.082,
      "step": 6370
    },
    {
      "epoch": 1.5370437296711241,
      "grad_norm": 1.2094467878341675,
      "learning_rate": 4.628915662650603e-06,
      "loss": 1.0594,
      "step": 6380
    },
    {
      "epoch": 1.5394530779424165,
      "grad_norm": 1.0868455171585083,
      "learning_rate": 4.6048192771084345e-06,
      "loss": 1.0591,
      "step": 6390
    },
    {
      "epoch": 1.5418624262137093,
      "grad_norm": 1.3141062259674072,
      "learning_rate": 4.580722891566265e-06,
      "loss": 1.0414,
      "step": 6400
    },
    {
      "epoch": 1.5442717744850019,
      "grad_norm": 1.0614575147628784,
      "learning_rate": 4.556626506024096e-06,
      "loss": 1.0475,
      "step": 6410
    },
    {
      "epoch": 1.5466811227562944,
      "grad_norm": 1.1116454601287842,
      "learning_rate": 4.532530120481928e-06,
      "loss": 1.0599,
      "step": 6420
    },
    {
      "epoch": 1.549090471027587,
      "grad_norm": 1.55507230758667,
      "learning_rate": 4.50843373493976e-06,
      "loss": 1.0298,
      "step": 6430
    },
    {
      "epoch": 1.5514998192988796,
      "grad_norm": 0.929581880569458,
      "learning_rate": 4.484337349397591e-06,
      "loss": 1.067,
      "step": 6440
    },
    {
      "epoch": 1.5539091675701724,
      "grad_norm": 0.948752224445343,
      "learning_rate": 4.4602409638554225e-06,
      "loss": 1.0559,
      "step": 6450
    },
    {
      "epoch": 1.5563185158414647,
      "grad_norm": 0.9701264500617981,
      "learning_rate": 4.4361445783132534e-06,
      "loss": 1.0637,
      "step": 6460
    },
    {
      "epoch": 1.5587278641127575,
      "grad_norm": 1.1799739599227905,
      "learning_rate": 4.412048192771084e-06,
      "loss": 1.1142,
      "step": 6470
    },
    {
      "epoch": 1.5611372123840501,
      "grad_norm": 1.3030034303665161,
      "learning_rate": 4.387951807228916e-06,
      "loss": 1.091,
      "step": 6480
    },
    {
      "epoch": 1.5635465606553427,
      "grad_norm": 1.2275633811950684,
      "learning_rate": 4.363855421686747e-06,
      "loss": 1.0504,
      "step": 6490
    },
    {
      "epoch": 1.5659559089266355,
      "grad_norm": 1.137726902961731,
      "learning_rate": 4.339759036144579e-06,
      "loss": 1.083,
      "step": 6500
    },
    {
      "epoch": 1.5683652571979279,
      "grad_norm": 1.5485893487930298,
      "learning_rate": 4.3156626506024105e-06,
      "loss": 1.054,
      "step": 6510
    },
    {
      "epoch": 1.5707746054692207,
      "grad_norm": 1.165147066116333,
      "learning_rate": 4.2915662650602415e-06,
      "loss": 1.0687,
      "step": 6520
    },
    {
      "epoch": 1.5731839537405132,
      "grad_norm": 1.713139533996582,
      "learning_rate": 4.267469879518072e-06,
      "loss": 1.0805,
      "step": 6530
    },
    {
      "epoch": 1.5755933020118058,
      "grad_norm": 1.1396183967590332,
      "learning_rate": 4.243373493975904e-06,
      "loss": 1.0461,
      "step": 6540
    },
    {
      "epoch": 1.5780026502830984,
      "grad_norm": 1.0647807121276855,
      "learning_rate": 4.219277108433735e-06,
      "loss": 1.0256,
      "step": 6550
    },
    {
      "epoch": 1.580411998554391,
      "grad_norm": 0.975502610206604,
      "learning_rate": 4.195180722891567e-06,
      "loss": 1.0466,
      "step": 6560
    },
    {
      "epoch": 1.5828213468256838,
      "grad_norm": 1.1114156246185303,
      "learning_rate": 4.171084337349398e-06,
      "loss": 0.9933,
      "step": 6570
    },
    {
      "epoch": 1.5852306950969761,
      "grad_norm": 1.1329048871994019,
      "learning_rate": 4.1469879518072295e-06,
      "loss": 1.0838,
      "step": 6580
    },
    {
      "epoch": 1.587640043368269,
      "grad_norm": 1.3226498365402222,
      "learning_rate": 4.12289156626506e-06,
      "loss": 1.107,
      "step": 6590
    },
    {
      "epoch": 1.5900493916395615,
      "grad_norm": 1.2835056781768799,
      "learning_rate": 4.098795180722892e-06,
      "loss": 1.047,
      "step": 6600
    },
    {
      "epoch": 1.592458739910854,
      "grad_norm": 1.3702512979507446,
      "learning_rate": 4.074698795180723e-06,
      "loss": 1.139,
      "step": 6610
    },
    {
      "epoch": 1.5948680881821469,
      "grad_norm": 1.143283486366272,
      "learning_rate": 4.050602409638554e-06,
      "loss": 1.0657,
      "step": 6620
    },
    {
      "epoch": 1.5972774364534392,
      "grad_norm": 1.20562744140625,
      "learning_rate": 4.026506024096386e-06,
      "loss": 1.0878,
      "step": 6630
    },
    {
      "epoch": 1.599686784724732,
      "grad_norm": 1.2994649410247803,
      "learning_rate": 4.0024096385542175e-06,
      "loss": 1.0823,
      "step": 6640
    },
    {
      "epoch": 1.6020961329960246,
      "grad_norm": 1.4169378280639648,
      "learning_rate": 3.978313253012048e-06,
      "loss": 1.0597,
      "step": 6650
    },
    {
      "epoch": 1.6045054812673172,
      "grad_norm": 1.3024624586105347,
      "learning_rate": 3.95421686746988e-06,
      "loss": 1.0879,
      "step": 6660
    },
    {
      "epoch": 1.6069148295386098,
      "grad_norm": 1.1131854057312012,
      "learning_rate": 3.930120481927711e-06,
      "loss": 1.0,
      "step": 6670
    },
    {
      "epoch": 1.6093241778099023,
      "grad_norm": 1.000921368598938,
      "learning_rate": 3.906024096385542e-06,
      "loss": 1.0308,
      "step": 6680
    },
    {
      "epoch": 1.6117335260811951,
      "grad_norm": 1.2123883962631226,
      "learning_rate": 3.881927710843374e-06,
      "loss": 1.0305,
      "step": 6690
    },
    {
      "epoch": 1.6141428743524875,
      "grad_norm": 1.3531800508499146,
      "learning_rate": 3.857831325301205e-06,
      "loss": 1.0503,
      "step": 6700
    },
    {
      "epoch": 1.6165522226237803,
      "grad_norm": 1.058190107345581,
      "learning_rate": 3.833734939759036e-06,
      "loss": 1.121,
      "step": 6710
    },
    {
      "epoch": 1.6189615708950729,
      "grad_norm": 1.5244932174682617,
      "learning_rate": 3.8096385542168678e-06,
      "loss": 1.0512,
      "step": 6720
    },
    {
      "epoch": 1.6213709191663654,
      "grad_norm": 0.9962784051895142,
      "learning_rate": 3.785542168674699e-06,
      "loss": 1.0637,
      "step": 6730
    },
    {
      "epoch": 1.6237802674376582,
      "grad_norm": 1.2157474756240845,
      "learning_rate": 3.76144578313253e-06,
      "loss": 1.0856,
      "step": 6740
    },
    {
      "epoch": 1.6261896157089506,
      "grad_norm": 1.200424313545227,
      "learning_rate": 3.7373493975903618e-06,
      "loss": 1.0781,
      "step": 6750
    },
    {
      "epoch": 1.6285989639802434,
      "grad_norm": 1.2877994775772095,
      "learning_rate": 3.713253012048193e-06,
      "loss": 1.0241,
      "step": 6760
    },
    {
      "epoch": 1.631008312251536,
      "grad_norm": 1.1271016597747803,
      "learning_rate": 3.689156626506024e-06,
      "loss": 1.0755,
      "step": 6770
    },
    {
      "epoch": 1.6334176605228286,
      "grad_norm": 1.4721301794052124,
      "learning_rate": 3.6650602409638558e-06,
      "loss": 1.0957,
      "step": 6780
    },
    {
      "epoch": 1.6358270087941214,
      "grad_norm": 1.2560451030731201,
      "learning_rate": 3.640963855421687e-06,
      "loss": 1.1036,
      "step": 6790
    },
    {
      "epoch": 1.6382363570654137,
      "grad_norm": 0.9039455652236938,
      "learning_rate": 3.6168674698795185e-06,
      "loss": 1.1103,
      "step": 6800
    },
    {
      "epoch": 1.6406457053367065,
      "grad_norm": 1.0072615146636963,
      "learning_rate": 3.59277108433735e-06,
      "loss": 0.9871,
      "step": 6810
    },
    {
      "epoch": 1.643055053607999,
      "grad_norm": 1.058516025543213,
      "learning_rate": 3.568674698795181e-06,
      "loss": 1.0556,
      "step": 6820
    },
    {
      "epoch": 1.6454644018792917,
      "grad_norm": 1.1374351978302002,
      "learning_rate": 3.5445783132530125e-06,
      "loss": 1.0365,
      "step": 6830
    },
    {
      "epoch": 1.6478737501505842,
      "grad_norm": 1.248547911643982,
      "learning_rate": 3.520481927710844e-06,
      "loss": 1.0344,
      "step": 6840
    },
    {
      "epoch": 1.6502830984218768,
      "grad_norm": 1.1906739473342896,
      "learning_rate": 3.4963855421686747e-06,
      "loss": 1.084,
      "step": 6850
    },
    {
      "epoch": 1.6526924466931696,
      "grad_norm": 1.1263116598129272,
      "learning_rate": 3.4722891566265065e-06,
      "loss": 1.0426,
      "step": 6860
    },
    {
      "epoch": 1.655101794964462,
      "grad_norm": 1.069772720336914,
      "learning_rate": 3.448192771084338e-06,
      "loss": 1.0408,
      "step": 6870
    },
    {
      "epoch": 1.6575111432357548,
      "grad_norm": 1.1171454191207886,
      "learning_rate": 3.4240963855421687e-06,
      "loss": 1.0647,
      "step": 6880
    },
    {
      "epoch": 1.6599204915070473,
      "grad_norm": 1.0406779050827026,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 1.0697,
      "step": 6890
    },
    {
      "epoch": 1.66232983977834,
      "grad_norm": 1.4518437385559082,
      "learning_rate": 3.375903614457832e-06,
      "loss": 1.104,
      "step": 6900
    },
    {
      "epoch": 1.6647391880496327,
      "grad_norm": 0.9768632054328918,
      "learning_rate": 3.3518072289156627e-06,
      "loss": 1.0645,
      "step": 6910
    },
    {
      "epoch": 1.667148536320925,
      "grad_norm": 1.3271465301513672,
      "learning_rate": 3.3277108433734945e-06,
      "loss": 1.0287,
      "step": 6920
    },
    {
      "epoch": 1.6695578845922179,
      "grad_norm": 1.187837839126587,
      "learning_rate": 3.303614457831326e-06,
      "loss": 1.081,
      "step": 6930
    },
    {
      "epoch": 1.6719672328635105,
      "grad_norm": 1.111292839050293,
      "learning_rate": 3.2795180722891567e-06,
      "loss": 1.0727,
      "step": 6940
    },
    {
      "epoch": 1.674376581134803,
      "grad_norm": 1.3648816347122192,
      "learning_rate": 3.2554216867469885e-06,
      "loss": 1.0633,
      "step": 6950
    },
    {
      "epoch": 1.6767859294060956,
      "grad_norm": 1.5972166061401367,
      "learning_rate": 3.2313253012048194e-06,
      "loss": 1.0469,
      "step": 6960
    },
    {
      "epoch": 1.6791952776773882,
      "grad_norm": 1.0052330493927002,
      "learning_rate": 3.2072289156626508e-06,
      "loss": 1.0143,
      "step": 6970
    },
    {
      "epoch": 1.681604625948681,
      "grad_norm": 1.3039335012435913,
      "learning_rate": 3.1831325301204825e-06,
      "loss": 1.0991,
      "step": 6980
    },
    {
      "epoch": 1.6840139742199733,
      "grad_norm": 1.1028996706008911,
      "learning_rate": 3.1590361445783134e-06,
      "loss": 1.0422,
      "step": 6990
    },
    {
      "epoch": 1.6864233224912661,
      "grad_norm": 1.188643217086792,
      "learning_rate": 3.1349397590361448e-06,
      "loss": 1.0392,
      "step": 7000
    },
    {
      "epoch": 1.6888326707625587,
      "grad_norm": 0.8713148832321167,
      "learning_rate": 3.1108433734939765e-06,
      "loss": 1.0687,
      "step": 7010
    },
    {
      "epoch": 1.6912420190338513,
      "grad_norm": 1.1512013673782349,
      "learning_rate": 3.0867469879518074e-06,
      "loss": 1.0619,
      "step": 7020
    },
    {
      "epoch": 1.693651367305144,
      "grad_norm": 1.086871862411499,
      "learning_rate": 3.0626506024096388e-06,
      "loss": 1.0987,
      "step": 7030
    },
    {
      "epoch": 1.6960607155764365,
      "grad_norm": 1.107533574104309,
      "learning_rate": 3.0385542168674705e-06,
      "loss": 0.9649,
      "step": 7040
    },
    {
      "epoch": 1.6984700638477293,
      "grad_norm": 1.3267271518707275,
      "learning_rate": 3.0144578313253014e-06,
      "loss": 1.1156,
      "step": 7050
    },
    {
      "epoch": 1.7008794121190218,
      "grad_norm": 1.3133057355880737,
      "learning_rate": 2.9903614457831328e-06,
      "loss": 1.021,
      "step": 7060
    },
    {
      "epoch": 1.7032887603903144,
      "grad_norm": 1.0000227689743042,
      "learning_rate": 2.966265060240964e-06,
      "loss": 1.0898,
      "step": 7070
    },
    {
      "epoch": 1.705698108661607,
      "grad_norm": 1.0422194004058838,
      "learning_rate": 2.9421686746987955e-06,
      "loss": 1.0829,
      "step": 7080
    },
    {
      "epoch": 1.7081074569328996,
      "grad_norm": 1.1436638832092285,
      "learning_rate": 2.9180722891566264e-06,
      "loss": 1.0832,
      "step": 7090
    },
    {
      "epoch": 1.7105168052041924,
      "grad_norm": 1.3259433507919312,
      "learning_rate": 2.893975903614458e-06,
      "loss": 1.0495,
      "step": 7100
    },
    {
      "epoch": 1.712926153475485,
      "grad_norm": 1.2096822261810303,
      "learning_rate": 2.8698795180722895e-06,
      "loss": 1.0734,
      "step": 7110
    },
    {
      "epoch": 1.7153355017467775,
      "grad_norm": 1.3514195680618286,
      "learning_rate": 2.8457831325301204e-06,
      "loss": 1.0584,
      "step": 7120
    },
    {
      "epoch": 1.71774485001807,
      "grad_norm": 1.3705265522003174,
      "learning_rate": 2.821686746987952e-06,
      "loss": 1.077,
      "step": 7130
    },
    {
      "epoch": 1.7201541982893627,
      "grad_norm": 1.3536572456359863,
      "learning_rate": 2.7975903614457835e-06,
      "loss": 1.0164,
      "step": 7140
    },
    {
      "epoch": 1.7225635465606555,
      "grad_norm": 1.1610512733459473,
      "learning_rate": 2.7734939759036144e-06,
      "loss": 1.06,
      "step": 7150
    },
    {
      "epoch": 1.7249728948319478,
      "grad_norm": 1.0747443437576294,
      "learning_rate": 2.749397590361446e-06,
      "loss": 1.0663,
      "step": 7160
    },
    {
      "epoch": 1.7273822431032406,
      "grad_norm": 0.8969329595565796,
      "learning_rate": 2.7253012048192775e-06,
      "loss": 1.0356,
      "step": 7170
    },
    {
      "epoch": 1.7297915913745332,
      "grad_norm": 1.3337308168411255,
      "learning_rate": 2.7012048192771084e-06,
      "loss": 1.0486,
      "step": 7180
    },
    {
      "epoch": 1.7322009396458258,
      "grad_norm": 0.9646986126899719,
      "learning_rate": 2.67710843373494e-06,
      "loss": 0.9952,
      "step": 7190
    },
    {
      "epoch": 1.7346102879171186,
      "grad_norm": 1.0198363065719604,
      "learning_rate": 2.653012048192771e-06,
      "loss": 1.0652,
      "step": 7200
    },
    {
      "epoch": 1.737019636188411,
      "grad_norm": 1.017901062965393,
      "learning_rate": 2.6289156626506024e-06,
      "loss": 1.0604,
      "step": 7210
    },
    {
      "epoch": 1.7394289844597037,
      "grad_norm": 1.1826186180114746,
      "learning_rate": 2.604819277108434e-06,
      "loss": 1.0584,
      "step": 7220
    },
    {
      "epoch": 1.7418383327309963,
      "grad_norm": 1.487051248550415,
      "learning_rate": 2.580722891566265e-06,
      "loss": 1.05,
      "step": 7230
    },
    {
      "epoch": 1.7442476810022889,
      "grad_norm": 1.1145521402359009,
      "learning_rate": 2.5566265060240964e-06,
      "loss": 1.0795,
      "step": 7240
    },
    {
      "epoch": 1.7466570292735815,
      "grad_norm": 1.0142728090286255,
      "learning_rate": 2.532530120481928e-06,
      "loss": 1.0922,
      "step": 7250
    },
    {
      "epoch": 1.749066377544874,
      "grad_norm": 1.2258394956588745,
      "learning_rate": 2.508433734939759e-06,
      "loss": 1.0545,
      "step": 7260
    },
    {
      "epoch": 1.7514757258161668,
      "grad_norm": 1.0127300024032593,
      "learning_rate": 2.4843373493975904e-06,
      "loss": 1.0548,
      "step": 7270
    },
    {
      "epoch": 1.7538850740874592,
      "grad_norm": 1.4493976831436157,
      "learning_rate": 2.460240963855422e-06,
      "loss": 1.0471,
      "step": 7280
    },
    {
      "epoch": 1.756294422358752,
      "grad_norm": 0.9763560891151428,
      "learning_rate": 2.436144578313253e-06,
      "loss": 1.1106,
      "step": 7290
    },
    {
      "epoch": 1.7587037706300446,
      "grad_norm": 1.4238766431808472,
      "learning_rate": 2.4120481927710844e-06,
      "loss": 1.0173,
      "step": 7300
    },
    {
      "epoch": 1.7611131189013371,
      "grad_norm": 1.2951077222824097,
      "learning_rate": 2.3879518072289158e-06,
      "loss": 1.0295,
      "step": 7310
    },
    {
      "epoch": 1.76352246717263,
      "grad_norm": 1.7683954238891602,
      "learning_rate": 2.363855421686747e-06,
      "loss": 1.0294,
      "step": 7320
    },
    {
      "epoch": 1.7659318154439223,
      "grad_norm": 1.1789450645446777,
      "learning_rate": 2.3397590361445784e-06,
      "loss": 1.0508,
      "step": 7330
    },
    {
      "epoch": 1.768341163715215,
      "grad_norm": 1.0385512113571167,
      "learning_rate": 2.3156626506024098e-06,
      "loss": 1.0505,
      "step": 7340
    },
    {
      "epoch": 1.7707505119865077,
      "grad_norm": 1.1235110759735107,
      "learning_rate": 2.291566265060241e-06,
      "loss": 1.0365,
      "step": 7350
    },
    {
      "epoch": 1.7731598602578003,
      "grad_norm": 0.948702335357666,
      "learning_rate": 2.2674698795180725e-06,
      "loss": 1.0238,
      "step": 7360
    },
    {
      "epoch": 1.7755692085290928,
      "grad_norm": 1.4836920499801636,
      "learning_rate": 2.243373493975904e-06,
      "loss": 1.0805,
      "step": 7370
    },
    {
      "epoch": 1.7779785568003854,
      "grad_norm": 1.141812801361084,
      "learning_rate": 2.219277108433735e-06,
      "loss": 1.0555,
      "step": 7380
    },
    {
      "epoch": 1.7803879050716782,
      "grad_norm": 1.1209278106689453,
      "learning_rate": 2.1951807228915665e-06,
      "loss": 1.0182,
      "step": 7390
    },
    {
      "epoch": 1.7827972533429706,
      "grad_norm": 1.268014669418335,
      "learning_rate": 2.171084337349398e-06,
      "loss": 1.1594,
      "step": 7400
    },
    {
      "epoch": 1.7852066016142634,
      "grad_norm": 1.0312987565994263,
      "learning_rate": 2.146987951807229e-06,
      "loss": 1.1077,
      "step": 7410
    },
    {
      "epoch": 1.787615949885556,
      "grad_norm": 1.1549198627471924,
      "learning_rate": 2.1228915662650605e-06,
      "loss": 1.0764,
      "step": 7420
    },
    {
      "epoch": 1.7900252981568485,
      "grad_norm": 1.1411110162734985,
      "learning_rate": 2.098795180722892e-06,
      "loss": 1.0939,
      "step": 7430
    },
    {
      "epoch": 1.7924346464281413,
      "grad_norm": 1.282304048538208,
      "learning_rate": 2.0746987951807227e-06,
      "loss": 1.0256,
      "step": 7440
    },
    {
      "epoch": 1.7948439946994337,
      "grad_norm": 1.0163812637329102,
      "learning_rate": 2.0506024096385545e-06,
      "loss": 1.0329,
      "step": 7450
    },
    {
      "epoch": 1.7972533429707265,
      "grad_norm": 1.173397421836853,
      "learning_rate": 2.026506024096386e-06,
      "loss": 1.0117,
      "step": 7460
    },
    {
      "epoch": 1.799662691242019,
      "grad_norm": 1.2101373672485352,
      "learning_rate": 2.002409638554217e-06,
      "loss": 1.0539,
      "step": 7470
    },
    {
      "epoch": 1.8020720395133116,
      "grad_norm": 1.4873571395874023,
      "learning_rate": 1.9783132530120485e-06,
      "loss": 1.0158,
      "step": 7480
    },
    {
      "epoch": 1.8044813877846044,
      "grad_norm": 1.162492036819458,
      "learning_rate": 1.95421686746988e-06,
      "loss": 1.0566,
      "step": 7490
    },
    {
      "epoch": 1.8068907360558968,
      "grad_norm": 1.026611089706421,
      "learning_rate": 1.930120481927711e-06,
      "loss": 1.0469,
      "step": 7500
    },
    {
      "epoch": 1.8093000843271896,
      "grad_norm": 1.560615062713623,
      "learning_rate": 1.9060240963855423e-06,
      "loss": 1.0468,
      "step": 7510
    },
    {
      "epoch": 1.8117094325984822,
      "grad_norm": 1.221908450126648,
      "learning_rate": 1.8819277108433736e-06,
      "loss": 1.0546,
      "step": 7520
    },
    {
      "epoch": 1.8141187808697747,
      "grad_norm": 0.984454870223999,
      "learning_rate": 1.8578313253012052e-06,
      "loss": 1.0658,
      "step": 7530
    },
    {
      "epoch": 1.8165281291410673,
      "grad_norm": 1.439255714416504,
      "learning_rate": 1.8337349397590363e-06,
      "loss": 1.1081,
      "step": 7540
    },
    {
      "epoch": 1.81893747741236,
      "grad_norm": 0.9083988070487976,
      "learning_rate": 1.8096385542168676e-06,
      "loss": 1.0307,
      "step": 7550
    },
    {
      "epoch": 1.8213468256836527,
      "grad_norm": 1.1564573049545288,
      "learning_rate": 1.785542168674699e-06,
      "loss": 1.0993,
      "step": 7560
    },
    {
      "epoch": 1.823756173954945,
      "grad_norm": 1.253491997718811,
      "learning_rate": 1.76144578313253e-06,
      "loss": 1.0579,
      "step": 7570
    },
    {
      "epoch": 1.8261655222262378,
      "grad_norm": 1.1857541799545288,
      "learning_rate": 1.7373493975903616e-06,
      "loss": 1.0099,
      "step": 7580
    },
    {
      "epoch": 1.8285748704975304,
      "grad_norm": 1.1550706624984741,
      "learning_rate": 1.713253012048193e-06,
      "loss": 1.0709,
      "step": 7590
    },
    {
      "epoch": 1.830984218768823,
      "grad_norm": 1.3587567806243896,
      "learning_rate": 1.6891566265060241e-06,
      "loss": 1.0564,
      "step": 7600
    },
    {
      "epoch": 1.8333935670401158,
      "grad_norm": 1.2899789810180664,
      "learning_rate": 1.6650602409638554e-06,
      "loss": 1.0613,
      "step": 7610
    },
    {
      "epoch": 1.8358029153114082,
      "grad_norm": 1.606450080871582,
      "learning_rate": 1.640963855421687e-06,
      "loss": 1.0601,
      "step": 7620
    },
    {
      "epoch": 1.838212263582701,
      "grad_norm": 1.220245599746704,
      "learning_rate": 1.6168674698795181e-06,
      "loss": 1.0035,
      "step": 7630
    },
    {
      "epoch": 1.8406216118539935,
      "grad_norm": 1.2233257293701172,
      "learning_rate": 1.5927710843373495e-06,
      "loss": 1.1121,
      "step": 7640
    },
    {
      "epoch": 1.843030960125286,
      "grad_norm": 1.3244136571884155,
      "learning_rate": 1.568674698795181e-06,
      "loss": 1.0855,
      "step": 7650
    },
    {
      "epoch": 1.8454403083965787,
      "grad_norm": 1.7452493906021118,
      "learning_rate": 1.5445783132530121e-06,
      "loss": 1.0384,
      "step": 7660
    },
    {
      "epoch": 1.8478496566678713,
      "grad_norm": 1.0516477823257446,
      "learning_rate": 1.5204819277108435e-06,
      "loss": 1.0711,
      "step": 7670
    },
    {
      "epoch": 1.850259004939164,
      "grad_norm": 1.105944275856018,
      "learning_rate": 1.4963855421686748e-06,
      "loss": 1.0636,
      "step": 7680
    },
    {
      "epoch": 1.8526683532104564,
      "grad_norm": 1.2784786224365234,
      "learning_rate": 1.472289156626506e-06,
      "loss": 1.0441,
      "step": 7690
    },
    {
      "epoch": 1.8550777014817492,
      "grad_norm": 1.2545145750045776,
      "learning_rate": 1.4481927710843375e-06,
      "loss": 1.0598,
      "step": 7700
    },
    {
      "epoch": 1.8574870497530418,
      "grad_norm": 1.3623276948928833,
      "learning_rate": 1.4240963855421688e-06,
      "loss": 1.0868,
      "step": 7710
    },
    {
      "epoch": 1.8598963980243344,
      "grad_norm": 1.2513206005096436,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 1.0643,
      "step": 7720
    },
    {
      "epoch": 1.8623057462956272,
      "grad_norm": 1.1137326955795288,
      "learning_rate": 1.3759036144578315e-06,
      "loss": 1.0405,
      "step": 7730
    },
    {
      "epoch": 1.8647150945669195,
      "grad_norm": 1.2826745510101318,
      "learning_rate": 1.3518072289156628e-06,
      "loss": 1.032,
      "step": 7740
    },
    {
      "epoch": 1.8671244428382123,
      "grad_norm": 1.0607119798660278,
      "learning_rate": 1.3277108433734942e-06,
      "loss": 1.0997,
      "step": 7750
    },
    {
      "epoch": 1.869533791109505,
      "grad_norm": 1.3120777606964111,
      "learning_rate": 1.3036144578313253e-06,
      "loss": 1.0499,
      "step": 7760
    },
    {
      "epoch": 1.8719431393807975,
      "grad_norm": 1.0882669687271118,
      "learning_rate": 1.2795180722891568e-06,
      "loss": 1.0767,
      "step": 7770
    },
    {
      "epoch": 1.87435248765209,
      "grad_norm": 1.195342779159546,
      "learning_rate": 1.2554216867469882e-06,
      "loss": 1.0632,
      "step": 7780
    },
    {
      "epoch": 1.8767618359233826,
      "grad_norm": 1.496649146080017,
      "learning_rate": 1.2313253012048195e-06,
      "loss": 1.0498,
      "step": 7790
    },
    {
      "epoch": 1.8791711841946754,
      "grad_norm": 0.9687283039093018,
      "learning_rate": 1.2072289156626506e-06,
      "loss": 1.0552,
      "step": 7800
    },
    {
      "epoch": 1.8815805324659678,
      "grad_norm": 1.455610990524292,
      "learning_rate": 1.183132530120482e-06,
      "loss": 1.0604,
      "step": 7810
    },
    {
      "epoch": 1.8839898807372606,
      "grad_norm": 1.1032463312149048,
      "learning_rate": 1.1590361445783133e-06,
      "loss": 1.0636,
      "step": 7820
    },
    {
      "epoch": 1.8863992290085532,
      "grad_norm": 1.550387978553772,
      "learning_rate": 1.1349397590361446e-06,
      "loss": 1.0861,
      "step": 7830
    },
    {
      "epoch": 1.8888085772798457,
      "grad_norm": 1.2566907405853271,
      "learning_rate": 1.110843373493976e-06,
      "loss": 1.0743,
      "step": 7840
    },
    {
      "epoch": 1.8912179255511385,
      "grad_norm": 1.1697291135787964,
      "learning_rate": 1.0867469879518073e-06,
      "loss": 1.0355,
      "step": 7850
    },
    {
      "epoch": 1.893627273822431,
      "grad_norm": 0.9479579925537109,
      "learning_rate": 1.0626506024096386e-06,
      "loss": 1.0104,
      "step": 7860
    },
    {
      "epoch": 1.8960366220937237,
      "grad_norm": 1.0477982759475708,
      "learning_rate": 1.03855421686747e-06,
      "loss": 1.0384,
      "step": 7870
    },
    {
      "epoch": 1.8984459703650163,
      "grad_norm": 1.0486559867858887,
      "learning_rate": 1.0168674698795181e-06,
      "loss": 1.0162,
      "step": 7880
    },
    {
      "epoch": 1.9008553186363089,
      "grad_norm": 1.2283018827438354,
      "learning_rate": 9.927710843373495e-07,
      "loss": 1.044,
      "step": 7890
    },
    {
      "epoch": 1.9032646669076017,
      "grad_norm": 1.1413980722427368,
      "learning_rate": 9.686746987951808e-07,
      "loss": 1.0507,
      "step": 7900
    },
    {
      "epoch": 1.905674015178894,
      "grad_norm": 1.3433700799942017,
      "learning_rate": 9.445783132530122e-07,
      "loss": 1.1243,
      "step": 7910
    },
    {
      "epoch": 1.9080833634501868,
      "grad_norm": 0.9425875544548035,
      "learning_rate": 9.204819277108434e-07,
      "loss": 0.9912,
      "step": 7920
    },
    {
      "epoch": 1.9104927117214794,
      "grad_norm": 0.9279590249061584,
      "learning_rate": 8.963855421686747e-07,
      "loss": 1.0567,
      "step": 7930
    },
    {
      "epoch": 1.912902059992772,
      "grad_norm": 1.5198822021484375,
      "learning_rate": 8.722891566265062e-07,
      "loss": 1.0607,
      "step": 7940
    },
    {
      "epoch": 1.9153114082640645,
      "grad_norm": 1.1666990518569946,
      "learning_rate": 8.481927710843374e-07,
      "loss": 1.041,
      "step": 7950
    },
    {
      "epoch": 1.9177207565353571,
      "grad_norm": 1.3596802949905396,
      "learning_rate": 8.240963855421688e-07,
      "loss": 1.0769,
      "step": 7960
    },
    {
      "epoch": 1.92013010480665,
      "grad_norm": 1.1942594051361084,
      "learning_rate": 8.000000000000001e-07,
      "loss": 1.0561,
      "step": 7970
    },
    {
      "epoch": 1.9225394530779423,
      "grad_norm": 1.330345869064331,
      "learning_rate": 7.759036144578314e-07,
      "loss": 1.058,
      "step": 7980
    },
    {
      "epoch": 1.924948801349235,
      "grad_norm": 1.313033938407898,
      "learning_rate": 7.518072289156627e-07,
      "loss": 1.0788,
      "step": 7990
    },
    {
      "epoch": 1.9273581496205276,
      "grad_norm": 1.4674129486083984,
      "learning_rate": 7.277108433734941e-07,
      "loss": 1.0933,
      "step": 8000
    },
    {
      "epoch": 1.9297674978918202,
      "grad_norm": 1.1753708124160767,
      "learning_rate": 7.036144578313253e-07,
      "loss": 1.0952,
      "step": 8010
    },
    {
      "epoch": 1.932176846163113,
      "grad_norm": 1.215855360031128,
      "learning_rate": 6.795180722891568e-07,
      "loss": 1.0637,
      "step": 8020
    },
    {
      "epoch": 1.9345861944344054,
      "grad_norm": 1.3094576597213745,
      "learning_rate": 6.55421686746988e-07,
      "loss": 1.0488,
      "step": 8030
    },
    {
      "epoch": 1.9369955427056982,
      "grad_norm": 1.344216227531433,
      "learning_rate": 6.313253012048193e-07,
      "loss": 1.0576,
      "step": 8040
    },
    {
      "epoch": 1.9394048909769908,
      "grad_norm": 1.1314018964767456,
      "learning_rate": 6.072289156626507e-07,
      "loss": 1.063,
      "step": 8050
    },
    {
      "epoch": 1.9418142392482833,
      "grad_norm": 1.180019736289978,
      "learning_rate": 5.83132530120482e-07,
      "loss": 1.0655,
      "step": 8060
    },
    {
      "epoch": 1.944223587519576,
      "grad_norm": 0.927517294883728,
      "learning_rate": 5.590361445783133e-07,
      "loss": 0.9877,
      "step": 8070
    },
    {
      "epoch": 1.9466329357908685,
      "grad_norm": 0.995215117931366,
      "learning_rate": 5.349397590361447e-07,
      "loss": 1.0178,
      "step": 8080
    },
    {
      "epoch": 1.9490422840621613,
      "grad_norm": 1.0827686786651611,
      "learning_rate": 5.108433734939759e-07,
      "loss": 1.0857,
      "step": 8090
    },
    {
      "epoch": 1.9514516323334536,
      "grad_norm": 1.489903211593628,
      "learning_rate": 4.867469879518072e-07,
      "loss": 1.0112,
      "step": 8100
    },
    {
      "epoch": 1.9538609806047464,
      "grad_norm": 1.2021102905273438,
      "learning_rate": 4.626506024096386e-07,
      "loss": 1.0701,
      "step": 8110
    },
    {
      "epoch": 1.956270328876039,
      "grad_norm": 1.1213643550872803,
      "learning_rate": 4.3855421686746996e-07,
      "loss": 1.0451,
      "step": 8120
    },
    {
      "epoch": 1.9586796771473316,
      "grad_norm": 1.2499644756317139,
      "learning_rate": 4.1445783132530124e-07,
      "loss": 1.0253,
      "step": 8130
    },
    {
      "epoch": 1.9610890254186244,
      "grad_norm": 1.0930345058441162,
      "learning_rate": 3.903614457831326e-07,
      "loss": 1.0489,
      "step": 8140
    },
    {
      "epoch": 1.9634983736899168,
      "grad_norm": 1.0867605209350586,
      "learning_rate": 3.662650602409639e-07,
      "loss": 1.0986,
      "step": 8150
    },
    {
      "epoch": 1.9659077219612096,
      "grad_norm": 1.2199307680130005,
      "learning_rate": 3.421686746987952e-07,
      "loss": 1.0574,
      "step": 8160
    },
    {
      "epoch": 1.9683170702325021,
      "grad_norm": 1.034220814704895,
      "learning_rate": 3.1807228915662654e-07,
      "loss": 1.0959,
      "step": 8170
    },
    {
      "epoch": 1.9707264185037947,
      "grad_norm": 1.2641746997833252,
      "learning_rate": 2.9397590361445787e-07,
      "loss": 1.094,
      "step": 8180
    },
    {
      "epoch": 1.9731357667750873,
      "grad_norm": 1.1445993185043335,
      "learning_rate": 2.6987951807228916e-07,
      "loss": 1.0465,
      "step": 8190
    },
    {
      "epoch": 1.9755451150463799,
      "grad_norm": 1.1996864080429077,
      "learning_rate": 2.457831325301205e-07,
      "loss": 1.0334,
      "step": 8200
    },
    {
      "epoch": 1.9779544633176727,
      "grad_norm": 1.424914836883545,
      "learning_rate": 2.2168674698795183e-07,
      "loss": 1.0506,
      "step": 8210
    },
    {
      "epoch": 1.9803638115889652,
      "grad_norm": 1.3818894624710083,
      "learning_rate": 1.9759036144578314e-07,
      "loss": 1.0642,
      "step": 8220
    },
    {
      "epoch": 1.9827731598602578,
      "grad_norm": 1.407448410987854,
      "learning_rate": 1.7349397590361448e-07,
      "loss": 1.0555,
      "step": 8230
    },
    {
      "epoch": 1.9851825081315504,
      "grad_norm": 1.3877695798873901,
      "learning_rate": 1.4939759036144581e-07,
      "loss": 1.0535,
      "step": 8240
    },
    {
      "epoch": 1.987591856402843,
      "grad_norm": 1.1396594047546387,
      "learning_rate": 1.2530120481927712e-07,
      "loss": 1.0705,
      "step": 8250
    },
    {
      "epoch": 1.9900012046741358,
      "grad_norm": 1.3117547035217285,
      "learning_rate": 1.0120481927710843e-07,
      "loss": 1.056,
      "step": 8260
    },
    {
      "epoch": 1.9924105529454281,
      "grad_norm": 1.1313880681991577,
      "learning_rate": 7.710843373493976e-08,
      "loss": 1.0366,
      "step": 8270
    },
    {
      "epoch": 1.994819901216721,
      "grad_norm": 1.2915222644805908,
      "learning_rate": 5.301204819277109e-08,
      "loss": 1.078,
      "step": 8280
    },
    {
      "epoch": 1.9972292494880135,
      "grad_norm": 1.0540286302566528,
      "learning_rate": 2.8915662650602414e-08,
      "loss": 1.1049,
      "step": 8290
    },
    {
      "epoch": 1.999638597759306,
      "grad_norm": 1.236401915550232,
      "learning_rate": 4.819277108433735e-09,
      "loss": 1.044,
      "step": 8300
    }
  ],
  "logging_steps": 10,
  "max_steps": 8300,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5842589019471872e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
